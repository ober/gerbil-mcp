[
  {
    "id": "ffi-null-safety-audit",
    "title": "FFI null-pointer safety audit for .scm files",
    "description": "A tool that statically analyzes .scm FFI files to find c-lambda declarations that dereference pointer arguments (___arg1->field) without null checks. Reports each accessor that could segfault on NULL input, cross-referenced with call sites in .ss wrapper files to check whether the wrapper guards the call with a null/truthy check. This catches the common pattern where FFI accessors blindly dereference pointers that can legitimately be NULL (e.g. xmlNode-children, xmlNode-ns, xmlNode-content returning NULL).",
    "impact": "medium",
    "tags": [
      "ffi",
      "null",
      "pointer",
      "safety",
      "audit",
      "c-lambda",
      "dereference",
      "segfault"
    ],
    "use_case": "When auditing FFI bindings to C libraries that use NULL to represent absence (linked list terminators, optional fields). Common in libxml2, libyaml, SQLite, and most C APIs.",
    "example_scenario": "Auditing gerbil-libxml: 15+ c-lambda accessors like xmlNode-content, xmlNode-name, xmlNs-href blindly dereference ___arg1->field. Some are guarded by null checks in the .ss wrapper (xmlNode-children via `if node`), but others are not (xmlNode-content on TEXT nodes, xmlNs-href). Manual cross-referencing took multiple tool calls to Read both files and trace each call path. A dedicated tool could report: 'xmlNode-content (line 163): dereferences ___arg1->content, called unguarded at libxml.ss:151'.",
    "estimated_token_reduction": "~2000 tokens per audit — eliminates manual cross-referencing of .scm accessors with .ss call sites, currently requires 2 Read calls + manual analysis",
    "votes": 2
  },
  {
    "id": "method-dispatch-audit",
    "title": "Detect method dispatch calls on objects that lack the method",
    "description": "A static analysis tool that checks `{method-name obj}` calls against the actual methods defined on the object's type. Reports cases where method dispatch will fail at runtime because the struct/class doesn't have the method defined (either directly or inherited). This catches the common bug pattern where code assumes an interface method exists (like `{close conn}`) but the struct's type hierarchy doesn't define it, leading to silent failures or contract violations at runtime.",
    "impact": "medium",
    "tags": [
      "method",
      "dispatch",
      "close",
      "interface",
      "struct",
      "static-analysis"
    ],
    "use_case": "When writing code that uses method dispatch on structs from external modules. Common in persistence layers, database wrappers, and any code using Gerbil's OOP features where multiple struct types implement similar interfaces.",
    "example_scenario": "In gerbil-persist, `{close Kvs}` called `{close (Kvs-connection self)}` where the connection is a DBI `connection` struct. DBI connections have NO `close` method — they use the plain function `sql-close`. This bug meant SQLite connections were never actually closed, causing 'database is locked' errors. The bug existed undetected because `{close}` dispatch failure was caught silently. A method-dispatch-audit tool would have flagged: '{close} called on connection::t at kvs.ss:26 — no close method found in type hierarchy'.",
    "estimated_token_reduction": "~1500 tokens per audit — eliminates manual tracing of method dispatch targets through struct hierarchies, currently requires gerbil_class_info + gerbil_module_exports + gerbil_eval to verify",
    "votes": 0
  },
  {
    "id": "ffi-buffer-size-audit",
    "title": "FFI buffer size audit — detect C functions writing more bytes than Scheme buffers allocate",
    "description": "A static analysis tool that cross-references c-declare C function output buffer sizes (from known API signatures or annotated array sizes like `byte out[96]`) against the Scheme-side make-u8vector allocations that provide those buffers. Detects cases where a C function writes N bytes but the Scheme wrapper allocates fewer than N bytes — a buffer overflow. Could parse #include headers for function signatures or accept size annotations. Reports: 'blst_p2_affine_serialize writes 192 bytes, but bytes<-blst-signature allocates 96-byte u8vector (line 250) — buffer overflow'.",
    "impact": "high",
    "tags": [
      "ffi",
      "buffer",
      "overflow",
      "size",
      "audit",
      "security",
      "u8vector",
      "make-u8vector"
    ],
    "use_case": "When reviewing FFI bindings for crypto libraries (blst, libsodium, libsecp256k1) or any C library that writes into caller-provided buffers. Buffer overflows in FFI are invisible at compile time and cause memory corruption at runtime.",
    "example_scenario": "In gerbil-crypto, blst_p1_affine_serialize writes 96 bytes (uncompressed G1) but the Scheme wrapper allocates a 48-byte u8vector. blst_p2_affine_serialize writes 192 bytes but gets a 96-byte buffer. These buffer overflows existed undetected because there were no BLS tests. Manual review required reading both the C header (blst.h) and the FFI shim to catch the mismatch. A dedicated tool could flag this instantly.",
    "estimated_token_reduction": "~3000 tokens per FFI module audit — eliminates manual cross-referencing of C API docs, c-declare shims, and Scheme buffer allocations across 3+ files",
    "votes": 0
  },
  {
    "id": "run-tests-clean-stale-artifacts",
    "title": "gerbil_run_tests should detect/clean stale compiled artifacts that conflict with source loading",
    "description": "When using gerbil_run_tests with file_path mode and GERBIL_LOADPATH pointing to source, stale compiled artifacts in .gerbil/lib/ or ~/.gerbil/lib/ can shadow the source files. This is especially problematic when a module exports `main` (for exe builds) — the compiled artifact's `(declare ...)` forms cause the test runner to invoke `main` instead of loading the test suite. The tool should either: (1) detect stale artifacts and warn, (2) offer a `clean` parameter to remove them before running, or (3) automatically check with gerbil_stale_static logic before test execution.",
    "impact": "medium",
    "tags": [
      "test",
      "stale",
      "artifacts",
      "clean",
      "compiled",
      "loadpath",
      "main"
    ],
    "use_case": "When running tests on a project that also builds executables. The exe module exports `main` and gets compiled with `(declare ...)` forms. Running gerbil_run_tests after a build picks up the compiled artifact, which triggers `main` invocation instead of test loading.",
    "example_scenario": "Project has es-proxy.ss (exports main for exe) and es-proxy-test.ss. After `gerbil build`, running gerbil_run_tests on es-proxy-test.ss with loadpath=[project-dir] fails with 'Missing argument remote-host' because it loads compiled es-proxy instead of source. Workaround: manually rm -rf .gerbil/lib/es-proxy ~/.gerbil/lib/es-proxy before testing. The Makefile does this, but gerbil_run_tests doesn't.",
    "estimated_token_reduction": "~500 tokens per failed test attempt — eliminates a round-trip of failure diagnosis + manual cleanup + retry",
    "votes": 0
  },
  {
    "id": "stack-trace-decode",
    "title": "Parse and decode full Gambit/Gerbil stack traces into readable form",
    "description": "A tool that takes a multi-line Gambit/Gerbil stack trace (from an exception, segfault, or GDB backtrace) and decodes it into readable function names with source file locations. Combines gerbil_demangle for C symbol names with source location lookup via gerbil_find_definition. Handles all Gambit stack trace formats: (1) Scheme-level exception traces with ##dynamic-env-bind chains, (2) GDB backtraces with ___H_ and ___G_ mangled names, (3) Gambit 'display-continuation-backtrace' output. Returns a structured table: frame number, demangled function name, source file, line number, and whether the frame is user code vs runtime.",
    "impact": "high",
    "tags": [
      "debug",
      "stack-trace",
      "backtrace",
      "demangle",
      "gdb",
      "exception",
      "crash"
    ],
    "use_case": "Every debugging session involving crashes, exceptions, or segfaults produces stack traces. Currently Claude must manually call gerbil_demangle on individual symbols and piece together the call chain. A single tool call should decode an entire trace.",
    "example_scenario": "User pastes a 30-line GDB backtrace from a segfaulting compiled binary with frames like '#0 ___H_gerbil_2f_crypto_2f_blst (0x7fff...) at blst.o2.c:142'. Currently requires 10+ gerbil_demangle calls to decode each frame, then manual gerbil_find_definition calls to locate source files. A stack-trace-decode tool would return: 'Frame 0: gerbil/crypto/blst (module init) at src/blst.ss:1, Frame 1: blst_p1_affine_serialize at blst-shim.c:42, ...' in one call.",
    "estimated_token_reduction": "~3000 tokens per debugging session — eliminates 10-20 sequential demangle + find_definition calls, plus manual correlation of frame addresses",
    "votes": 0
  },
  {
    "id": "tail-position-check",
    "title": "Verify that recursive calls in a function are in tail position",
    "description": "A static analysis tool that reads a function definition and checks whether recursive calls (direct or mutual) are in tail position. Reports each call site as 'tail' or 'non-tail' with the reason (e.g. 'wrapped in cons', 'inside let body but not tail expression', 'inside map callback'). This is fundamental to Scheme — non-tail-recursive functions will blow the stack on large inputs. The tool should handle: named let loops, letrec, match arms, cond/case branches, when/unless bodies, and the common trap of (cons (f x) acc) vs (f (cons x acc)). Could be implemented as AST analysis via gerbil_read_forms + gerbil_eval for expansion.",
    "impact": "high",
    "tags": [
      "tail-call",
      "recursion",
      "optimization",
      "stack-overflow",
      "static-analysis",
      "performance"
    ],
    "use_case": "When writing any recursive function in Gerbil. Claude frequently generates recursive code that looks correct but isn't tail-recursive, leading to stack overflows on inputs larger than ~10K elements. This is the #1 performance bug pattern in Scheme code.",
    "example_scenario": "Claude writes `(def (flatten lst) (match lst ([] []) ([hd . tl] (append (if (list? hd) (flatten hd) [hd]) (flatten tl)))))` — both recursive calls are non-tail (wrapped in append and if). A tail-position-check would flag both calls and suggest the accumulator pattern: `(def (flatten lst (acc [])) ...)`. Currently there's no way to verify tail position without manually tracing the AST or running with a huge input and seeing if it crashes.",
    "estimated_token_reduction": "~1000 tokens per function — eliminates trial-and-error testing for stack overflow, manual AST inspection, or running with large inputs to detect non-tail calls",
    "votes": 0
  },
  {
    "id": "module-quickstart",
    "title": "Generate a working example file that exercises a module's main exports",
    "description": "Given a module path (e.g. ':std/misc/concurrent-plan', ':std/parser', ':std/event'), generate a complete, runnable .ss file that imports the module and demonstrates its top 5-10 exports with realistic usage. Uses gerbil_module_exports to discover exports, gerbil_function_signature for arities, gerbil_doc for types, and gerbil_howto for any existing recipes. Verifies the generated code compiles via gerbil_check_syntax. This addresses the massive gap where hundreds of stdlib modules have zero documentation or recipes — especially :std/parser (11 modules, 0 recipes), :std/event (0 recipes), :std/web/fastcgi (0 recipes), :std/misc/concurrent-plan (0 recipes), :std/misc/shared (0 recipes), :std/misc/text (0 recipes).",
    "impact": "high",
    "tags": [
      "documentation",
      "example",
      "quickstart",
      "stdlib",
      "undocumented",
      "module",
      "tutorial"
    ],
    "use_case": "When working with any stdlib module that has no cookbook recipes. Currently Claude must call gerbil_module_exports, then gerbil_doc on each export, then guess at usage patterns, then verify with gerbil_eval — a 10+ tool call workflow. A single tool could generate a verified working example.",
    "example_scenario": "User asks 'how do I use :std/parser to parse a simple expression language?' Currently no recipes exist. Claude must: (1) gerbil_list_std_modules to find parser submodules, (2) gerbil_module_exports on each of 11 modules, (3) gerbil_doc on promising exports, (4) gerbil_eval to test patterns, (5) iterate until something works. A module-quickstart tool would generate a working parser example in one call, showing deflexer, defparser, and grammar usage.",
    "estimated_token_reduction": "~5000 tokens per undocumented module — eliminates the 10-15 tool call discovery workflow and trial-and-error testing for modules with no recipes",
    "votes": 0
  },
  {
    "id": "dynamic-reference-gen",
    "title": "Auto-generate reference documentation for any stdlib module on demand",
    "description": "Extends the MCP resource system beyond the 5 hardcoded reference docs (idioms, pattern-matching, actors, stdlib-map, gambit-interop) to dynamically generate reference documentation for ANY module. Given a module path, introspects all exports via gerbil_module_exports, classifies them (procedure/macro/value/type) via gerbil_doc, includes arities via gerbil_function_signature, pulls relevant cookbook recipes via gerbil_howto, and formats as a markdown reference page. Could be exposed as a parameterized MCP resource: gerbil://reference/module/{module-path}. This would make every module in Gerbil's stdlib instantly documented.",
    "impact": "high",
    "tags": [
      "reference",
      "documentation",
      "resource",
      "stdlib",
      "auto-generate",
      "module",
      "api-docs"
    ],
    "use_case": "Any time Claude needs to work with a module not covered by the 5 existing reference docs. Currently 95%+ of stdlib modules have no reference documentation, forcing Claude to make multiple tool calls to understand each module.",
    "example_scenario": "User asks about :std/db/dbi (database interface). No reference doc exists. Claude must call gerbil_module_exports (1 call), gerbil_doc on each of ~20 exports (20 calls), gerbil_function_signature on procedures (10+ calls). A dynamic reference resource would return a complete API reference page in one read, including all exports, types, arities, and related recipes.",
    "estimated_token_reduction": "~4000 tokens per module exploration — replaces 20-30 sequential tool calls with a single resource read",
    "votes": 0
  },
  {
    "id": "project-health-check",
    "title": "Composite project audit — run all quality checks in a single tool call",
    "description": "A single tool that runs the full battery of project quality checks and returns a unified report: (1) gerbil_lint on all .ss files, (2) gerbil_security_scan on the project, (3) gerbil_check_exports for cross-module consistency, (4) gerbil_dependency_cycles for circular imports, (5) gerbil_stale_static for stale build artifacts, (6) gerbil_stale_linked_pkg for outdated linked packages, (7) gerbil_dead_code for unused definitions, (8) gerbil_check_import_conflicts for symbol clashes. Returns a structured summary with issue counts by severity and category. Currently Claude must run each of these 8 tools sequentially, consuming 8 round-trips and ~4000 tokens of tool call overhead.",
    "impact": "high",
    "tags": [
      "audit",
      "quality",
      "lint",
      "security",
      "composite",
      "project",
      "health-check"
    ],
    "use_case": "Before committing, before a release, or when first encountering an unfamiliar project. A single 'how healthy is this project?' query that would otherwise require 8 sequential tool calls.",
    "example_scenario": "User says 'review this project for issues before I release it.' Currently Claude must sequentially run lint, security scan, check-exports, dependency-cycles, stale-static, stale-linked-pkg, dead-code, and check-import-conflicts — 8 tool calls, each waiting for the previous to complete. A project-health-check would return: '3 lint warnings, 1 security issue (medium), 2 dead code definitions, no circular deps, no stale artifacts, 1 import conflict' in one call.",
    "estimated_token_reduction": "~4000 tokens per audit — eliminates 8 sequential tool calls and their individual result parsing, consolidates into a single structured report",
    "votes": 0
  },
  {
    "id": "interface-compliance-check",
    "title": "Verify that a struct/class implements all methods required by an interface",
    "description": "Given a struct type and an interface definition, check whether the struct (directly or through inheritance) provides implementations for all required methods. Reports missing methods, wrong arities, and type mismatches. Combines gerbil_class_info (for the type's slot list and precedence), gerbil_module_exports (for what methods exist), and gerbil_function_signature (for arity verification). Also checks that method dispatch `{method-name obj}` calls will succeed at runtime by verifying the method exists in the type's effective method table.",
    "impact": "medium",
    "tags": [
      "interface",
      "compliance",
      "struct",
      "class",
      "method",
      "type-check",
      "contract"
    ],
    "use_case": "When implementing interfaces (definterface) or when using method dispatch on structs from external modules. Silent method dispatch failures are a common source of bugs in Gerbil OOP code.",
    "example_scenario": "User defines (definterface Closeable (close)) and implements a struct that wraps a DBI connection. They call {close wrapper} but the inner connection type doesn't have a close method — it uses sql-close. Currently this bug is invisible until runtime. An interface-compliance-check would flag: 'connection::t does not implement Closeable — missing method: close. Did you mean sql-close?'",
    "estimated_token_reduction": "~1500 tokens per type check — eliminates manual gerbil_class_info + gerbil_module_exports + gerbil_eval verification chain",
    "votes": 0
  },
  {
    "id": "return-type-analysis",
    "title": "Analyze what types/values a function can return across all code paths",
    "description": "Static analysis tool that traces all return paths through a function definition and reports the possible return types. Catches the extremely common Gerbil gotchas: (1) hash-ref returning #!void (truthy!) for missing keys, (2) when/unless returning #<void> instead of #f, (3) match with incomplete patterns returning nothing, (4) string-contains returning an index (integer) not #t, (5) functions that sometimes return a value and sometimes return void. Reports each code path with its return type. Would catch bugs like using (when ...) as a boolean-returning predicate, or assuming hash-ref returns #f for missing keys.",
    "impact": "high",
    "tags": [
      "type",
      "return-value",
      "void",
      "static-analysis",
      "gotcha",
      "hash-ref",
      "when",
      "predicate"
    ],
    "use_case": "When writing conditional logic that depends on return values. Gerbil has many functions whose return types are surprising (#!void is truthy, string-contains returns index, hash-ref returns #!void not #f). These account for ~15% of the gotcha recipes in the cookbook.",
    "example_scenario": "Claude writes: `(if (hash-ref config key) (process config) (use-default))` — this never reaches use-default because hash-ref returns #!void (truthy!) for missing keys. Currently the only way to catch this is to already know the gotcha (from cookbook) or discover it at runtime. A return-type-analysis tool would flag: 'hash-ref returns #!void for missing keys (truthy) — did you mean hash-get which returns #f?'",
    "estimated_token_reduction": "~800 tokens per function — prevents a debug round-trip (write buggy code → test → discover wrong return type → fix → retest)",
    "votes": 0
  },
  {
    "id": "httpd-handler-scaffold",
    "title": "Generate HTTP server handler skeleton from route specifications",
    "description": "Given a list of route specifications (method, path pattern, handler name), generate a complete :std/net/httpd server setup with proper imports, handler functions, request parsing, JSON response helpers, error handling, and graceful shutdown. The :std/net/httpd module is poorly documented — the stdlib map mentions it but there are zero cookbook recipes for server-side HTTP. This tool would generate working server code that handles: routing, path parameters, query strings, JSON request/response, CORS headers, and error responses.",
    "impact": "medium",
    "tags": [
      "httpd",
      "http",
      "server",
      "handler",
      "routing",
      "scaffold",
      "web",
      "api"
    ],
    "use_case": "When building HTTP APIs or web services in Gerbil. Currently Claude must guess at httpd patterns since there are no recipes or reference docs for server-side HTTP beyond the stdlib-map table entry.",
    "example_scenario": "User asks 'create a REST API with GET /users, POST /users, GET /users/:id'. Currently Claude has no recipes for httpd handler patterns and must discover the API via gerbil_module_exports + gerbil_eval trial-and-error. A scaffold tool would generate a working server with proper handler registration, request parsing, and JSON responses.",
    "estimated_token_reduction": "~3000 tokens per HTTP service — eliminates discovery workflow for undocumented httpd API and prevents common mistakes in handler registration",
    "votes": 0
  },
  {
    "id": "parser-grammar-scaffold",
    "title": "Generate LL(1) parser from grammar specification using :std/parser",
    "description": "Given a simple grammar specification (BNF-like or example input), generate a working parser using Gerbil's :std/parser subsystem (deflexer, defparser, grammar modules). The parser subsystem has 11 modules (parser, parser/base, parser/deflexer, parser/defparser, parser/grammar, parser/grammar-reader, parser/lexer, parser/ll1, parser/rlang, parser/rx-parser, parser/stream) but ZERO cookbook recipes and ZERO reference documentation. This is an entire language tooling subsystem that's completely opaque to Claude. The tool would generate a complete parser with lexer rules, grammar productions, and AST construction.",
    "impact": "medium",
    "tags": [
      "parser",
      "grammar",
      "lexer",
      "scaffold",
      "ll1",
      "deflexer",
      "defparser",
      "dsl"
    ],
    "use_case": "When building domain-specific languages, configuration file parsers, protocol parsers, or any text processing that needs structured parsing beyond regex. The :std/parser module is powerful but completely undocumented.",
    "example_scenario": "User asks 'parse a simple arithmetic expression language (1 + 2 * 3)'. Currently Claude has no idea how deflexer/defparser work — no recipes, no reference docs, no examples. Must make 15+ tool calls to discover the API: list_std_modules, module_exports on 11 submodules, doc on each export, eval to test patterns. A parser scaffold would generate working lexer + parser + evaluator in one call.",
    "estimated_token_reduction": "~5000 tokens per parser — eliminates the complete discovery workflow for an 11-module subsystem with zero documentation",
    "votes": 0
  },
  {
    "id": "actor-ensemble-scaffold",
    "title": "Scaffold a distributed actor ensemble project with supervisor tree",
    "description": "Generate a complete actor ensemble project template using gxensemble (14+ modules: admin, api, connection, cookie, ensemble-config, ensemble-server, ensemble-supervisor, executor, filesystem, io, loader, logger, message, proto, registry, server, supervisor, tls). The ensemble system is Gerbil's distributed computing framework but has ZERO recipes, ZERO reference docs, and ZERO tool support. This scaffold would generate: actor protocol definitions, message types, supervisor tree, TLS configuration, ensemble config, and a working example with at least two actors communicating across processes.",
    "impact": "medium",
    "tags": [
      "actor",
      "ensemble",
      "distributed",
      "supervisor",
      "scaffold",
      "gxensemble",
      "tls",
      "protocol"
    ],
    "use_case": "When building distributed systems with Gerbil's actor ensemble. This is Gerbil's unique selling point (Erlang-like distributed actors) but it's completely undocumented for AI assistants.",
    "example_scenario": "User asks 'build a distributed key-value store with Gerbil actors'. Currently Claude has no idea how gxensemble works — the 14 submodules are completely opaque. Must discover everything from scratch via module_exports on each submodule. A scaffold would generate a working 2-node ensemble with supervisor, protocol defs, and TLS config.",
    "estimated_token_reduction": "~6000 tokens per distributed project — eliminates the discovery of 14 undocumented modules and prevents the many configuration pitfalls in ensemble setup",
    "votes": 0
  },
  {
    "id": "event-system-guide",
    "title": "Interactive exploration tool for :std/event (sync, select, event sources)",
    "description": "A specialized tool for Gerbil's event system (:std/event) that explains and demonstrates event-based programming: sync, select, choice, wrap, handle, and event source creation. The event system is central to Gerbil's concurrency model (it underlies channels, actors, and I/O multiplexing) but has only 1 basic cookbook recipe and no reference documentation. The tool would: (1) list available event combinators with usage examples, (2) show how to create custom event sources, (3) demonstrate sync/select patterns with timeouts, (4) explain the relationship between events, channels, and actors.",
    "impact": "medium",
    "tags": [
      "event",
      "sync",
      "select",
      "concurrent",
      "channel",
      "actor",
      "io-multiplexing"
    ],
    "use_case": "When building reactive or event-driven systems. The event system is the foundation of Gerbil's concurrency but Claude doesn't understand how sync/select/wrap/handle work together.",
    "example_scenario": "User asks 'wait for either a channel message or a timeout, whichever comes first'. This is a basic event-system pattern (select with timeout) but Claude has no recipes for it. Must discover sync, wrap, handle from module_exports and guess at usage. An event-system tool would show the idiomatic pattern: (sync (choice (wrap (recv ch) handle-msg) (wrap (alarm timeout-ms) handle-timeout))).",
    "estimated_token_reduction": "~2000 tokens per event pattern — eliminates discovery of undocumented event combinators and prevents incorrect usage of sync/select",
    "votes": 0
  },
  {
    "id": "macro-hygiene-check",
    "title": "Detect variable capture and hygiene violations in macro definitions",
    "description": "Static analysis tool that checks macro definitions (defrules, syntax-case, syntax-rules) for common hygiene violations: (1) unintended variable capture — using a free variable that could shadow a user's binding, (2) missing datum->syntax conversions, (3) template variables used outside their pattern scope, (4) ellipsis misuse in templates, (5) syntax-rules patterns that overlap (ambiguous matching). Reports each issue with the specific variable or pattern and a suggested fix. Would also detect the common mistake of using `def` inside a macro expansion that lands in expression context (where `let` is required).",
    "impact": "medium",
    "tags": [
      "macro",
      "hygiene",
      "syntax-case",
      "defrules",
      "capture",
      "variable",
      "static-analysis"
    ],
    "use_case": "When writing macros in Gerbil. Macro hygiene bugs are notoriously hard to debug — they manifest as mysterious 'unbound identifier' or 'bad syntax' errors at use sites, not at the macro definition. Claude frequently generates macros with subtle hygiene issues.",
    "example_scenario": "Claude writes a defrules macro that internally uses a variable named `result` — this captures any user binding also named `result`. Or a syntax-case macro that forgets datum->syntax when constructing identifiers. Currently the only way to detect these is to test the macro in various contexts and observe failures. A hygiene-check would flag: 'WARNING: free variable `result` in template could capture user bindings — use (generate-temporary) or with-syntax to introduce a fresh binding'.",
    "estimated_token_reduction": "~1500 tokens per macro — prevents the debug cycle of macro-works-in-simple-case but fails-in-real-use",
    "votes": 0
  },
  {
    "id": "concurrent-plan-validate",
    "title": "Validate :std/misc/concurrent-plan DAG execution plans",
    "description": "A tool for the completely undocumented :std/misc/concurrent-plan module. Given a concurrent-plan definition, validates: (1) all dependencies reference existing plan steps, (2) no circular dependencies, (3) all leaf steps have implementations, (4) estimates parallelism degree (max concurrent steps). The concurrent-plan module enables DAG-based parallel task execution — defining steps with dependencies and letting the runtime figure out what can run in parallel. But with 0 recipes and 0 docs, Claude can't help users with it at all.",
    "impact": "low",
    "tags": [
      "concurrent-plan",
      "dag",
      "parallel",
      "validation",
      "dependency",
      "workflow"
    ],
    "use_case": "When building complex multi-step workflows where steps have dependencies and should run in parallel where possible. Similar to Make dependency graphs or CI pipeline DAGs.",
    "example_scenario": "User wants to build a data pipeline: fetch from 3 APIs in parallel, merge results, then transform and store. concurrent-plan is the right tool but Claude has no idea how to use it. A validate tool would at minimum teach Claude the API by providing working examples and validating user-defined plans.",
    "estimated_token_reduction": "~2000 tokens per plan — eliminates discovery of undocumented module and prevents invalid plan definitions",
    "votes": 0
  },
  {
    "id": "test-fixture-gen",
    "title": "Generate test fixtures and mock modules for :std/test",
    "description": "Given a module's exports, generate a mock/stub module that provides fake implementations suitable for testing. For procedures: generate functions that return sensible defaults or configurable return values. For types: generate factory functions that create test instances with default field values. For I/O operations: generate in-memory replacements (string ports, hash-table-backed 'databases'). Also generate test fixture setup/teardown patterns with parameterize for dependency injection. Currently there are no testing patterns beyond basic check/check-equal in the cookbook — no mocking, no fixtures, no dependency injection recipes.",
    "impact": "medium",
    "tags": [
      "test",
      "mock",
      "stub",
      "fixture",
      "testing",
      "dependency-injection",
      "parameterize"
    ],
    "use_case": "When writing tests for code that depends on external services (databases, HTTP APIs, file system). Gerbil's parameterize system is ideal for dependency injection but there are no recipes showing the pattern.",
    "example_scenario": "User wants to test a function that calls sql-exec and http-get. Currently no Gerbil mocking patterns exist in the cookbook. Claude must invent patterns from scratch. A test-fixture-gen would generate: (1) a mock-db module using hash tables instead of SQL, (2) a mock-http module returning canned responses, (3) a test-setup function using parameterize to inject mocks.",
    "estimated_token_reduction": "~2000 tokens per test module — eliminates inventing mock patterns from scratch and prevents common testing anti-patterns",
    "votes": 0
  },
  {
    "id": "db-pattern-scaffold",
    "title": "Generate database access patterns with connection pooling, transactions, and error handling",
    "description": "Given a database type (sqlite or postgresql) and a schema description, generate a complete data access layer with: (1) connection pool setup (:std/db/conpool), (2) transaction wrappers with rollback on error, (3) prepared statement patterns, (4) CRUD operations for each table, (5) proper resource cleanup with unwind-protect. Database access in Gerbil has :std/db/dbi, :std/db/sqlite, :std/db/postgresql, and :std/db/conpool — but there are only 2 basic cookbook recipes (sqlite-database-operations, postgresql-database-queries). No recipes for connection pooling, transactions, error recovery, or prepared statements.",
    "impact": "medium",
    "tags": [
      "database",
      "sqlite",
      "postgresql",
      "connection-pool",
      "transaction",
      "dbi",
      "conpool",
      "crud"
    ],
    "use_case": "When building any application that persists data. Database access is a fundamental need but barely documented in Gerbil — only basic query patterns exist.",
    "example_scenario": "User asks 'create a user management system with SQLite'. Claude has 1 basic SQLite recipe but doesn't know connection pooling, transaction patterns, or error handling for DBI. Must discover conpool API from scratch (0 recipes). A scaffold would generate a complete data access layer with pooled connections, transactional writes, and proper cleanup.",
    "estimated_token_reduction": "~3000 tokens per database module — eliminates discovery of conpool API and prevents common resource leak patterns (unclosed connections, uncommitted transactions)",
    "votes": 0
  },
  {
    "id": "graceful-shutdown-scaffold",
    "title": "Generate graceful shutdown patterns for long-running Gerbil services",
    "description": "Generate a complete graceful shutdown framework for Gerbil services: (1) signal handler registration (SIGTERM, SIGINT, SIGHUP), (2) shutdown coordination across threads/actors, (3) drain in-flight requests (HTTP, actor messages), (4) close database connections and file handles, (5) flush logs, (6) exit with proper status code. Uses :std/os/signal-handler, mutex/condition synchronization, and unwind-protect cleanup. Currently there are 2 basic signal handler recipes but no patterns for coordinated multi-component shutdown — the #1 gap for production Gerbil services.",
    "impact": "medium",
    "tags": [
      "shutdown",
      "signal",
      "graceful",
      "production",
      "service",
      "sigterm",
      "cleanup",
      "deployment"
    ],
    "use_case": "When building any long-running Gerbil service (HTTP server, actor system, background worker). Proper shutdown is critical for production but completely undocumented.",
    "example_scenario": "User deploys a Gerbil HTTP server + background worker. Sending SIGTERM should: stop accepting new HTTP requests, drain in-flight requests, stop the worker after its current task, close DB connections, flush logs, then exit(0). Currently Claude has no pattern for this — only basic signal handler registration. A scaffold would generate the full shutdown coordinator.",
    "estimated_token_reduction": "~2000 tokens per service — prevents reinventing the shutdown coordination pattern and avoids common pitfalls (race conditions during shutdown, leaked resources, signal handler re-entrancy)",
    "votes": 0
  }
]
