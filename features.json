[
  {
    "id": "gerbil-aws-namespace-validator",
    "title": "Tool to check gerbil-aws client namespace configuration",
    "description": "A tool that takes a gerbil-aws client expression (e.g., AWSClient or AWSJsonClient creation code) and validates that the namespace configuration will produce correct key names in parsed responses. It would check if the service's known namespace URI is mapped, and warn if strip-ns would produce incorrect results. Could also test a live API call and show the actual response keys vs expected keys.",
    "impact": "medium",
    "tags": [
      "gerbil-aws",
      "namespace",
      "XML",
      "validation",
      "strip-ns"
    ],
    "use_case": "When setting up a new gerbil-aws client for a Query API service (STS, RDS, ELBv2, etc.), validate that namespace mappings are correct before writing code that depends on specific response key names.",
    "example_scenario": "User creates an STSClient without namespace mappings. Tool warns that STS namespace URI 'https://sts.amazonaws.com/doc/2011-06-15/' is not mapped, and strip-ns will produce broken keys like '//sts.amazonaws.com/doc/2011-06-15/:Account instead of 'Account.",
    "estimated_token_reduction": "~500-1000 tokens per debugging session. Eliminates multi-step diagnosis: eval call → inspect response → trace through strip-ns → identify namespace issue."
  },
  {
    "id": "test-affected-by-signature-change",
    "title": "Detect test files affected by function signature changes",
    "description": "A tool that, given a function name and its module path, finds all test files that directly call that function and reports whether their call sites match the current arity. When a function's parameter list changes (e.g., adding a new required parameter), all test call sites break silently — they compile fine but fail at runtime with \"Wrong number of arguments\". This tool would scan test/*.ss files for calls to the function and compare call-site arity against the module's current exported signature.",
    "impact": "medium",
    "tags": [
      "test",
      "arity",
      "signature",
      "refactor",
      "breaking-change"
    ],
    "use_case": "After modifying a function signature (adding/removing parameters), quickly find which test files need updating before running the full test suite.",
    "example_scenario": "User adds a 'regions' parameter to find-edits-in-line. The function compiles fine, but test/rename-test.ss calls it with the old 7-arg signature. Running all tests fails at runtime with 'Wrong number of arguments'. This tool would immediately flag: 'test/rename-test.ss:15 calls find-edits-in-line with 7 args, expected 8'.",
    "estimated_token_reduction": "~300-500 tokens per refactoring. Eliminates the round-trip of running tests, reading error output, finding the test file, reading it, and updating call sites."
  },
  {
    "id": "lsp-message-validator",
    "title": "Validate LSP JSON-RPC messages against protocol spec",
    "description": "A tool that parses LSP JSON-RPC messages and validates them against the Language Server Protocol specification. Would check: required fields present, correct types for each field, valid method names, proper Content-Length framing. Could work on raw message strings or hash tables representing messages. Would report specific violations with the LSP spec reference.",
    "impact": "medium",
    "tags": [
      "lsp",
      "json-rpc",
      "validation",
      "protocol",
      "debug"
    ],
    "use_case": "When implementing or debugging an LSP server, validating that generated responses conform to the protocol spec without needing to test with a real editor client.",
    "example_scenario": "User implements a new LSP handler and wants to verify the response structure is correct. Currently they must manually compare against the LSP spec or wait for editor errors. This tool would immediately flag: 'textDocument/completion response missing required field: isIncomplete'.",
    "estimated_token_reduction": "~300-500 tokens per handler implementation. Eliminates back-and-forth with editor clients to debug protocol issues."
  },
  {
    "id": "swagger-to-gerbil-scaffold",
    "title": "Generate Gerbil REST API client from Swagger/OpenAPI spec",
    "description": "A tool that reads a Swagger/OpenAPI JSON spec and generates Gerbil Scheme source code for a REST API client. For each endpoint, it would generate a function with the correct path, HTTP method, path parameters, query parameters, and request body structure. This would dramatically accelerate building API clients like gerbil-jira, where the Jira API has 597 endpoints across 97 groups. Currently, each endpoint must be manually translated from the spec to Scheme code, which is tedious and error-prone.",
    "impact": "high",
    "tags": [
      "swagger",
      "openapi",
      "api",
      "client",
      "scaffold",
      "generate",
      "rest"
    ],
    "use_case": "When building a Gerbil REST API client for a service that publishes a Swagger/OpenAPI spec (Jira, GitHub, AWS, etc.), generate the boilerplate API functions automatically instead of hand-coding each endpoint.",
    "example_scenario": "User has a swagger-v3.json with 597 Jira endpoints. They call gerbil_swagger_scaffold with the spec path and output directory. The tool generates Gerbil source files grouped by API tag (issues.ss, projects.ss, etc.) with a function per endpoint, correct parameter names, and proper HTTP method calls. The user then just needs to add formatting/CLI logic on top.",
    "estimated_token_reduction": "~10000+ tokens per API client project. Eliminates manually reading the spec and translating hundreds of endpoints to Scheme functions."
  },
  {
    "id": "ffi-binding-scaffold",
    "title": "Generate FFI bindings from C header files",
    "description": "A tool that parses a C header file and generates Gambit FFI binding code (.scm file with c-declare, c-define-type, c-lambda declarations). It would recognize common patterns: opaque pointer types, create/destroy function pairs (for automatic cleanup), and simple function signatures. This would dramatically accelerate creating Gerbil bindings for C libraries like LevelDB, SQLite, etc.",
    "impact": "high",
    "tags": [
      "ffi",
      "c-header",
      "scaffold",
      "generate",
      "binding",
      "gambit"
    ],
    "use_case": "When creating Gerbil FFI bindings for a C library, generate the boilerplate c-define-type and c-lambda declarations from the header file instead of manually translating each typedef and function signature.",
    "example_scenario": "User wants to bind libleveldb. They point the tool at leveldb/c.h. It generates: c-define-type declarations for all opaque types (leveldb_t, leveldb_options_t, etc.), c-lambda bindings for all functions, and cleanup functions for types that have corresponding _destroy functions. User then just needs to add the Gerbil wrapper layer.",
    "estimated_token_reduction": "~5000+ tokens per FFI project. Eliminates manually reading C headers, figuring out type mappings, and writing repetitive c-lambda declarations."
  },
  {
    "id": "ffi-callback-debugger",
    "title": "Debug FFI callback linkage issues",
    "description": "A diagnostic tool that checks whether c-define callbacks are correctly linked and callable from C code. It would verify: (1) the c-define generates a properly named C function, (2) extern declarations match c-define signatures, (3) the Scheme runtime is properly initialized before callbacks can fire. Currently, c-define callbacks that fail just hang or crash with no useful error message.",
    "impact": "medium",
    "tags": [
      "ffi",
      "c-define",
      "callback",
      "debug",
      "diagnostic"
    ],
    "use_case": "When implementing C-to-Scheme callbacks (e.g., for comparators, event handlers), diagnose why the callback hangs or crashes instead of guessing through trial and error.",
    "example_scenario": "User implements a LevelDB comparator using c-define callbacks. When LevelDB calls the compare callback, the process hangs. The diagnostic tool would show: 'c-define scm_comparator_compare_cb exists but calling it blocks - Scheme runtime may not be in correct state for callbacks from this C context'.",
    "estimated_token_reduction": "~1000 tokens per callback debugging session. Eliminates trial-and-error approach to diagnosing why callbacks don't work."
  },
  {
    "id": "compile-safe-howto-recipes",
    "title": "Flag cookbook recipes that use REPL-only patterns",
    "description": "Several existing cookbook recipes show patterns that work in the REPL (gxi) but fail when compiled with gxc. For example, the 'iterate-hash' recipe shows (for ((k v) (in-hash ht)) ...) and the 'for-collect' recipe shows (for/collect ((x i) (in-indexed ...)) ...) — both use destructuring in for bindings that causes 'Reference to unbound identifier' errors during compilation. The howto_verify tool only checks syntax expansion, not gxc compilation, so these recipes pass verification despite being broken for compiled code. Either: (1) Add a 'compile_check: true' flag to recipes and verify them with gxc instead of just the expander, or (2) Add a 'repl_only: true' metadata field to flag patterns that only work interactively.",
    "impact": "high",
    "tags": [
      "cookbook",
      "compile",
      "repl",
      "gxc",
      "verification"
    ],
    "use_case": "When generating code that will be compiled (e.g., code generators, project scaffolding), cookbook recipes are used as reference patterns. If the recipe uses a REPL-only pattern, the generated code will fail to compile, requiring debugging and workarounds.",
    "example_scenario": "Code generator emits (for ((k v) (in-hash data)) ...) based on the iterate-hash cookbook recipe. The generated project fails to build with 'unbound identifier: v'. Developer spends 500+ tokens debugging before discovering the REPL-vs-compiler divergence and rewriting with (for (kv (in-hash data)) (let ((k (car kv)) (v (cdr kv))) ...)).",
    "estimated_token_reduction": "~500-1000 tokens per incident. Prevents debugging sessions caused by copying REPL-only patterns into compiled code."
  },
  {
    "id": "build-auto-chmod-build-ss",
    "title": "Auto-detect and report non-executable build.ss in gerbil_build_and_report",
    "description": "When gerbil_build_and_report fails with \"Permission denied\", the tool should check if build.ss exists but lacks the executable bit, and report a clear diagnostic message like \"build.ss is not executable — run chmod +x build.ss\" instead of the generic error. This is a very common issue when creating new Gerbil projects.",
    "impact": "medium",
    "tags": [
      "build",
      "permission",
      "chmod",
      "build.ss",
      "diagnostic"
    ],
    "use_case": "When creating a new Gerbil project, the build.ss file is often created without the executable bit. The current error message is cryptic: \"Permission denied\" buried in a subprocess error chain.",
    "example_scenario": "User creates a new project and writes build.ss. Runs gerbil_build_and_report. Gets \"1 error: Permission denied\" with no indication that chmod +x is needed. Has to manually debug the file permissions.",
    "estimated_token_reduction": "~200 tokens per occurrence — eliminates a round-trip of debugging and running chmod manually"
  }
]
