[
  {
    "id": "gerbil-aws-namespace-validator",
    "title": "Tool to check gerbil-aws client namespace configuration",
    "description": "A tool that takes a gerbil-aws client expression (e.g., AWSClient or AWSJsonClient creation code) and validates that the namespace configuration will produce correct key names in parsed responses. It would check if the service's known namespace URI is mapped, and warn if strip-ns would produce incorrect results. Could also test a live API call and show the actual response keys vs expected keys.",
    "impact": "medium",
    "tags": [
      "gerbil-aws",
      "namespace",
      "XML",
      "validation",
      "strip-ns"
    ],
    "use_case": "When setting up a new gerbil-aws client for a Query API service (STS, RDS, ELBv2, etc.), validate that namespace mappings are correct before writing code that depends on specific response key names.",
    "example_scenario": "User creates an STSClient without namespace mappings. Tool warns that STS namespace URI 'https://sts.amazonaws.com/doc/2011-06-15/' is not mapped, and strip-ns will produce broken keys like '//sts.amazonaws.com/doc/2011-06-15/:Account instead of 'Account.",
    "estimated_token_reduction": "~500-1000 tokens per debugging session. Eliminates multi-step diagnosis: eval call → inspect response → trace through strip-ns → identify namespace issue."
  },
  {
    "id": "test-affected-by-signature-change",
    "title": "Detect test files affected by function signature changes",
    "description": "A tool that, given a function name and its module path, finds all test files that directly call that function and reports whether their call sites match the current arity. When a function's parameter list changes (e.g., adding a new required parameter), all test call sites break silently — they compile fine but fail at runtime with \"Wrong number of arguments\". This tool would scan test/*.ss files for calls to the function and compare call-site arity against the module's current exported signature.",
    "impact": "medium",
    "tags": [
      "test",
      "arity",
      "signature",
      "refactor",
      "breaking-change"
    ],
    "use_case": "After modifying a function signature (adding/removing parameters), quickly find which test files need updating before running the full test suite.",
    "example_scenario": "User adds a 'regions' parameter to find-edits-in-line. The function compiles fine, but test/rename-test.ss calls it with the old 7-arg signature. Running all tests fails at runtime with 'Wrong number of arguments'. This tool would immediately flag: 'test/rename-test.ss:15 calls find-edits-in-line with 7 args, expected 8'.",
    "estimated_token_reduction": "~300-500 tokens per refactoring. Eliminates the round-trip of running tests, reading error output, finding the test file, reading it, and updating call sites."
  },
  {
    "id": "lsp-message-validator",
    "title": "Validate LSP JSON-RPC messages against protocol spec",
    "description": "A tool that parses LSP JSON-RPC messages and validates them against the Language Server Protocol specification. Would check: required fields present, correct types for each field, valid method names, proper Content-Length framing. Could work on raw message strings or hash tables representing messages. Would report specific violations with the LSP spec reference.",
    "impact": "medium",
    "tags": [
      "lsp",
      "json-rpc",
      "validation",
      "protocol",
      "debug"
    ],
    "use_case": "When implementing or debugging an LSP server, validating that generated responses conform to the protocol spec without needing to test with a real editor client.",
    "example_scenario": "User implements a new LSP handler and wants to verify the response structure is correct. Currently they must manually compare against the LSP spec or wait for editor errors. This tool would immediately flag: 'textDocument/completion response missing required field: isIncomplete'.",
    "estimated_token_reduction": "~300-500 tokens per handler implementation. Eliminates back-and-forth with editor clients to debug protocol issues."
  },
  {
    "id": "module-exports-declare-workaround",
    "title": "gerbil_module_exports should handle modules with (declare ...) forms",
    "description": "gerbil_module_exports fails on modules that use Gambit's (declare (block) (standard-bindings) (extended-bindings) ...) form. The error is a Syntax Error: \"Bad syntax; illegal expression\" during expansion. This affects modules like :ober/oberlib and likely other packages that use Gambit performance declarations. The tool should either handle these declarations gracefully or fall back to scanning the compiled .scm files for exported symbols.",
    "impact": "medium",
    "tags": [
      "module",
      "exports",
      "declare",
      "gambit",
      "introspection"
    ],
    "use_case": "When trying to introspect third-party modules (like oberlib) that use Gambit-specific (declare ...) forms to check what functions they export.",
    "example_scenario": "User calls gerbil_module_exports with module_path ':ober/oberlib'. The tool fails with: Syntax Error: Bad syntax; illegal expression — (declare (block) (standard-bindings) (extended-bindings) (inlining-limit 200)). The user must fall back to manually grepping compiled .scm files in .gerbil/lib/static/ to find exported symbols, which is tedious and error-prone.",
    "estimated_token_reduction": "~500-1000 tokens per session where a (declare)-using module needs introspection. Eliminates manual grep + read of compiled artifacts."
  },
  {
    "id": "swagger-to-gerbil-scaffold",
    "title": "Generate Gerbil REST API client from Swagger/OpenAPI spec",
    "description": "A tool that reads a Swagger/OpenAPI JSON spec and generates Gerbil Scheme source code for a REST API client. For each endpoint, it would generate a function with the correct path, HTTP method, path parameters, query parameters, and request body structure. This would dramatically accelerate building API clients like gerbil-jira, where the Jira API has 597 endpoints across 97 groups. Currently, each endpoint must be manually translated from the spec to Scheme code, which is tedious and error-prone.",
    "impact": "high",
    "tags": [
      "swagger",
      "openapi",
      "api",
      "client",
      "scaffold",
      "generate",
      "rest"
    ],
    "use_case": "When building a Gerbil REST API client for a service that publishes a Swagger/OpenAPI spec (Jira, GitHub, AWS, etc.), generate the boilerplate API functions automatically instead of hand-coding each endpoint.",
    "example_scenario": "User has a swagger-v3.json with 597 Jira endpoints. They call gerbil_swagger_scaffold with the spec path and output directory. The tool generates Gerbil source files grouped by API tag (issues.ss, projects.ss, etc.) with a function per endpoint, correct parameter names, and proper HTTP method calls. The user then just needs to add formatting/CLI logic on top.",
    "estimated_token_reduction": "~10000+ tokens per API client project. Eliminates manually reading the spec and translating hundreds of endpoints to Scheme functions."
  },
  {
    "id": "ffi-binding-scaffold",
    "title": "Generate FFI bindings from C header files",
    "description": "A tool that parses a C header file and generates Gambit FFI binding code (.scm file with c-declare, c-define-type, c-lambda declarations). It would recognize common patterns: opaque pointer types, create/destroy function pairs (for automatic cleanup), and simple function signatures. This would dramatically accelerate creating Gerbil bindings for C libraries like LevelDB, SQLite, etc.",
    "impact": "high",
    "tags": [
      "ffi",
      "c-header",
      "scaffold",
      "generate",
      "binding",
      "gambit"
    ],
    "use_case": "When creating Gerbil FFI bindings for a C library, generate the boilerplate c-define-type and c-lambda declarations from the header file instead of manually translating each typedef and function signature.",
    "example_scenario": "User wants to bind libleveldb. They point the tool at leveldb/c.h. It generates: c-define-type declarations for all opaque types (leveldb_t, leveldb_options_t, etc.), c-lambda bindings for all functions, and cleanup functions for types that have corresponding _destroy functions. User then just needs to add the Gerbil wrapper layer.",
    "estimated_token_reduction": "~5000+ tokens per FFI project. Eliminates manually reading C headers, figuring out type mappings, and writing repetitive c-lambda declarations."
  },
  {
    "id": "ffi-callback-debugger",
    "title": "Debug FFI callback linkage issues",
    "description": "A diagnostic tool that checks whether c-define callbacks are correctly linked and callable from C code. It would verify: (1) the c-define generates a properly named C function, (2) extern declarations match c-define signatures, (3) the Scheme runtime is properly initialized before callbacks can fire. Currently, c-define callbacks that fail just hang or crash with no useful error message.",
    "impact": "medium",
    "tags": [
      "ffi",
      "c-define",
      "callback",
      "debug",
      "diagnostic"
    ],
    "use_case": "When implementing C-to-Scheme callbacks (e.g., for comparators, event handlers), diagnose why the callback hangs or crashes instead of guessing through trial and error.",
    "example_scenario": "User implements a LevelDB comparator using c-define callbacks. When LevelDB calls the compare callback, the process hangs. The diagnostic tool would show: 'c-define scm_comparator_compare_cb exists but calling it blocks - Scheme runtime may not be in correct state for callbacks from this C context'.",
    "estimated_token_reduction": "~1000 tokens per callback debugging session. Eliminates trial-and-error approach to diagnosing why callbacks don't work."
  },
  {
    "id": "safe-package-manage-cwd",
    "title": "gerbil_package_manage should default to safe CWD to prevent project destruction",
    "description": "The gerbil_package_manage tool currently inherits the working directory of the MCP server process. When the user is working in a project directory that has gerbil.pkg + .gerbil/, gxpkg's setup-local-pkg-env! sets GERBIL_PATH to the local .gerbil/, causing install/uninstall operations to operate on the local package context. This can result in the entire project directory being wiped (rm -rf during clean/uninstall). The tool should default its CWD to $HOME (or a temp directory) unless the user explicitly provides a cwd parameter, to prevent this destructive behavior. Alternatively, it could detect when CWD contains gerbil.pkg and warn/refuse unless --global-env is explicitly requested.",
    "impact": "high",
    "tags": [
      "package",
      "install",
      "safety",
      "cwd",
      "destructive"
    ],
    "use_case": "Any time gerbil_package_manage is called while working in a project directory. This is the common case since MCP tools inherit the project's working directory.",
    "example_scenario": "User is working in /home/user/project/ which has gerbil.pkg and .gerbil/. They call gerbil_package_manage to install a dependency. The tool runs `gerbil pkg install` from /home/user/project/, which triggers setup-local-pkg-env! setting GERBIL_PATH=./.gerbil. The subsequent clean/build/uninstall operations destroy project files including source code and .git directory.",
    "estimated_token_reduction": "Prevents catastrophic data loss. Saves ~5000+ tokens recovering from the disaster (re-cloning, re-reading files, re-applying changes)."
  },
  {
    "id": "build-and-report-auto-loadpath",
    "title": "gerbil_build_and_report should auto-detect and set GERBIL_LOADPATH from gerbil.pkg depend:",
    "description": "When gerbil_build_and_report is used on a project that has external dependencies declared in gerbil.pkg depend:, the build fails with 'cannot find library module' unless GERBIL_LOADPATH is manually passed. The tool could auto-detect gerbil.pkg depend: entries, check that packages are installed in ~/.gerbil/pkg/, and automatically add ~/.gerbil/lib to GERBIL_LOADPATH. This would eliminate the most common build failure mode when using the tool on real projects.",
    "impact": "medium",
    "tags": [
      "build",
      "loadpath",
      "gerbil.pkg",
      "depend",
      "auto-detect"
    ],
    "use_case": "Any project that imports third-party packages installed via gerbil pkg. The build tool should work out-of-the-box without requiring the user to know about GERBIL_LOADPATH.",
    "example_scenario": "Project has gerbil.pkg with depend: (\\\"github.com/ober/gerbil-leveldb\\\"). User calls gerbil_build_and_report without loadpath. Build fails with 'cannot find library module :clan/db/leveldb'. User must realize they need loadpath: [\\\"~/.gerbil/lib\\\"] and retry. Auto-detection would eliminate this round-trip.",
    "estimated_token_reduction": "~300-500 tokens per failed build + retry. Eliminates 1 tool call round-trip and error diagnosis."
  }
]
