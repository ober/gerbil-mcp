[
  {
    "id": "crypto-digest-sha256-md5",
    "title": "Compute SHA256 or MD5 hash of data",
    "tags": [
      "sha256",
      "md5",
      "hash",
      "digest",
      "crypto",
      "checksum",
      "bytes"
    ],
    "imports": [
      ":std/crypto/digest"
    ],
    "code": "(import :std/crypto/digest)\\n\\n;; SHA256 of a u8vector — returns u8vector\\n(def hash256 (sha256 #u8(104 101 108 108 111)))\\n\\n;; SHA256 of a string (convert to bytes first)\\n(def hash256-str (sha256 (string->bytes \\\"hello\\\")))\\n\\n;; MD5 of bytes — returns u8vector\\n(def hash-md5 (md5 (string->bytes \\\"hello\\\")))\\n\\n;; To get hex string, combine with :std/text/hex\\n(import :std/text/hex)\\n(hex-encode (sha256 (string->bytes \\\"hello\\\")))\\n;; => \\\"2cf24dba5fb0a30e26e83b2ac5b9e29e1b161e5c1fa7425e73043362938b9824\\\"",
    "notes": "sha256 and md5 each take a single u8vector argument and return a u8vector. Other available digests: sha1, sha384, sha512, ripemd160, blake2s256, blake2b512. All from :std/crypto/digest.",
    "related": [
      "base64-encode-decode"
    ]
  },
  {
    "id": "base64-encode-decode",
    "title": "Base64 encode and decode data",
    "tags": [
      "base64",
      "encode",
      "decode",
      "bytes",
      "string",
      "u8vector",
      "binary"
    ],
    "imports": [
      ":std/text/base64"
    ],
    "code": "(import :std/text/base64)\\n\\n;; Encode u8vector to base64 string\\n(u8vector->base64-string (string->bytes \\\"hello\\\"))\\n;; => \\\"aGVsbG8=\\\"\\n\\n;; Decode base64 string to u8vector\\n(base64-string->u8vector \\\"aGVsbG8=\\\")\\n;; => #u8(104 101 108 108 111)\\n\\n;; Encode/decode raw strings\\n(base64-encode \\\"hello\\\")\\n;; => \\\"aGVsbG8=\\\"\\n(base64-decode \\\"aGVsbG8=\\\")\\n;; => \\\"hello\\\"",
    "notes": "u8vector->base64-string and base64-string->u8vector work with binary data. base64-encode and base64-decode work with strings. Useful for HTTP headers like Content-MD5 which require base64-encoded digests.",
    "related": [
      "crypto-digest-sha256-md5"
    ]
  },
  {
    "id": "deferror-class-defraise",
    "title": "Define error class with deferror-class and defraise/context",
    "tags": [
      "error",
      "exception",
      "deferror",
      "defraise",
      "custom",
      "raise",
      "class",
      "context"
    ],
    "imports": [
      ":std/error"
    ],
    "code": "(import :std/error)\\n\\n;; Define an error class (creates predicate automatically)\\n(deferror-class (MyServiceError Error) () my-service-error?)\\n\\n;; Define a raise helper with automatic 'where' context\\n(defraise/context (raise-my-error where message irritants ...)\\n  (MyServiceError message irritants: [irritants ...]))\\n\\n;; Usage — 'where' is automatically set to the calling function name\\n(def (connect host port)\\n  (unless host\\n    (raise-my-error connect \\\"host is required\\\" \\\"host\\\"))\\n  ...)\\n\\n;; Catch it\\n(try (connect #f 80)\\n  (catch (my-service-error? e)\\n    (displayln \\\"Service error: \\\" (error-message e))))",
    "notes": "deferror-class is more concise than defstruct for error types — it automatically inherits Error fields (message, irritants, where). defraise/context auto-fills the 'where' field. The first arg to defraise/context after 'where' becomes the error message, rest become irritants.",
    "related": [
      "error-handling"
    ]
  },
  {
    "id": "cli-getopt-subcommands",
    "title": "Build CLI with getopt (v0.19+ API)",
    "tags": [
      "cli",
      "getopt",
      "command",
      "flag",
      "option",
      "argument",
      "command-line",
      "program"
    ],
    "imports": [
      ":std/cli/getopt",
      ":std/sugar"
    ],
    "code": "(import :std/cli/getopt :std/sugar)\n\n;; Simple CLI with options (no subcommands)\n(def (main . args)\n  (call-with-getopt\n    (lambda (opt)\n      (let-hash opt\n        (when .?verbose (displayln \"verbose mode\"))\n        (displayln \"output: \" (or .?output \"default.txt\"))))\n    args\n    program: \"my-tool\"\n    help: \"My CLI tool\"\n    (flag 'verbose \"--verbose\" \"-v\"\n      help: \"Verbose output\")\n    (option 'output \"--output\" \"-o\"\n      help: \"Output file\"\n      value: identity)))\n\n;; CLI with subcommands\n(def list-cmd\n  (command 'list\n    help: \"List items\"\n    (option 'filter \"--filter\" \"-f\" default: #f help: \"Filter\")))\n\n(def create-cmd\n  (command 'create\n    help: \"Create an item\"\n    (argument 'name help: \"Item name\")))\n\n(def (main . args)\n  (call-with-getopt\n    (lambda (opt)\n      (let-hash opt\n        (case .command\n          ((list) (displayln \"listing with filter: \" .?filter))\n          ((create) (displayln \"creating: \" .name)))))\n    args\n    program: \"my-tool\"\n    help: \"My CLI tool\"\n    list-cmd create-cmd))",
    "notes": "IMPORTANT: In Gerbil v0.19+, call-with-getopt signature is: (call-with-getopt handler args program: \"name\" help: \"...\" options...). The handler lambda comes FIRST, args SECOND, then program: keyword. Older examples showing (call-with-getopt \"name\" args handler ...) are WRONG for v0.19+. For exe builds, the main module MUST have (export main). Use identity instead of string->string for option value converters.",
    "related": [
      "let-hash-destructure"
    ]
  },
  {
    "id": "srfi19-date-time-format",
    "title": "Date/time formatting with SRFI-19",
    "tags": [
      "date",
      "time",
      "srfi",
      "srfi-19",
      "format",
      "timestamp",
      "iso8601",
      "utc",
      "current"
    ],
    "imports": [
      ":std/srfi/19"
    ],
    "code": "(import :std/srfi/19)\\n\\n;; Current date/time (UTC)\\n(def now (current-date))\\n\\n;; Format as ISO 8601 timestamp\\n(date->string now \\\"~Y~m~dT~H~M~SZ\\\")\\n;; => \\\"20250115T143052Z\\\"\\n\\n;; Format date portion only\\n(date->string now \\\"~Y~m~d\\\")\\n;; => \\\"20250115\\\"\\n\\n;; Format human-readable\\n(date->string now \\\"~Y-~m-~d ~H:~M:~S\\\")\\n;; => \\\"2025-01-15 14:30:52\\\"\\n\\n;; Common format directives:\\n;;   ~Y  4-digit year    ~m  2-digit month   ~d  2-digit day\\n;;   ~H  24-hour hour    ~M  minute          ~S  second\\n;;   ~Z  timezone offset  ~A  weekday name    ~B  month name",
    "notes": "current-date returns UTC. date->string uses SRFI-19 format directives (tilde-based, not strftime). Commonly needed for AWS signature timestamps (yyyyMMddTHHmmssZ format) and date-scoped signing keys (yyyyMMdd)."
  },
  {
    "id": "xml-parse-sxml",
    "title": "Parse XML string to SXML",
    "tags": [
      "xml",
      "parse",
      "sxml",
      "markup",
      "html",
      "response",
      "api"
    ],
    "imports": [
      ":std/markup/xml"
    ],
    "code": "(import :std/markup/xml)\\n\\n;; Parse XML string to SXML tree\\n(def sxml\\n  (call-with-input-string\\n    \\\"<root><item>hello</item><item>world</item></root>\\\"\\n    read-xml))\\n;; => (*TOP* (root (item \\\"hello\\\") (item \\\"world\\\")))\\n\\n;; GOTCHA: XML with <?xml ...?> declaration produces a *PI* node\\n(def sxml-with-pi\\n  (call-with-input-string\\n    \\\"<?xml version=\\\\\\\"1.0\\\\\\\" encoding=\\\\\\\"UTF-8\\\\\\\"?><root><item>hello</item></root>\\\"\\n    read-xml))\\n;; => (*TOP* (*PI* xml \\\"version=...\\\") (root (item \\\"hello\\\")))\\n;; Note the *PI* node — you must skip it when searching for the root element!\\n\\n;; Navigate SXML — it's just nested lists\\n;; (tag child1 child2 ...) where children are strings or nested tags\\n(def root (cadr sxml))    ;; skip *TOP*, get (root ...)\\n(def items (cdr root))    ;; get children: ((item \\\"hello\\\") (item \\\"world\\\"))\\n(def first-text (cadar items))  ;; => \\\"hello\\\"",
    "notes": "read-xml from :std/markup/xml returns SXML (S-expression XML). It takes a single port argument. The result is always wrapped in (*TOP* ...). IMPORTANT: When the XML source has a <?xml ...?> processing instruction, a (*PI* xml ...) node appears in the SXML tree — you must skip it (along with @ and *NAMESPACES*) when traversing to find the root element, or it will be mistaken for the content root. See the sxml-skip-pi-nodes recipe for a correct traversal pattern. Use cadr to skip *TOP*, then navigate with car/cdr/assoc.",
    "related": [
      "sxml-skip-pi-nodes"
    ]
  },
  {
    "id": "using-typed-struct-access",
    "title": "Typed struct field access with using macro",
    "tags": [
      "using",
      "struct",
      "typed",
      "access",
      "field",
      "slot",
      "dot",
      "optimize",
      "defstruct"
    ],
    "imports": [],
    "code": "(defstruct point (x y) final: #t)\\n(defstruct (point3d point) (z) final: #t)\\n\\n;; using gives typed access — dot notation without dynamic dispatch\\n(def (distance p1 p2)\\n  (using ((p1 :- point) (p2 :- point))\\n    (sqrt (+ (expt (- p1.x p2.x) 2)\\n             (expt (- p1.y p2.y) 2)))))\\n\\n(distance (make-point 0 0) (make-point 3 4))  ;; => 5.0\\n\\n;; Single binding form\\n(def (describe-point p)\\n  (using (p :- point)\\n    (format \\\"(~a, ~a)\\\" p.x p.y)))\\n\\n;; Works with mutation too\\n(def (move-point! p dx dy)\\n  (using (p :- point)\\n    (set! p.x (+ p.x dx))\\n    (set! p.y (+ p.y dy))))",
    "notes": "using provides typed struct access that compiles to direct field access (no hash-table lookup). Use with defstruct types. The :- annotation is a type declaration. Pair with final: #t on defstruct for best optimization. Unlike (@ obj slot), using is compile-time checked."
  },
  {
    "id": "let-hash-destructure",
    "title": "Destructure hash tables with let-hash",
    "tags": [
      "let-hash",
      "hash",
      "destructure",
      "sugar",
      "optional",
      "field",
      "config",
      "options"
    ],
    "imports": [
      ":std/sugar"
    ],
    "code": "(import :std/sugar)\\n\\n(def config (hash (name \\\"app\\\") (port 8080) (debug #f)))\\n\\n(let-hash config\\n  ;; .field — required (hash-ref with symbol key, error if missing)\\n  (displayln \\\"name: \\\" .name)\\n\\n  ;; .?field — optional (hash-get, returns #f if missing)\\n  (when .?debug\\n    (displayln \\\"debug mode\\\"))\\n\\n  ;; Use .?field with defaults via 'or'\\n  (def timeout (or .?timeout 30))\\n  (displayln \\\"port: \\\" .port \\\" timeout: \\\" timeout))\\n\\n;; With string keys, use .$field\\n(def headers (hash (\\\"Content-Type\\\" \\\"text/html\\\") (\\\"X-Custom\\\" \\\"val\\\")))\\n(let-hash headers\\n  (displayln .$Content-Type))  ;; uses string key \\\"Content-Type\\\"",
    "notes": "let-hash is from :std/sugar. Three accessor forms: .field (symbol key, required — errors if missing), .?field (symbol key, optional — returns #f), .$field (string key, optional). Very useful for CLI option hashes from getopt and API response hashes. Nests well — (let-hash outer (let-hash .inner-hash ...)).",
    "related": [
      "cli-getopt-subcommands"
    ]
  },
  {
    "id": "parse-ini-file",
    "title": "Parse INI/config file into nested hash tables",
    "tags": [
      "ini",
      "config",
      "parse",
      "file",
      "section",
      "profile",
      "aws",
      "credentials",
      "settings"
    ],
    "imports": [
      ":std/sugar",
      ":std/srfi/13"
    ],
    "code": "(import :std/sugar (only-in :std/srfi/13 string-trim-both string-prefix? string-index))\\n\\n;; Parse INI file into hash of sections, each section is a hash of key=value\\n(def (parse-ini-file path)\\n  (let ((result (make-hash-table))\\n        (current-section #f))\\n    (when (file-exists? path)\\n      (call-with-input-file path\\n        (lambda (port)\\n          (let loop ()\\n            (let (line (read-line port))\\n              (unless (eof-object? line)\\n                (let (trimmed (string-trim-both line))\\n                  (cond\\n                    ((or (equal? trimmed \\\"\\\") (string-prefix? \\\"#\\\" trimmed)\\n                         (string-prefix? \\\";\\\" trimmed))\\n                     (void))  ;; skip blank/comment lines\\n                    ((and (string-prefix? \\\"[\\\" trimmed))\\n                     (let (end (string-index trimmed #\\\\]))\\n                       (when end\\n                         (set! current-section (substring trimmed 1 end))\\n                         (unless (hash-key? result current-section)\\n                           (hash-put! result current-section (make-hash-table))))))\\n                    (else\\n                     (when current-section\\n                       (let (eq-pos (string-index trimmed #\\\\=))\\n                         (when eq-pos\\n                           (let ((key (string-trim-both (substring trimmed 0 eq-pos)))\\n                                 (val (string-trim-both (substring trimmed (+ eq-pos 1)\\n                                                          (string-length trimmed)))))\\n                             (hash-put! (hash-ref result current-section) key val))))))))\\n                (loop)))))))\\n    result))\\n\\n;; Usage:\\n;; (def config (parse-ini-file \\\"~/.aws/credentials\\\"))\\n;; (hash-ref (hash-ref config \\\"default\\\") \\\"aws_access_key_id\\\")",
    "notes": "Handles [section] headers, key=value pairs, blank lines, and # or ; comments. Returns a hash of hashes: outer keys are section names, inner keys are setting names. Useful for parsing AWS credentials/config files, .gitconfig, and similar INI-style configs. Uses string-trim-both and string-index from :std/srfi/13."
  },
  {
    "id": "http-post-form-encoded",
    "title": "HTTP POST with form-url-encoded body",
    "tags": [
      "http",
      "post",
      "form",
      "urlencoded",
      "uri",
      "encode",
      "request",
      "api",
      "query"
    ],
    "imports": [
      ":std/net/request",
      ":std/net/uri"
    ],
    "code": "(import :std/net/request :std/net/uri)\\n\\n;; Build form-encoded body from alist of (key . value) pairs\\n(def params '((\\\"Action\\\" . \\\"DescribeInstances\\\")\\n              (\\\"Version\\\" . \\\"2016-11-15\\\")\\n              (\\\"MaxResults\\\" . \\\"10\\\")))\\n\\n(def body (form-url-encode params))\\n;; => \\\"Action=DescribeInstances&Version=2016-11-15&MaxResults=10\\\"\\n\\n;; POST with form-encoded body\\n(def resp (http-post \\\"https://api.example.com/\\\"\\n            data: body\\n            headers: '((\\\"Content-Type\\\" . \\\"application/x-www-form-urlencoded\\\"))))\\n\\n(request-status resp)   ;; HTTP status code\\n(request-text resp)     ;; response body as string\\n(request-close resp)    ;; release connection",
    "notes": "form-url-encode from :std/net/uri takes an alist of (key . value) string pairs and produces a URL-encoded query string. This is the standard format for AWS Query API services (EC2, STS, IAM, SNS, CloudFormation). Always call request-close after reading the response to release the connection.",
    "related": [
      "http-get",
      "http-post-json"
    ]
  },
  {
    "id": "sigv4-aws-request-signing",
    "title": "AWS SigV4 request signing",
    "tags": [
      "aws",
      "sigv4",
      "signing",
      "signature",
      "authentication",
      "s3",
      "ec2",
      "request",
      "api"
    ],
    "imports": [
      ":std/net/s3/sigv4",
      ":std/crypto/digest",
      ":std/text/hex",
      ":std/srfi/19",
      ":std/net/request"
    ],
    "code": "(import :std/net/s3/sigv4 :std/crypto/digest :std/text/hex\\n        :std/srfi/19 :std/net/request)\\n\\n;; Prepare timestamp and scope\\n(def now (current-date))\\n(def ts (date->string now \\\"~Y~m~dT~H~M~SZ\\\"))     ;; e.g. \\\"20250115T143052Z\\\"\\n(def scopets (date->string now \\\"~Y~m~d\\\"))           ;; e.g. \\\"20250115\\\"\\n(def scope (string-append scopets \\\"/us-east-1/sts\\\")) ;; date/region/service\\n\\n;; Build headers list as alist with :: syntax\\n(def body-bytes (string->bytes \\\"Action=GetCallerIdentity&Version=2011-06-15\\\"))\\n(def body-hash (sha256 body-bytes))\\n(def host \\\"sts.amazonaws.com\\\")\\n(def headers [[\\\"Host\\\" :: host]\\n              [\\\"x-amz-date\\\" :: ts]\\n              [\\\"Content-Type\\\" :: \\\"application/x-www-form-urlencoded\\\"]])\\n\\n;; Create canonical request\\n(def creq (aws4-canonical-request\\n             verb: 'POST uri: \\\"/\\\" query: #f\\n             headers: headers hash: body-hash))\\n\\n;; Generate Authorization header\\n(def auth (aws4-auth scope creq ts headers\\n                     \\\"SECRET_KEY\\\" \\\"ACCESS_KEY\\\"))\\n\\n;; Make the signed request\\n(def signed-headers (cons [\\\"Authorization\\\" :: auth] headers))\\n(def resp (http-post (string-append \\\"https://\\\" host \\\"/\\\")\\n            headers: signed-headers\\n            data: (bytes->string body-bytes)))",
    "notes": "aws4-canonical-request and aws4-auth are from :std/net/s3/sigv4 (works for ALL AWS services, not just S3). The scope format is \\\"YYYYMMDD/region/service\\\". Headers must be an alist with [key :: value] pairs. body-hash is the SHA256 of the request body as a u8vector. For GET requests with no body, use (sha256 #u8()) for the hash.",
    "related": [
      "http-post-form-encoded",
      "crypto-digest-sha256-md5",
      "srfi19-date-time-format"
    ]
  },
  {
    "id": "hash-table-basics",
    "title": "Hash table operations",
    "tags": [
      "hash",
      "table",
      "get",
      "ref",
      "put",
      "key",
      "remove",
      "lookup",
      "default"
    ],
    "imports": [],
    "code": "(def ht (hash (\"name\" \"alice\") (\"age\" 30)))   ;; literal syntax\n(hash-ref ht \"name\")          ;; => \"alice\" (error if missing)\n(hash-ref ht \"missing\" 42)    ;; => 42 (hash-ref takes optional 3rd arg default)\n(hash-get ht \"name\")          ;; => \"alice\" (returns #f if missing)\n;; IMPORTANT: hash-get takes EXACTLY 2 args (table, key). Returns #f if missing.\n;; For a default value, use hash-ref with 3 args: (hash-ref ht key default)\n(hash-put! ht \"email\" \"a@b\")  ;; mutate\n(hash-key? ht \"name\")         ;; => #t\n(hash-remove! ht \"age\")\n(hash->list ht)               ;; => ((\"name\" . \"alice\") ...)\n\n;; Multi-arity wrapper if you want hash-get with defaults:\n(def* hget\n  ((ht key) (hash-get ht key))\n  ((ht key default) (hash-ref ht key default)))",
    "notes": "CRITICAL: hash-get is STRICTLY 2-arity in Gerbil. (hash-get ht key default) is WRONG and will error. Use hash-ref for 3-arg lookups with a default. The hget wrapper pattern (using def*) provides a convenient multi-arity alternative. Use (hash ...) for string keys, (hash-eq ...) for symbol keys.",
    "related": [
      "iterate-hash",
      "hash-table-merge"
    ]
  },
  {
    "id": "exe-build-static-modules",
    "title": "Build statically-linked executable with dependencies",
    "tags": [
      "exe",
      "build",
      "static",
      "link",
      "binary",
      "executable",
      "release",
      "defbuild-script"
    ],
    "imports": [
      ":std/build-script"
    ],
    "code": ";; build.ss — with exe target\n#!/usr/bin/env gxi\n(import :std/build-script)\n(defbuild-script\n  '(\"module-a\"\n    \"module-b\"\n    (exe: \"main\" bin: \"my-app\")))\n\n;; REQUIREMENTS for exe linking:\n;; 1. The main module MUST export its main function:\n;;    (export main)\n;;\n;; 2. All dependencies must have static modules (.scm files in static/ dir).\n;;    Build dependencies with --release:\n;;      cd /path/to/dependency && gerbil build --release\n;;\n;; 3. GERBIL_LOADPATH must include the dependency's .gerbil/lib/ directory\n;;    so the linker can find static modules:\n;;      GERBIL_LOADPATH=/path/to/dep/.gerbil/lib gerbil build --release\n;;\n;; 4. Build YOUR project with --release too:\n;;      gerbil build --release",
    "notes": "Common errors: (1) \"cannot find static module foo__bar.scm\" — the dependency wasn't built with --release, or its .gerbil/lib/ isn't in GERBIL_LOADPATH. (2) \"module does not export symbol: main\" — add (export main) to the main module. (3) Linker warnings about dlopen/getaddrinfo are harmless for static Gambit binaries. The resulting binary is fully self-contained and doesn't need Gerbil installed to run.",
    "related": [
      "cli-getopt-subcommands"
    ]
  },
  {
    "id": "export-t-does-not-reexport-imports",
    "title": "(export #t) does NOT re-export imported symbols",
    "tags": [
      "export",
      "import",
      "re-export",
      "module",
      "gotcha",
      "transitive"
    ],
    "imports": [],
    "code": ";; Module A (a.ss) — imports and re-exports\n(import :some-library/foo)  ;; provides make-foo\n(export #t)\n\n(def (helper x) (make-foo x))  ;; make-foo is usable here\n\n;; Module B (b.ss) — imports Module A\n(import ./a)\n\n;; (make-foo 42)  ;; ERROR: make-foo is NOT available!\n;; (export #t) only exports symbols DEFINED in the module,\n;; not symbols imported from other modules.\n\n;; WORKAROUND 1: Import the library directly in Module B\n(import :some-library/foo)  ;; now make-foo is available\n\n;; WORKAROUND 2: Explicitly re-export in Module A\n;; (export (import: :some-library/foo))  ;; re-exports foo's bindings",
    "notes": "In Gerbil, (export #t) exports all bindings DEFINED in the current module's scope, but does NOT transitively re-export symbols imported from other modules. If module A imports :lib/foo and uses (export #t), module B importing A will NOT get :lib/foo's symbols. Module B must import :lib/foo directly, or module A must use (export (import: :lib/foo)) for explicit re-export. This is a common source of \"Reference to unbound identifier\" errors when refactoring."
  },
  {
    "id": "cons-pair-in-bracket-list-gotcha",
    "title": "Dotted pair syntax inside [] is a function call, not a cons pair",
    "tags": [
      "cons",
      "pair",
      "list",
      "bracket",
      "dotted",
      "gotcha",
      "alist",
      "dimensions"
    ],
    "imports": [],
    "code": ";; WRONG: Dotted pair syntax with a variable inside [] list sugar\n;; This is interpreted as calling \"Key\" as a function with value as arg!\n(def key-name \"MyKey\")\n;; [(\"Key\" . key-name)]  ;; ERROR: Bad syntax; invalid match target\n;; Expands to (@list (\"Key\" . key-name)) where (\"Key\" . key-name)\n;; is treated as (%%app \"Key\" . key-name) — a function application.\n\n;; CORRECT: Use (cons ...) to build pairs with variables\n[(cons \"Key\" key-name)]        ;; => ((\"Key\" . \"MyKey\"))\n\n;; Literal dotted pairs (both sides are constants) work inside quote:\n'((\"Key\" . \"literal-value\"))   ;; OK — quoted datum\n\n;; Common use case: building alists for AWS API dimensions\n(def instance-id \"i-abc123\")\n;; Wrong:  dimensions: [(\"InstanceId\" . instance-id)]\n;; Right:  dimensions: [(cons \"InstanceId\" instance-id)]\n\n;; Multiple pairs:\n(def name \"my-func\")\n(def dims [(cons \"FunctionName\" name)\n           (cons \"Resource\" \"my-resource\")])\n;; => ((\"FunctionName\" . \"my-func\") (\"Resource\" . \"my-resource\"))",
    "notes": "In Gerbil, [x y z] is sugar for (@list x y z). Each element is an expression. The syntax (\"Key\" . var) in expression position is NOT a cons pair — it's a function application where \"Key\" is the operator. This causes \"Bad syntax; invalid match target\" or similar errors. Use (cons \"Key\" var) instead. Literal pairs work fine inside quote: '((\"k\" . \"v\")). This commonly bites when building alists (e.g., AWS API dimension parameters) where keys are string literals but values are variables."
  },
  {
    "id": "gerbil-build-loadpath-for-packages",
    "title": "gerbil build needs GERBIL_LOADPATH to find installed packages",
    "tags": [
      "build",
      "GERBIL_LOADPATH",
      "package",
      "import",
      "cannot find",
      "library module",
      "Makefile"
    ],
    "imports": [],
    "code": ";; If your project imports a third-party package installed via gerbil pkg:\n;; (import :my-library/module)\n;;\n;; Running bare `gerbil build` may fail with:\n;;   Syntax Error: cannot find library module\n;;   form: :my-library/module\n;;\n;; The fix: set GERBIL_LOADPATH to include ~/.gerbil/lib\n;;\n;; Option 1: Shell environment variable\n;; $ GERBIL_LOADPATH=~/.gerbil/lib gerbil build\n;;\n;; Option 2: Makefile (recommended for projects)\n;; ------- Makefile -------\n;; GERBIL_PATH = $(HOME)/.gerbil\n;; export GERBIL_LOADPATH = $(GERBIL_PATH)/lib\n;;\n;; build:\n;; \tgerbil build\n;;\n;; clean:\n;; \tgerbil clean\n;; ------- end -------\n;;\n;; Note: gxi (the REPL) finds packages without GERBIL_LOADPATH,\n;; but the build subprocess spawned by `gerbil build` does not.\n;; This is a common source of confusion when imports work in gxi\n;; but fail during compilation.",
    "notes": "The gerbil build command spawns a subprocess to compile, and that subprocess does not inherit the default package search paths that gxi uses. You must explicitly set GERBIL_LOADPATH=$HOME/.gerbil/lib (or wherever packages are installed). A Makefile with `export GERBIL_LOADPATH` is the standard pattern. This explains why `gxi -e '(import :pkg/mod)'` works but `gerbil build` fails with \"cannot find library module\"."
  },
  {
    "id": "gerbil-aws-query-vs-json-response-keys",
    "title": "gerbil-aws Query API vs JSON API response key differences",
    "tags": [
      "gerbil-aws",
      "query",
      "json",
      "XML",
      "symbol",
      "string",
      "keys",
      "AWS",
      "migration",
      "CloudWatch",
      "RDS",
      "ELBv2"
    ],
    "imports": [],
    "code": ";; gerbil-aws has two API protocols with DIFFERENT response formats:\n;;\n;; 1. Query API (XML): EC2, STS, IAM, CloudWatch, RDS, ELBv2, SNS, SQS, CloudFormation\n;;    - Keys are SYMBOLS: 'Average, 'InstanceId, 'DBInstanceIdentifier\n;;    - Values are STRINGS (from XML text): \"30.5\", \"true\", \"i-abc123\"\n;;    - Lists use {member: [...]} wrapper from XML <member> elements\n;;    - Booleans are strings: \"true\" / \"false\"\n;;\n;; 2. JSON API: Lambda, CloudWatch Logs, DynamoDB, Compute Optimizer, Cost Optimization Hub\n;;    - Keys are STRINGS: \"Average\", \"instanceId\", \"functionName\"\n;;    - Values are TYPED: 30.5 (number), #t (boolean), \"i-abc123\" (string)\n;;    - Lists are plain lists (JSON arrays)\n;;    - Booleans are #t / #f\n;;\n;; When migrating from AWS CLI (JSON output) to native Query API:\n;;   (hget resp \"Datapoints\")          ;; CLI: string key, list value\n;;   ;; becomes:\n;;   ;; get-metric-statistics returns the list directly (no wrapper key)\n;;\n;;   (hget dp \"Average\")               ;; CLI: string key, number value\n;;   ;; becomes:\n;;   (safe-number (hash-ref dp 'Average #f) 0)  ;; Query: symbol key, STRING value\n;;\n;; When migrating from AWS CLI to native JSON API:\n;;   (hget resp \"Functions\")           ;; CLI: string key, list value\n;;   ;; stays the same — JSON API matches CLI output format\n;;\n;; IMPORTANT: Query API numeric values MUST be converted with string->number\n;; or a safe-number wrapper. They come back as strings like \"30.5\" not 30.5.",
    "notes": "This is the most common source of bugs when migrating from AWS CLI calls to native gerbil-aws. Query API services return symbol keys and string values from XML parsing, while JSON API services return string keys and typed values (matching CLI output). Always use hash-ref with symbol keys ('Key) for Query API responses, and convert numeric strings with string->number or a safe wrapper.",
    "related": [
      "http-post-form-encoded",
      "parse-xml-to-sxml"
    ]
  },
  {
    "id": "extract-member-list-xml-normalization",
    "title": "Normalize XML member-list structures from gerbil-aws Query API",
    "tags": [
      "gerbil-aws",
      "XML",
      "member",
      "list",
      "normalize",
      "query",
      "API",
      "dimensions",
      "CloudWatch"
    ],
    "imports": [],
    "code": ";; AWS Query API XML uses <member> elements for lists:\n;;   <Dimensions>\n;;     <member><Name>InstanceId</Name><Value>i-abc</Value></member>\n;;     <member><Name>ImageId</Name><Value>ami-xyz</Value></member>\n;;   </Dimensions>\n;;\n;; After sxml->hash parsing, this becomes different structures depending\n;; on the number of <member> elements:\n;;\n;;   Single member:  {member: {Name: \"InstanceId\", Value: \"i-abc\"}}\n;;   Multiple:       {member: [{Name: \"InstanceId\", ...}, {Name: \"ImageId\", ...}]}\n;;   Empty:          #f or missing key\n;;\n;; Use this helper to normalize to a plain list in all cases:\n\n(def (extract-member-list raw)\n  \"Normalize XML member-list to a plain list.\n   Handles: #f -> [], list -> list, {member: list} -> list,\n            {member: hash} -> [hash], string -> [string]\"\n  (cond\n    ((not raw) [])\n    ((list? raw) raw)\n    ((hash-table? raw)\n     (let ((m (hash-get raw 'member)))\n       (cond\n         ((list? m) m)\n         ((not m) [])\n         (else [m]))))          ;; single member: wrap in list\n    (else [])))\n\n;; Example: extracting CloudWatch dimensions from list-metrics response\n;; (def metric (car (list-metrics cw metric-name: \"CPUUtilization\" ...)))\n;; (def dims-raw (hash-ref metric 'Dimensions #f))\n;; (def dims (extract-member-list dims-raw))\n;; ;; dims is now always a list of hashes with 'Name and 'Value keys\n;; (def dims-alist\n;;   (map (lambda (d) (cons (hash-ref d 'Name \"\") (hash-ref d 'Value \"\")))\n;;        dims))",
    "notes": "The gerbil-aws Query API functions like cw-action/items extract the outer member list, but inner nested member-list structures (e.g., Dimensions within a Metric) remain in raw XML-parsed form. This helper normalizes the three possible shapes (single hash, list of hashes, or #f) into a consistent list. Essential when processing CloudWatch list-metrics dimensions, IAM policy documents, or any Query API response with nested lists.",
    "related": [
      "gerbil-aws-query-vs-json-response-keys"
    ]
  },
  {
    "id": "sxml-skip-pi-nodes",
    "title": "Skip *PI* processing instruction nodes when traversing SXML",
    "tags": [
      "sxml",
      "xml",
      "parsing",
      "processing-instruction",
      "PI",
      "read-xml",
      "traverse",
      "gotcha",
      "*PI*",
      "*TOP*"
    ],
    "imports": [
      ":std/markup/xml"
    ],
    "code": "\n(import :std/markup/xml)\n\n;; XML responses often start with <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n;; read-xml parses this into a *PI* (Processing Instruction) SXML node:\n;;\n;;   (*TOP*\n;;     (@ (*NAMESPACES* ...))\n;;     (*PI* xml \"version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"\")   ;; <-- gotcha!\n;;     (ns:RootElement ...))\n;;\n;; When traversing SXML to find the root element, you MUST skip *PI* nodes\n;; along with @, *NAMESPACES*, and *TOP*. Otherwise *PI* gets mistakenly\n;; treated as the root element.\n\n;; WRONG — misses *PI*, returns wrong node:\n(def (find-root-BAD xml)\n  (let find ((node xml))\n    (cond\n      ((not (pair? node)) #f)\n      ((memq (car node) '(@ *NAMESPACES*)) #f)        ;; missing *PI*!\n      ((not (eq? (car node) '*TOP*)) node)\n      (else (ormap find (cdr node))))))\n\n;; CORRECT — skips *PI* nodes:\n(def (find-root-GOOD xml)\n  (let find ((node xml))\n    (cond\n      ((not (pair? node)) #f)\n      ((memq (car node) '(@ *NAMESPACES* *PI*)) #f)   ;; includes *PI*\n      ((not (eq? (car node) '*TOP*)) node)\n      (else (ormap find (cdr node))))))\n\n;; Example: parsing an S3 response with XML declaration\n(def xml (read-xml\n           \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?><Root><Item>hello</Item></Root>\"\n           namespaces: '()))\n\n(find-root-BAD xml)   ;; => (*PI* xml \"version=\\\"1.0\\\" ...\") — WRONG!\n(find-root-GOOD xml)  ;; => (Root (Item \"hello\")) — correct\n",
    "notes": "The *PI* node appears in SXML when the source XML contains processing instructions like <?xml ...?>. Most real-world XML APIs (AWS S3, etc.) include this declaration. The SXML metadata nodes to always skip when searching for content elements are: *TOP* (document root wrapper), @ (attributes), *NAMESPACES* (namespace declarations), and *PI* (processing instructions). Forgetting *PI* causes silent data loss — the PI node gets processed as if it were the root element, typically producing an empty string or #f instead of the expected parsed data."
  },
  {
    "id": "stale-global-static-files-segfault",
    "title": "Stale global static files cause segfaults in compiled binaries",
    "tags": [
      "segfault",
      "static",
      "linking",
      "build",
      "stale",
      "global",
      "GERBIL_LOADPATH",
      "ABI",
      "mismatch",
      "crash",
      "exe"
    ],
    "imports": [],
    "code": ";; PROBLEM: Compiled binary segfaults but code works fine in gxi REPL.\n;;\n;; ROOT CAUSE: Stale static files (.scm, .c, .o) in ~/.gerbil/lib/static/\n;; shadow locally compiled versions. When GERBIL_LOADPATH includes\n;; ~/.gerbil/lib BEFORE the local project path, the exe linker picks up\n;; the old global .o files instead of the current local ones.\n;;\n;; This causes ABI mismatches: e.g., cost-explorer calls\n;;   aws-billing/aws#first-of-month-string__%  (new split variant)\n;; but the stale global aws module only defines\n;;   aws-billing/aws#first-of-month-string     (old monolithic variant)\n;; Calling an undefined symbol → SIGSEGV.\n;;\n;; HOW STALE FILES GET THERE:\n;; - Running `gerbil build` or `gxpkg build` from within a project\n;;   that has its .gerbil/lib/ in GERBIL_LOADPATH\n;; - A previous `gerbil pkg install` of the package\n;; - Manually copying build artifacts\n;;\n;; DIAGNOSIS:\n;; 1. Check for duplicate static files:\n;;    find ~/.gerbil/lib -name 'YOURPKG__*.scm' -o -name 'YOURPKG__*.o'\n;;\n;; 2. Compare with local project files:\n;;    ls -la ~/.gerbil/lib/static/YOURPKG__module.scm   # stale (old timestamp)\n;;    ls -la ./project/.gerbil/lib/static/YOURPKG__module.scm  # current\n;;\n;; 3. Check build output: if BOTH paths appear during exe compilation,\n;;    the global one may win.\n;;\n;; FIX:\n;; Remove ALL stale global artifacts (.scm, .c, .o, .ssi):\n;;   rm -rf ~/.gerbil/lib/YOURPKG/\n;;   rm -f  ~/.gerbil/lib/static/YOURPKG__*.scm\n;;   rm -f  ~/.gerbil/lib/static/YOURPKG__*.c\n;;   rm -f  ~/.gerbil/lib/static/YOURPKG__*.o\n;;\n;; Then clean rebuild:\n;;   make clean && make build\n;;\n;; IMPORTANT: `gerbil clean` only removes LOCAL .gerbil/ artifacts.\n;; It does NOT clean ~/.gerbil/lib/. You must manually remove stale\n;; global files. Also note: removing just .scm files is NOT enough —\n;; the linker uses the .o files directly if they exist.",
    "notes": "The Gerbil compiler may change how optional-arg functions are compiled across versions (monolithic closure vs split __%/__0 variants). If global static files are from an older compilation, the ABI won't match modules compiled with the current compiler. The segfault typically occurs at the call site in `(declare (not safe))` blocks where the undefined function symbol resolves to null/garbage. The `strings` command won't find Gerbil string literals in compiled binaries (they're stored as Gambit string objects, not C strings), so use `grep` on the `.scm` static files to verify which version the linker uses.",
    "related": [
      "static-exe-with-deps",
      "gerbil-build-loadpath"
    ]
  },
  {
    "id": "debug-compiled-only-segfault",
    "title": "Debug segfaults that only occur in compiled binaries (not REPL)",
    "tags": [
      "debug",
      "segfault",
      "compiled",
      "binary",
      "REPL",
      "gdb",
      "static",
      "linking",
      "crash"
    ],
    "imports": [],
    "code": ";; When code works in gxi but segfaults as a compiled binary:\n;;\n;; STEP 1: Test in REPL to confirm the logic is correct\n;;   echo '(import :mymodule) (my-function args)' | \\\n;;     GERBIL_LOADPATH=... gxi\n;;\n;; STEP 2: Add debug displayln/force-output INSIDE the crashing function\n;;   (def (my-function arg)\n;;     (displayln \"[dbg] entering\") (force-output)\n;;     (let ((x (step-1)))\n;;       (displayln \"[dbg] step-1 ok\") (force-output)\n;;       ...))\n;;\n;; STEP 3: Rebuild and check if debug output appears in binary\n;;   ;; Gerbil string literals are NOT plain C strings in the binary.\n;;   ;; Check the static .scm file instead:\n;;   grep 'dbg' .gerbil/lib/static/YOURPKG__module.scm\n;;\n;; STEP 4: If debug strings are in .scm but NOT in behavior,\n;;   check for stale global copies shadowing local files:\n;;   find ~/.gerbil/lib -name 'YOURPKG__*' -type f\n;;\n;; STEP 5: Compare compiled function signatures between versions\n;;   ;; Old compilation style (monolithic optional-arg function):\n;;   ;;   (define pkg#my-fn (let ((opt-lambda ...)) (lambda _g_ ...)))\n;;   ;;\n;;   ;; New compilation style (split variants):\n;;   ;;   (define pkg#my-fn__% (lambda (arg) ...))    ; implementation\n;;   ;;   (define pkg#my-fn__0 (lambda () ...))        ; zero-arg wrapper\n;;   ;;   (define pkg#my-fn (lambda _g_ (cond ...)))   ; dispatch\n;;   ;;\n;;   ;; If caller uses my-fn__% but linked module only defines my-fn,\n;;   ;; the symbol is undefined → segfault in (declare (not safe)) context.\n;;\n;; STEP 6: GDB can identify the hosting function but not the exact line:\n;;   ;; ___H_pkg____module is Gambit's C hosting function for the module.\n;;   ;; All compiled Scheme code for that module lives inside this one\n;;   ;; C function, so the crash address isn't very informative.\n;;   ;; Use debug displayln to narrow down instead.",
    "notes": "Key insight: in compiled Gerbil binaries with (declare (not safe)), calling an undefined/unresolved symbol doesn't raise a Scheme exception — it causes a raw SIGSEGV because the null function pointer is called without any safety checks. The REPL doesn't have this problem because it resolves symbols dynamically. Also: `gerbil clean` does NOT remove ~/.gerbil/lib/ artifacts — only local .gerbil/ files.",
    "related": [
      "stale-global-static-files-segfault",
      "static-exe-with-deps"
    ]
  },
  {
    "id": "srfi-19-current-time-shadows-gambit",
    "title": "SRFI-19 current-time shadows Gambit's current-time (causes time->seconds crash)",
    "tags": [
      "srfi-19",
      "current-time",
      "time",
      "gambit",
      "shadow",
      "time->seconds",
      "mutex",
      "rate-limit",
      "gotcha"
    ],
    "imports": [
      ":std/srfi/19"
    ],
    "code": ";; PROBLEM: Importing :std/srfi/19 shadows Gambit's built-in (current-time).\n;;\n;; Gambit's (current-time) returns a Gambit time object (##type #2 time).\n;; SRFI-19's (current-time) returns an SRFI-19 time object (different type).\n;; Gambit's (time->seconds) only accepts Gambit time objects.\n;;\n;; If you import :std/srfi/19 and then call:\n;;   (time->seconds (current-time))\n;; You get: \"Instance of #<type #2 time> expected\"\n;; because (current-time) now returns SRFI-19 time, but (time->seconds)\n;; expects Gambit time.\n;;\n;; This commonly bites in rate-limiting code, mutex timing, or anywhere\n;; you mix SRFI-19 date formatting with Gambit timing primitives.\n\n;; WRONG — crashes at runtime:\n;; (import :std/srfi/19)\n;; (def (rate-limit!)\n;;   (let ((now (time->seconds (current-time))))  ;; BOOM\n;;     ...))\n\n;; FIX: Use ##current-time to bypass the SRFI-19 shadow:\n(import :std/srfi/19)\n(def (rate-limit!)\n  (let ((now (exact->inexact (time->seconds (##current-time)))))\n    ;; ##current-time always returns Gambit's native time object\n    ;; time->seconds works correctly on it\n    now))\n\n;; ALTERNATIVE: Use SRFI-19's own time conversion instead:\n;; (import :std/srfi/19)\n;; (def (current-seconds)\n;;   (let ((t (current-time)))  ;; SRFI-19 time\n;;     (+ (time-second t)       ;; SRFI-19 accessor\n;;        (/ (time-nanosecond t) 1e9))))",
    "notes": "The ## prefix accesses Gambit's raw (unshadowed) primitives. ##current-time is safe to use even when SRFI-19 is imported. This issue only manifests at runtime — compilation succeeds because both versions of current-time have the same arity. The error message \"Instance of #<type #2 time> expected\" is the key diagnostic clue. Also note: exact->inexact is needed because time->seconds may return an exact rational.",
    "related": [
      "date-time-formatting-srfi-19"
    ]
  },
  {
    "id": "mutex-unwind-protect-deadlock-prevention",
    "title": "Always wrap mutex-lock!/unlock! with unwind-protect to prevent deadlocks",
    "tags": [
      "mutex",
      "unwind-protect",
      "deadlock",
      "thread",
      "lock",
      "concurrency",
      "exception",
      "safety"
    ],
    "imports": [],
    "code": ";; PROBLEM: If an exception occurs between mutex-lock! and mutex-unlock!,\n;; the mutex stays locked forever, deadlocking all subsequent callers.\n;;\n;; WRONG — deadlocks after first exception:\n;; (def my-lock (make-mutex 'my-lock))\n;; (def (unsafe-operation!)\n;;   (mutex-lock! my-lock)\n;;   (do-something-that-might-throw)  ;; if this throws...\n;;   (mutex-unlock! my-lock))         ;; ...this never runs → deadlock\n\n;; CORRECT — always unlocks, even on exception:\n(def my-lock (make-mutex 'my-lock))\n\n(def (safe-operation!)\n  (mutex-lock! my-lock)\n  (unwind-protect\n    (do-something-that-might-throw)\n    (mutex-unlock! my-lock)))\n\n;; PATTERN: Rate limiter with mutex + timing\n(def _api-lock (make-mutex 'api-lock))\n(def _last-call-time 0.0)\n(defconst API-DELAY 0.1)  ;; 100ms between calls\n\n(def (rate-limit!)\n  (mutex-lock! _api-lock)\n  (unwind-protect\n    (let* ((now (exact->inexact (time->seconds (##current-time))))\n           (elapsed (fl- now _last-call-time)))\n      (when (fl< elapsed API-DELAY)\n        (thread-sleep! (fl- API-DELAY elapsed)))\n      (set! _last-call-time\n        (exact->inexact (time->seconds (##current-time)))))\n    (mutex-unlock! _api-lock)))\n\n;; DIAGNOSTIC: Deadlock symptoms in Gerbil:\n;; - Program hangs after first API error\n;; - GDB backtrace shows ##mutex-lock-out-of-line!\n;; - Error log shows \"Deadlock detected\" with mutex name",
    "notes": "unwind-protect guarantees the cleanup form (mutex-unlock!) runs regardless of whether the body completes normally or throws an exception. This is analogous to try/finally in other languages. Without it, any exception between lock and unlock permanently locks the mutex. This is especially critical in rate-limiting code where API calls may throw network exceptions, timeout errors, or AWS service errors. The deadlock typically manifests on the SECOND call after the first exception.",
    "related": [
      "srfi-19-current-time-shadows-gambit",
      "error-handling"
    ]
  },
  {
    "id": "error-message-returns-false-for-non-error",
    "title": "error-message returns #f for non-Gerbil-Error exceptions — use display-exception",
    "tags": [
      "error-message",
      "exception",
      "display-exception",
      "error",
      "catch",
      "non-error",
      "gambit",
      "gotcha",
      "exception->string"
    ],
    "imports": [
      ":std/error"
    ],
    "code": ";; PROBLEM: (error-message e) only works for Gerbil Error objects.\n;; For Gambit exceptions, AWS errors, or other non-Error exceptions,\n;; it returns #f — making error messages invisible.\n;;\n;; WRONG — loses error information for non-Error exceptions:\n;; (try (some-operation)\n;;   (catch (e)\n;;     (displayln \"Error: \" (error-message e))))\n;; ;; Prints: \"Error: #f\" for Gambit/AWS exceptions\n\n;; CORRECT — use display-exception which handles ALL exception types:\n(def (exception->string e)\n  \"Convert any exception to a readable string.\"\n  (with-output-to-string (lambda () (display-exception e))))\n\n;; Usage in catch blocks:\n(try (some-operation)\n  (catch (e)\n    (displayln \"Error: \" (exception->string e))))\n\n;; WHY: Gerbil has multiple exception types:\n;; - (Error message irritants where) — Gerbil's own error type\n;;   → (error-message e) works, returns the message string\n;;\n;; - Gambit exceptions (error-exception, type-exception, etc.)\n;;   → (error-message e) returns #f\n;;   → (display-exception e port) works for all types\n;;\n;; - AWS service errors (from gerbil-aws)\n;;   → Usually Gambit error-exception objects\n;;   → (error-message e) returns #f\n;;\n;; display-exception is Gambit's universal exception printer.\n;; It knows how to format ALL exception types including stack traces.",
    "notes": "This is a common gotcha when writing generic error handlers. error-message is defined on the Gerbil Error struct and returns the 'message' slot. But catch (e) catches ALL exceptions, not just Gerbil Errors. Gambit runtime exceptions (type errors, arity errors, I/O errors, network errors) are NOT Gerbil Error objects. The exception->string helper using display-exception is the universal solution. Also: (object->string e) sometimes works but may not include the full formatted error message that display-exception provides.",
    "related": [
      "error-handling",
      "custom-error",
      "deferror-class"
    ]
  },
  {
    "id": "gerbil-json-arrays-are-lists-not-vectors",
    "title": "Gerbil JSON arrays are lists, not vectors — never use (vector? x) to check",
    "tags": [
      "json",
      "vector",
      "list",
      "array",
      "vector?",
      "read-json",
      "gerbil-aws",
      "ensure-list",
      "gotcha",
      "silent-failure"
    ],
    "imports": [
      ":std/text/json"
    ],
    "code": ";; PROBLEM: Gerbil's read-json (and gerbil-aws JSON API responses) return\n;; JSON arrays as Scheme LISTS, not vectors. Code that checks (vector? x)\n;; silently drops all data because (vector? '(1 2 3)) => #f.\n;;\n;; This is a SILENT FAILURE — no error, no exception, just empty results.\n\n;; WRONG — silently discards all JSON array data:\n;; (let ((results (hget resp \"ResultsByTime\")))\n;;   (if (vector? results)          ;; ALWAYS #f for JSON arrays!\n;;     (vector->list results)       ;; never reached\n;;     []))                         ;; always returns empty list\n\n;; WRONG — silently skips processing:\n;; (let ((groups (hget resp \"Groups\")))\n;;   (when (vector? groups)         ;; ALWAYS #f!\n;;     (for-each process groups)))  ;; never runs\n\n;; CORRECT — use a defensive ensure-list helper:\n(def (ensure-list v)\n  \"Coerce a vector, list, or other value to a list.\"\n  (cond ((list? v) v)\n        ((vector? v) (vector->list v))  ;; handles the rare vector case\n        (else [])))\n\n;; Usage:\n(let ((results (ensure-list (hget resp \"ResultsByTime\"))))\n  (for-each process results))\n\n;; For extracting the first element of a \"Keys\" array:\n;; WRONG:\n;; (if (vector? keys) (vector-ref keys 0) \"Unknown\")\n;; CORRECT:\n(let ((ks (ensure-list keys)))\n  (if (pair? ks) (car ks) \"Unknown\"))\n\n;; WHY THIS HAPPENS:\n;; - Gerbil's :std/text/json read-json maps JSON arrays to Scheme lists\n;; - gerbil-aws JSON API (Cost Explorer, Lambda, etc.) uses read-json\n;; - Many AWS SDK examples in other languages use arrays/vectors,\n;;   so it's natural to write (vector? ...) but WRONG in Gerbil\n;; - The gerbil-aws Query API (EC2, RDS, etc.) also returns lists\n;;   (from XML member parsing), never vectors",
    "notes": "This is one of the most insidious bugs because it causes SILENT data loss — no exceptions, no errors, just empty results everywhere. The code appears to run successfully but produces no output. Diagnosis: add (displayln (object-type results)) to see that results is a list, not a vector. Prevention: never use (vector? x) to guard JSON array processing — use (list? x) or the ensure-list helper instead. This applies to ALL gerbil-aws responses (both Query API and JSON API) and to any data parsed by Gerbil's read-json.",
    "related": [
      "gerbil-aws-query-vs-json-response-keys",
      "json-parse"
    ]
  },
  {
    "id": "ec2-xml-lowercase-camelcase-keys",
    "title": "EC2 Query API XML uses lowercase camelCase keys, not PascalCase",
    "tags": [
      "ec2",
      "query-api",
      "xml",
      "camelCase",
      "lowercase",
      "regionName",
      "instanceId",
      "symbol",
      "key",
      "gotcha"
    ],
    "imports": [],
    "code": ";; PROBLEM: AWS API documentation shows PascalCase names like\n;; \"RegionName\", \"InstanceId\", \"VolumeId\". But the EC2 Query API\n;; XML response uses lowercase camelCase: <regionName>, <instanceId>.\n;;\n;; After XML parsing in gerbil-aws, these become lowercase symbols:\n;;   'regionName  NOT 'RegionName\n;;   'instanceId  NOT 'InstanceId\n;;   'volumeId    NOT 'VolumeId\n;;   'vpcId       NOT 'VpcId\n;;\n;; WRONG — throws UnboundKeyError:\n;; (hash-ref region-hash 'RegionName)   ;; key not found!\n;; (hash-ref instance 'InstanceId)      ;; key not found!\n;;\n;; CORRECT — use lowercase camelCase:\n;; (hash-ref region-hash 'regionName)   ;; works\n;; (hash-ref instance 'instanceId)      ;; works\n;;\n;; This applies to ALL ec2-action/items responses in gerbil-aws:\n;;   describe-regions     → 'regionName, 'regionEndpoint\n;;   describe-instances   → 'instanceId, 'instanceType, 'imageId\n;;   describe-volumes     → 'volumeId, 'size, 'volumeType\n;;   describe-snapshots   → 'snapshotId, 'volumeId, 'startTime\n;;   describe-addresses   → 'publicIp, 'allocationId\n;;   describe-nat-gateways → 'natGatewayId, 'vpcId, 'subnetId\n;;   describe-images      → 'imageId, 'name, 'creationDate\n;;\n;; But OTHER Query API services may use different casing:\n;;   CloudWatch  → 'MetricName, 'Namespace (PascalCase)\n;;   RDS         → 'DBInstanceIdentifier (PascalCase)\n;;   ELBv2       → 'LoadBalancerArn (PascalCase)\n;;\n;; The casing matches the actual XML element names in each service's\n;; API response, which varies by service. EC2 happens to use lowercase.",
    "notes": "The AWS documentation and CLI both show PascalCase (RegionName, InstanceId), but EC2's actual XML response uses lowercase camelCase. Other Query API services like CloudWatch and RDS use PascalCase in their XML. There's no universal rule — you must check the actual XML element names for each service. When in doubt, add a debug line: (displayln (hash->list my-hash)) to see the actual keys.",
    "related": [
      "gerbil-aws-query-vs-json-response-keys"
    ]
  },
  {
    "id": "write-json-cannot-serialize-cons-pairs",
    "title": "write-json cannot serialize cons pairs from hash->list — convert to hashes first",
    "tags": [
      "write-json",
      "hash->list",
      "cons",
      "pair",
      "alist",
      "serialize",
      "json",
      "Missing method",
      "gotcha"
    ],
    "imports": [
      ":std/text/json"
    ],
    "code": ";; PROBLEM: (hash->list ht) returns alist pairs: ((\"key1\" . val1) (\"key2\" . val2) ...)\n;; write-json does NOT know how to serialize cons pairs (dotted pairs).\n;; It throws: \"Missing method --- irritants: (\"key\" . value) :json\"\n;;\n;; This commonly happens when you sort a hash table and embed the\n;; sorted result in a data structure that later gets written to JSON.\n\n;; WRONG — crashes at JSON serialization time:\n;; (def sorted-services\n;;   (sort (hash->list service-totals)\n;;         (lambda (a b) (> (cdr a) (cdr b)))))\n;; (hash-put! data \"top_services\" sorted-services)\n;; ;; Later: (write-json data port)\n;; ;; ERROR: Missing method (\"EC2 - Other\" . 1073969.83) :json\n\n;; CORRECT — convert cons pairs to hashes before storing:\n(import :std/text/json)\n(def sorted-services\n  (sort (hash->list service-totals)\n        (lambda (a b) (> (cdr a) (cdr b)))))\n\n;; Convert alist pairs to list of hashes for JSON serialization:\n(def json-safe-services\n  (map (lambda (p) (hash (\"service\" (car p)) (\"cost\" (cdr p))))\n       sorted-services))\n\n(hash-put! data \"top_services\" json-safe-services)\n;; Now write-json works: [{\"service\":\"EC2\",\"cost\":1073969.83}, ...]\n\n;; write-json handles these types:\n;;   hash-table  → JSON object {\"key\": value}\n;;   list        → JSON array [...]\n;;   string      → JSON string \"...\"\n;;   number      → JSON number\n;;   #t / #f     → true / false\n;;   void / #!void → null\n;;\n;; It does NOT handle:\n;;   cons pair (\"k\" . v) → ERROR: Missing method :json\n;;   struct             → ERROR (unless has :json method)\n;;   symbol             → ERROR",
    "notes": "This error only surfaces at JSON write time, not when building the data structure. It's easy to miss during development if you only test the markdown output (which uses car/cdr on pairs directly). The fix is to convert alist pairs to hashes at the point where they're stored in the data structure, before they reach write-json. An alternative is to define a recursive sanitizer that walks the data tree and converts all cons pairs to hashes, but it's cleaner to convert at the source.",
    "related": [
      "gerbil-json-arrays-are-lists-not-vectors",
      "json-generate"
    ]
  },
  {
    "id": "gerbil-aws-sts-nested-response",
    "title": "STS GetCallerIdentity returns nested hash — Account is under GetCallerIdentityResult",
    "tags": [
      "sts",
      "get-caller-identity",
      "account-id",
      "nested",
      "gerbil-aws",
      "query-api"
    ],
    "imports": [
      ":gerbil-aws/sts/api",
      ":gerbil-aws/sts/operations"
    ],
    "code": ";; gerbil-aws STS uses the Query API (XML). The GetCallerIdentity\n;; response XML is:\n;;   <GetCallerIdentityResponse>\n;;     <GetCallerIdentityResult>\n;;       <Account>123456789012</Account>\n;;       <Arn>arn:aws:iam::123456789012:user/me</Arn>\n;;       <UserId>AIDAXXXXXXX</UserId>\n;;     </GetCallerIdentityResult>\n;;     <ResponseMetadata>...</ResponseMetadata>\n;;   </GetCallerIdentityResponse>\n;;\n;; After aws-response->hash, the result is a NESTED hash:\n;;   {GetCallerIdentityResult: {Account: \"123456789012\", Arn: \"...\", UserId: \"...\"},\n;;    ResponseMetadata: {RequestId: \"...\"}}\n\n;; WRONG — 'Account is NOT at the top level:\n;; (def identity (get-caller-identity sts))\n;; (hash-ref identity 'Account \"\")  ;; => \"\" (always!)\n\n;; CORRECT — navigate to GetCallerIdentityResult first:\n(def sts (STSClient))\n(def identity (get-caller-identity sts))\n(def result (hash-ref identity 'GetCallerIdentityResult identity))\n(def account-id (hash-ref result 'Account \"\"))\n;; account-id => \"123456789012\"\n\n;; The same pattern applies to other STS operations:\n;; - AssumeRole → 'AssumeRoleResult → 'Credentials, 'AssumedRoleUser\n;; - GetSessionToken → 'GetSessionTokenResult → 'Credentials",
    "notes": "This is because gerbil-aws's aws-response->hash (in aws/xml.ss) converts the entire XML response to a nested hash, including the *Result wrapper element. The Query API always wraps the actual data in an ActionNameResult element. Using (hash-ref identity 'GetCallerIdentityResult identity) as a fallback ensures forward compatibility if the library ever changes to unwrap automatically.",
    "related": [
      "gerbil-aws-query-vs-json-response-keys",
      "ec2-lowercase-camelcase-keys"
    ]
  },
  {
    "id": "gerbil-aws-empty-xml-tagset-string",
    "title": "Empty XML elements like tagSet become \"\" not [] — guard with list? before iterating",
    "tags": [
      "xml",
      "sxml",
      "tagSet",
      "empty-element",
      "type-exception",
      "gerbil-aws",
      "ec2"
    ],
    "imports": [],
    "code": ";; PROBLEM: In gerbil-aws EC2 responses, empty XML elements like <tagSet/>\n;; are parsed by sxml->hash as \"\" (empty string), not [] (empty list).\n;;\n;; This happens because of this clause in sxml->hash:\n;;   ((null? (cdr element)) \"\")  ;; Empty element: (tag) → \"\"\n;;\n;; So when a resource has no tags:\n;;   <tagSet/>  →  \"\" in the hash table\n;;\n;; And (hash-ref resource 'tagSet []) returns \"\" (key exists with value \"\"),\n;; NOT the default [].\n\n;; WRONG — crashes with type-exception: PAIR expected from (car \"\")\n;; (def (get-name tags)\n;;   (let loop ((ts (or tags [])))  ;; (or \"\" []) => \"\" (truthy!)\n;;     (if (null? ts) \"\"            ;; (null? \"\") => #f\n;;       (let ((t (car ts)))        ;; (car \"\") => TYPE EXCEPTION!\n;;         ...))))\n\n;; CORRECT — check (list? tags) before iterating:\n(def (get-name tags)\n  (let ((ts (if (list? tags) tags [])))\n    (let loop ((ts ts))\n      (if (null? ts) \"\"\n        (let ((t (car ts)))\n          (if (and (hash-table? t)\n                   (string=? (hash-ref t 'key \"\") \"Name\"))\n            (hash-ref t 'value \"\")\n            (loop (cdr ts))))))))\n\n;; This affects ANY EC2 field that can be an empty XML element:\n;;   tagSet, blockDeviceMapping, networkInterfaceSet,\n;;   securityGroupSet, natGatewayAddressSet, etc.\n;;\n;; General rule: always use (list? x) not (or x []) when the\n;; value might be \"\" from empty XML elements.",
    "notes": "This is a silent type-exception that only manifests when a resource happens to have no tags (or other empty set elements). Resources with at least one tag work fine because tagSet gets parsed as a list of items. The bug is intermittent — it depends on whether specific resources in specific regions have tags. Use (if (list? val) val []) instead of (or val []) for XML-parsed set fields.",
    "related": [
      "ec2-lowercase-camelcase-keys",
      "gerbil-aws-query-vs-json-response-keys"
    ]
  },
  {
    "id": "aws-pricing-api-endpoint",
    "title": "AWS Pricing API endpoint is api.pricing not pricing — CloudFront 403 on wrong endpoint",
    "tags": [
      "aws",
      "pricing",
      "endpoint",
      "api.pricing",
      "cloudfront",
      "403",
      "gerbil-aws",
      "json-api"
    ],
    "imports": [
      ":gerbil-aws/aws/json-api"
    ],
    "code": ";; PROBLEM: The AWS Pricing API uses a DIFFERENT endpoint pattern\n;; than most AWS services. The standard pattern is:\n;;   service.region.amazonaws.com\n;;\n;; But the Pricing API uses:\n;;   api.pricing.region.amazonaws.com\n;;\n;; Using the standard pattern (pricing.us-east-1.amazonaws.com) hits\n;; a CloudFront distribution that only serves GET requests for the\n;; pricing website. POST requests get:\n;;   403 ERROR: \"This distribution is not configured to allow the\n;;   HTTP request method that was used for this request.\"\n\n;; WRONG — hits CloudFront, gets 403:\n;; (AWSJsonClient service: \"pricing\"\n;;               target-prefix: \"AWSPriceListService\"\n;;               region: \"us-east-1\")\n;; ;; Constructs endpoint: pricing.us-east-1.amazonaws.com\n\n;; CORRECT — explicitly set the api.pricing endpoint:\n(def pricing-client\n  (AWSJsonClient service: \"pricing\"\n                 target-prefix: \"AWSPriceListService\"\n                 endpoint: \"api.pricing.us-east-1.amazonaws.com\"\n                 region: \"us-east-1\"))\n\n;; For a configurable region:\n(def (make-pricing-client (region \"us-east-1\"))\n  (AWSJsonClient service: \"pricing\"\n                 target-prefix: \"AWSPriceListService\"\n                 endpoint: (string-append \"api.pricing.\" region \".amazonaws.com\")\n                 region: region))\n\n;; Other AWS services with non-standard endpoints:\n;;   Cost Explorer: ce.us-east-1.amazonaws.com (standard pattern, works)\n;;   S3: s3.region.amazonaws.com or s3.amazonaws.com (path-style)\n;;   STS: sts.amazonaws.com (global) or sts.region.amazonaws.com (regional)",
    "notes": "The AWS Pricing API is only available in us-east-1 and ap-south-1. Always pass the endpoint explicitly when creating the client. The AWSJsonClient default endpoint construction (service.region.amazonaws.com) does NOT work for the Pricing API. This manifests as a confusing CloudFront 403 error rather than an obvious endpoint error.",
    "related": [
      "gerbil-aws-query-vs-json-response-keys"
    ]
  },
  {
    "id": "aws-pricing-api-content-type-1-1",
    "title": "AWS Pricing API requires content-type application/x-amz-json-1.1, not 1.0",
    "tags": [
      "pricing",
      "aws",
      "content-type",
      "json",
      "1.1",
      "AWSJsonClient",
      "UnknownOperationException",
      "404"
    ],
    "imports": [
      ":gerbil-aws/aws/json-api"
    ],
    "code": ";; PROBLEM: The AWS Pricing API requires content-type \"application/x-amz-json-1.1\"\n;; but AWSJsonClient defaults to \"application/x-amz-json-1.0\".\n;;\n;; Without the correct content-type, ALL Pricing API calls fail with:\n;;   HTTP 404: <UnknownOperationException/>\n;;\n;; This is a SILENT CASCADING FAILURE — pricing lookups return #f,\n;; causing downstream code to skip hundreds of resources.\n\n;; WRONG — uses default content-type 1.0, gets 404 on every call:\n;; (def (make-pricing-client (region \"us-east-1\"))\n;;   (AWSJsonClient service: \"pricing\"\n;;                  target-prefix: \"AWSPriceListService\"\n;;                  endpoint: (string-append \"api.pricing.\" region \".amazonaws.com\")\n;;                  region: region))\n\n;; CORRECT — explicitly set content-type to 1.1:\n(def (make-pricing-client (region \"us-east-1\"))\n  (AWSJsonClient service: \"pricing\"\n                 target-prefix: \"AWSPriceListService\"\n                 endpoint: (string-append \"api.pricing.\" region \".amazonaws.com\")\n                 content-type: \"application/x-amz-json-1.1\"\n                 region: region))\n\n;; AWS services and their JSON protocol versions:\n;;   application/x-amz-json-1.1:\n;;     Pricing, Lambda, CloudWatch Logs, ECS, SSM, Secrets Manager\n;;   application/x-amz-json-1.0:\n;;     DynamoDB, Compute Optimizer, Cost Optimization Hub, SWF\n;;\n;; Check the AWS service's API reference for the correct version.\n;; The version is listed in the \"Common Headers\" section of each API doc.",
    "notes": "The AWSJsonClient in gerbil-aws defaults content-type to \"application/x-amz-json-1.0\" (set in json-api.ss line 45). AWS services that require 1.1 will reject ALL requests with HTTP 404 UnknownOperationException. This is extremely hard to debug because: (1) the error is XML even though it's a JSON API, (2) 404 suggests a wrong URL, not a wrong content-type, (3) the endpoint IS correct (api.pricing.region.amazonaws.com). Combined with the endpoint issue (see aws-pricing-api-endpoint recipe), there are TWO things you must get right for the Pricing API: the api.pricing prefix AND the 1.1 content-type.",
    "related": [
      "aws-pricing-api-endpoint"
    ]
  },
  {
    "id": "gerbil-aws-strip-ns-uri-namespace-bug",
    "title": "gerbil-aws strip-ns breaks on full URI namespace prefixes — finds first colon not last",
    "tags": [
      "strip-ns",
      "namespace",
      "XML",
      "SXML",
      "URI",
      "gerbil-aws",
      "STS",
      "RDS",
      "ELBv2"
    ],
    "imports": [],
    "code": ";; PROBLEM: gerbil-aws's strip-ns function in aws/xml.ss finds the FIRST\n;; colon in a symbol name, but URI namespace prefixes contain multiple colons.\n;;\n;; The function is:\n;;   (def (strip-ns sym)\n;;     (let (s (symbol->string sym))\n;;       (let (pos (string-contains s \":\"))   ;; finds FIRST \":\"\n;;         (if pos\n;;           (string->symbol (substring s (+ pos 1) (string-length s)))\n;;           sym))))\n;;\n;; For EC2, namespaces are mapped to short prefixes like \"ec2:\",\n;; so strip-ns works: 'ec2:instanceId → 'instanceId\n;;\n;; But for services WITHOUT namespace mappings (STS, RDS, ELBv2, CloudWatch),\n;; the XML parser produces full URI prefixes:\n;;   '//sts.amazonaws.com/doc/2011-06-15/:Account\n;;   '//rds.amazonaws.com/doc/2014-10-31/:DBInstances\n;;\n;; strip-ns finds the first \":\" in \"//sts.amazonaws.com/doc/2011-06-15/:Account\"\n;; which is in \"http:\" — producing '//sts.amazonaws.com/doc/2011-06-15/:Account\n;; (unchanged!) instead of 'Account.\n;;\n;; WORKAROUND: Add namespace mappings to your client, like EC2 does:\n;; (AWSClient ...\n;;   namespaces: '((\"https://sts.amazonaws.com/doc/2011-06-15/\" . \"sts\")))\n;;\n;; Or fix strip-ns to find the LAST colon:\n(def (strip-ns sym)\n  (let* ((s (symbol->string sym))\n         (len (string-length s)))\n    (let loop ((i (- len 1)))\n      (cond\n        ((< i 0) sym)\n        ((char=? (string-ref s i) #\\:)\n         (string->symbol (substring s (+ i 1) len)))\n        (else (loop (- i 1)))))))\n\n;; Test:\n;; (strip-ns '//sts.amazonaws.com/doc/2011-06-15/:Account) => 'Account\n;; (strip-ns 'ec2:instanceId) => 'instanceId\n;; (strip-ns 'noNamespace) => 'noNamespace\n\n;; AFFECTED SERVICES (no namespace mappings by default):\n;;   STS  — get-caller-identity returns empty account-id\n;;   RDS  — describe-db-instances returns 0 items\n;;   ELBv2 — describe-load-balancers returns 0 items\n;;   CloudWatch — some responses may be affected\n;;\n;; EC2 WORKS because it has explicit namespace mappings in ec2/xml.ss:\n;;   '((\"http://ec2.amazonaws.com/doc/2016-11-15/\" . \"ec2\"))",
    "notes": "This is a bug in gerbil-aws/aws/xml.ss. The proper fix is to change strip-ns to find the LAST colon instead of the first. The workaround is to add namespace mappings to each client (like EC2 does), but this requires knowing the exact namespace URI for each AWS service version. The bug causes SILENT DATA LOSS — API calls succeed (HTTP 200) but the response parsing can't match expected keys, so functions return empty lists or empty strings. Symptoms: get-account-id returns \"\", describe-db-instances returns 0 items, describe-load-balancers returns 0 items.",
    "related": [
      "aws-pricing-api-endpoint",
      "gerbil-aws-query-vs-json-response-keys",
      "ec2-lowercase-camelcase-keys"
    ]
  }
]
