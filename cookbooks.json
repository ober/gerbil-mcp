[
  {
    "id": "crypto-digest-sha256-md5",
    "title": "Compute SHA256 or MD5 hash of data",
    "tags": [
      "sha256",
      "md5",
      "hash",
      "digest",
      "crypto",
      "checksum",
      "bytes"
    ],
    "imports": [
      ":std/crypto/digest"
    ],
    "code": "(import :std/crypto/digest)\\n\\n;; SHA256 of a u8vector — returns u8vector\\n(def hash256 (sha256 #u8(104 101 108 108 111)))\\n\\n;; SHA256 of a string (convert to bytes first)\\n(def hash256-str (sha256 (string->bytes \\\"hello\\\")))\\n\\n;; MD5 of bytes — returns u8vector\\n(def hash-md5 (md5 (string->bytes \\\"hello\\\")))\\n\\n;; To get hex string, combine with :std/text/hex\\n(import :std/text/hex)\\n(hex-encode (sha256 (string->bytes \\\"hello\\\")))\\n;; => \\\"2cf24dba5fb0a30e26e83b2ac5b9e29e1b161e5c1fa7425e73043362938b9824\\\"",
    "notes": "sha256 and md5 each take a single u8vector argument and return a u8vector. Other available digests: sha1, sha384, sha512, ripemd160, blake2s256, blake2b512. All from :std/crypto/digest.",
    "related": [
      "base64-encode-decode"
    ]
  },
  {
    "id": "base64-encode-decode",
    "title": "Base64 encode and decode data",
    "tags": [
      "base64",
      "encode",
      "decode",
      "bytes",
      "string",
      "u8vector",
      "binary"
    ],
    "imports": [
      ":std/text/base64"
    ],
    "code": "(import :std/text/base64)\\n\\n;; Encode u8vector to base64 string\\n(u8vector->base64-string (string->bytes \\\"hello\\\"))\\n;; => \\\"aGVsbG8=\\\"\\n\\n;; Decode base64 string to u8vector\\n(base64-string->u8vector \\\"aGVsbG8=\\\")\\n;; => #u8(104 101 108 108 111)\\n\\n;; Encode/decode raw strings\\n(base64-encode \\\"hello\\\")\\n;; => \\\"aGVsbG8=\\\"\\n(base64-decode \\\"aGVsbG8=\\\")\\n;; => \\\"hello\\\"",
    "notes": "u8vector->base64-string and base64-string->u8vector work with binary data. base64-encode and base64-decode work with strings. Useful for HTTP headers like Content-MD5 which require base64-encoded digests.",
    "related": [
      "crypto-digest-sha256-md5"
    ]
  },
  {
    "id": "deferror-class-defraise",
    "title": "Define error class with deferror-class and defraise/context",
    "tags": [
      "error",
      "exception",
      "deferror",
      "defraise",
      "custom",
      "raise",
      "class",
      "context"
    ],
    "imports": [
      ":std/error"
    ],
    "code": "(import :std/error)\\n\\n;; Define an error class (creates predicate automatically)\\n(deferror-class (MyServiceError Error) () my-service-error?)\\n\\n;; Define a raise helper with automatic 'where' context\\n(defraise/context (raise-my-error where message irritants ...)\\n  (MyServiceError message irritants: [irritants ...]))\\n\\n;; Usage — 'where' is automatically set to the calling function name\\n(def (connect host port)\\n  (unless host\\n    (raise-my-error connect \\\"host is required\\\" \\\"host\\\"))\\n  ...)\\n\\n;; Catch it\\n(try (connect #f 80)\\n  (catch (my-service-error? e)\\n    (displayln \\\"Service error: \\\" (error-message e))))",
    "notes": "deferror-class is more concise than defstruct for error types — it automatically inherits Error fields (message, irritants, where). defraise/context auto-fills the 'where' field. The first arg to defraise/context after 'where' becomes the error message, rest become irritants.",
    "related": [
      "error-handling"
    ]
  },
  {
    "id": "cli-getopt-subcommands",
    "title": "Build CLI with getopt (v0.19+ API)",
    "tags": [
      "cli",
      "getopt",
      "command",
      "flag",
      "option",
      "argument",
      "command-line",
      "program"
    ],
    "imports": [
      ":std/cli/getopt",
      ":std/sugar"
    ],
    "code": "(import :std/cli/getopt :std/sugar)\n\n;; Simple CLI with options (no subcommands)\n(def (main . args)\n  (call-with-getopt\n    (lambda (opt)\n      (let-hash opt\n        (when .?verbose (displayln \"verbose mode\"))\n        (displayln \"output: \" (or .?output \"default.txt\"))))\n    args\n    program: \"my-tool\"\n    help: \"My CLI tool\"\n    (flag 'verbose \"--verbose\" \"-v\"\n      help: \"Verbose output\")\n    (option 'output \"--output\" \"-o\"\n      help: \"Output file\"\n      value: identity)))\n\n;; CLI with subcommands\n(def list-cmd\n  (command 'list\n    help: \"List items\"\n    (option 'filter \"--filter\" \"-f\" default: #f help: \"Filter\")))\n\n(def create-cmd\n  (command 'create\n    help: \"Create an item\"\n    (argument 'name help: \"Item name\")))\n\n(def (main . args)\n  (call-with-getopt\n    (lambda (opt)\n      (let-hash opt\n        (case .command\n          ((list) (displayln \"listing with filter: \" .?filter))\n          ((create) (displayln \"creating: \" .name)))))\n    args\n    program: \"my-tool\"\n    help: \"My CLI tool\"\n    list-cmd create-cmd))",
    "notes": "IMPORTANT: In Gerbil v0.19+, call-with-getopt signature is: (call-with-getopt handler args program: \"name\" help: \"...\" options...). The handler lambda comes FIRST, args SECOND, then program: keyword. Older examples showing (call-with-getopt \"name\" args handler ...) are WRONG for v0.19+. For exe builds, the main module MUST have (export main). Use identity instead of string->string for option value converters.",
    "related": [
      "let-hash-destructure"
    ]
  },
  {
    "id": "srfi19-date-time-format",
    "title": "Date/time formatting with SRFI-19",
    "tags": [
      "date",
      "time",
      "srfi",
      "srfi-19",
      "format",
      "timestamp",
      "iso8601",
      "utc",
      "current"
    ],
    "imports": [
      ":std/srfi/19"
    ],
    "code": "(import :std/srfi/19)\\n\\n;; Current date/time (UTC)\\n(def now (current-date))\\n\\n;; Format as ISO 8601 timestamp\\n(date->string now \\\"~Y~m~dT~H~M~SZ\\\")\\n;; => \\\"20250115T143052Z\\\"\\n\\n;; Format date portion only\\n(date->string now \\\"~Y~m~d\\\")\\n;; => \\\"20250115\\\"\\n\\n;; Format human-readable\\n(date->string now \\\"~Y-~m-~d ~H:~M:~S\\\")\\n;; => \\\"2025-01-15 14:30:52\\\"\\n\\n;; Common format directives:\\n;;   ~Y  4-digit year    ~m  2-digit month   ~d  2-digit day\\n;;   ~H  24-hour hour    ~M  minute          ~S  second\\n;;   ~Z  timezone offset  ~A  weekday name    ~B  month name",
    "notes": "current-date returns UTC. date->string uses SRFI-19 format directives (tilde-based, not strftime). Commonly needed for AWS signature timestamps (yyyyMMddTHHmmssZ format) and date-scoped signing keys (yyyyMMdd)."
  },
  {
    "id": "xml-parse-sxml",
    "title": "Parse XML string to SXML",
    "tags": [
      "xml",
      "parse",
      "sxml",
      "markup",
      "html",
      "response",
      "api"
    ],
    "imports": [
      ":std/markup/xml"
    ],
    "code": "(import :std/markup/xml)\\n\\n;; Parse XML string to SXML tree\\n(def sxml\\n  (call-with-input-string\\n    \\\"<root><item>hello</item><item>world</item></root>\\\"\\n    read-xml))\\n;; => (*TOP* (root (item \\\"hello\\\") (item \\\"world\\\")))\\n\\n;; GOTCHA: XML with <?xml ...?> declaration produces a *PI* node\\n(def sxml-with-pi\\n  (call-with-input-string\\n    \\\"<?xml version=\\\\\\\"1.0\\\\\\\" encoding=\\\\\\\"UTF-8\\\\\\\"?><root><item>hello</item></root>\\\"\\n    read-xml))\\n;; => (*TOP* (*PI* xml \\\"version=...\\\") (root (item \\\"hello\\\")))\\n;; Note the *PI* node — you must skip it when searching for the root element!\\n\\n;; Navigate SXML — it's just nested lists\\n;; (tag child1 child2 ...) where children are strings or nested tags\\n(def root (cadr sxml))    ;; skip *TOP*, get (root ...)\\n(def items (cdr root))    ;; get children: ((item \\\"hello\\\") (item \\\"world\\\"))\\n(def first-text (cadar items))  ;; => \\\"hello\\\"",
    "notes": "read-xml from :std/markup/xml returns SXML (S-expression XML). It takes a single port argument. The result is always wrapped in (*TOP* ...). IMPORTANT: When the XML source has a <?xml ...?> processing instruction, a (*PI* xml ...) node appears in the SXML tree — you must skip it (along with @ and *NAMESPACES*) when traversing to find the root element, or it will be mistaken for the content root. See the sxml-skip-pi-nodes recipe for a correct traversal pattern. Use cadr to skip *TOP*, then navigate with car/cdr/assoc.",
    "related": [
      "sxml-skip-pi-nodes"
    ]
  },
  {
    "id": "using-typed-struct-access",
    "title": "Typed struct field access with using macro",
    "tags": [
      "using",
      "struct",
      "typed",
      "access",
      "field",
      "slot",
      "dot",
      "optimize",
      "defstruct"
    ],
    "imports": [],
    "code": "(defstruct point (x y) final: #t)\\n(defstruct (point3d point) (z) final: #t)\\n\\n;; using gives typed access — dot notation without dynamic dispatch\\n(def (distance p1 p2)\\n  (using ((p1 :- point) (p2 :- point))\\n    (sqrt (+ (expt (- p1.x p2.x) 2)\\n             (expt (- p1.y p2.y) 2)))))\\n\\n(distance (make-point 0 0) (make-point 3 4))  ;; => 5.0\\n\\n;; Single binding form\\n(def (describe-point p)\\n  (using (p :- point)\\n    (format \\\"(~a, ~a)\\\" p.x p.y)))\\n\\n;; Works with mutation too\\n(def (move-point! p dx dy)\\n  (using (p :- point)\\n    (set! p.x (+ p.x dx))\\n    (set! p.y (+ p.y dy))))",
    "notes": "using provides typed struct access that compiles to direct field access (no hash-table lookup). Use with defstruct types. The :- annotation is a type declaration. Pair with final: #t on defstruct for best optimization. Unlike (@ obj slot), using is compile-time checked."
  },
  {
    "id": "let-hash-destructure",
    "title": "Destructure hash tables with let-hash",
    "tags": [
      "let-hash",
      "hash",
      "destructure",
      "sugar",
      "optional",
      "field",
      "config",
      "options"
    ],
    "imports": [
      ":std/sugar"
    ],
    "code": "(import :std/sugar)\\n\\n(def config (hash (name \\\"app\\\") (port 8080) (debug #f)))\\n\\n(let-hash config\\n  ;; .field — required (hash-ref with symbol key, error if missing)\\n  (displayln \\\"name: \\\" .name)\\n\\n  ;; .?field — optional (hash-get, returns #f if missing)\\n  (when .?debug\\n    (displayln \\\"debug mode\\\"))\\n\\n  ;; Use .?field with defaults via 'or'\\n  (def timeout (or .?timeout 30))\\n  (displayln \\\"port: \\\" .port \\\" timeout: \\\" timeout))\\n\\n;; With string keys, use .$field\\n(def headers (hash (\\\"Content-Type\\\" \\\"text/html\\\") (\\\"X-Custom\\\" \\\"val\\\")))\\n(let-hash headers\\n  (displayln .$Content-Type))  ;; uses string key \\\"Content-Type\\\"",
    "notes": "let-hash is from :std/sugar. Three accessor forms: .field (symbol key, required — errors if missing), .?field (symbol key, optional — returns #f), .$field (string key, optional). Very useful for CLI option hashes from getopt and API response hashes. Nests well — (let-hash outer (let-hash .inner-hash ...)).",
    "related": [
      "cli-getopt-subcommands"
    ]
  },
  {
    "id": "parse-ini-file",
    "title": "Parse INI/config file into nested hash tables",
    "tags": [
      "ini",
      "config",
      "parse",
      "file",
      "section",
      "profile",
      "aws",
      "credentials",
      "settings"
    ],
    "imports": [
      ":std/sugar",
      ":std/srfi/13"
    ],
    "code": "(import :std/sugar (only-in :std/srfi/13 string-trim-both string-prefix? string-index))\\n\\n;; Parse INI file into hash of sections, each section is a hash of key=value\\n(def (parse-ini-file path)\\n  (let ((result (make-hash-table))\\n        (current-section #f))\\n    (when (file-exists? path)\\n      (call-with-input-file path\\n        (lambda (port)\\n          (let loop ()\\n            (let (line (read-line port))\\n              (unless (eof-object? line)\\n                (let (trimmed (string-trim-both line))\\n                  (cond\\n                    ((or (equal? trimmed \\\"\\\") (string-prefix? \\\"#\\\" trimmed)\\n                         (string-prefix? \\\";\\\" trimmed))\\n                     (void))  ;; skip blank/comment lines\\n                    ((and (string-prefix? \\\"[\\\" trimmed))\\n                     (let (end (string-index trimmed #\\\\]))\\n                       (when end\\n                         (set! current-section (substring trimmed 1 end))\\n                         (unless (hash-key? result current-section)\\n                           (hash-put! result current-section (make-hash-table))))))\\n                    (else\\n                     (when current-section\\n                       (let (eq-pos (string-index trimmed #\\\\=))\\n                         (when eq-pos\\n                           (let ((key (string-trim-both (substring trimmed 0 eq-pos)))\\n                                 (val (string-trim-both (substring trimmed (+ eq-pos 1)\\n                                                          (string-length trimmed)))))\\n                             (hash-put! (hash-ref result current-section) key val))))))))\\n                (loop)))))))\\n    result))\\n\\n;; Usage:\\n;; (def config (parse-ini-file \\\"~/.aws/credentials\\\"))\\n;; (hash-ref (hash-ref config \\\"default\\\") \\\"aws_access_key_id\\\")",
    "notes": "Handles [section] headers, key=value pairs, blank lines, and # or ; comments. Returns a hash of hashes: outer keys are section names, inner keys are setting names. Useful for parsing AWS credentials/config files, .gitconfig, and similar INI-style configs. Uses string-trim-both and string-index from :std/srfi/13."
  },
  {
    "id": "http-post-form-encoded",
    "title": "HTTP POST with form-url-encoded body",
    "tags": [
      "http",
      "post",
      "form",
      "urlencoded",
      "uri",
      "encode",
      "request",
      "api",
      "query"
    ],
    "imports": [
      ":std/net/request",
      ":std/net/uri"
    ],
    "code": "(import :std/net/request :std/net/uri)\\n\\n;; Build form-encoded body from alist of (key . value) pairs\\n(def params '((\\\"Action\\\" . \\\"DescribeInstances\\\")\\n              (\\\"Version\\\" . \\\"2016-11-15\\\")\\n              (\\\"MaxResults\\\" . \\\"10\\\")))\\n\\n(def body (form-url-encode params))\\n;; => \\\"Action=DescribeInstances&Version=2016-11-15&MaxResults=10\\\"\\n\\n;; POST with form-encoded body\\n(def resp (http-post \\\"https://api.example.com/\\\"\\n            data: body\\n            headers: '((\\\"Content-Type\\\" . \\\"application/x-www-form-urlencoded\\\"))))\\n\\n(request-status resp)   ;; HTTP status code\\n(request-text resp)     ;; response body as string\\n(request-close resp)    ;; release connection",
    "notes": "form-url-encode from :std/net/uri takes an alist of (key . value) string pairs and produces a URL-encoded query string. This is the standard format for AWS Query API services (EC2, STS, IAM, SNS, CloudFormation). Always call request-close after reading the response to release the connection.",
    "related": [
      "http-get",
      "http-post-json"
    ]
  },
  {
    "id": "sigv4-aws-request-signing",
    "title": "AWS SigV4 request signing",
    "tags": [
      "aws",
      "sigv4",
      "signing",
      "signature",
      "authentication",
      "s3",
      "ec2",
      "request",
      "api"
    ],
    "imports": [
      ":std/net/s3/sigv4",
      ":std/crypto/digest",
      ":std/text/hex",
      ":std/srfi/19",
      ":std/net/request"
    ],
    "code": "(import :std/net/s3/sigv4 :std/crypto/digest :std/text/hex\\n        :std/srfi/19 :std/net/request)\\n\\n;; Prepare timestamp and scope\\n(def now (current-date))\\n(def ts (date->string now \\\"~Y~m~dT~H~M~SZ\\\"))     ;; e.g. \\\"20250115T143052Z\\\"\\n(def scopets (date->string now \\\"~Y~m~d\\\"))           ;; e.g. \\\"20250115\\\"\\n(def scope (string-append scopets \\\"/us-east-1/sts\\\")) ;; date/region/service\\n\\n;; Build headers list as alist with :: syntax\\n(def body-bytes (string->bytes \\\"Action=GetCallerIdentity&Version=2011-06-15\\\"))\\n(def body-hash (sha256 body-bytes))\\n(def host \\\"sts.amazonaws.com\\\")\\n(def headers [[\\\"Host\\\" :: host]\\n              [\\\"x-amz-date\\\" :: ts]\\n              [\\\"Content-Type\\\" :: \\\"application/x-www-form-urlencoded\\\"]])\\n\\n;; Create canonical request\\n(def creq (aws4-canonical-request\\n             verb: 'POST uri: \\\"/\\\" query: #f\\n             headers: headers hash: body-hash))\\n\\n;; Generate Authorization header\\n(def auth (aws4-auth scope creq ts headers\\n                     \\\"SECRET_KEY\\\" \\\"ACCESS_KEY\\\"))\\n\\n;; Make the signed request\\n(def signed-headers (cons [\\\"Authorization\\\" :: auth] headers))\\n(def resp (http-post (string-append \\\"https://\\\" host \\\"/\\\")\\n            headers: signed-headers\\n            data: (bytes->string body-bytes)))",
    "notes": "aws4-canonical-request and aws4-auth are from :std/net/s3/sigv4 (works for ALL AWS services, not just S3). The scope format is \\\"YYYYMMDD/region/service\\\". Headers must be an alist with [key :: value] pairs. body-hash is the SHA256 of the request body as a u8vector. For GET requests with no body, use (sha256 #u8()) for the hash.",
    "related": [
      "http-post-form-encoded",
      "crypto-digest-sha256-md5",
      "srfi19-date-time-format"
    ]
  },
  {
    "id": "hash-table-basics",
    "title": "Hash table operations",
    "tags": [
      "hash",
      "table",
      "get",
      "ref",
      "put",
      "key",
      "remove",
      "lookup",
      "default"
    ],
    "imports": [],
    "code": "(def ht (hash (\"name\" \"alice\") (\"age\" 30)))   ;; literal syntax\n(hash-ref ht \"name\")          ;; => \"alice\" (error if missing)\n(hash-ref ht \"missing\" 42)    ;; => 42 (hash-ref takes optional 3rd arg default)\n(hash-get ht \"name\")          ;; => \"alice\" (returns #f if missing)\n;; IMPORTANT: hash-get takes EXACTLY 2 args (table, key). Returns #f if missing.\n;; For a default value, use hash-ref with 3 args: (hash-ref ht key default)\n(hash-put! ht \"email\" \"a@b\")  ;; mutate\n(hash-key? ht \"name\")         ;; => #t\n(hash-remove! ht \"age\")\n(hash->list ht)               ;; => ((\"name\" . \"alice\") ...)\n\n;; Multi-arity wrapper if you want hash-get with defaults:\n(def* hget\n  ((ht key) (hash-get ht key))\n  ((ht key default) (hash-ref ht key default)))",
    "notes": "CRITICAL: hash-get is STRICTLY 2-arity in Gerbil. (hash-get ht key default) is WRONG and will error. Use hash-ref for 3-arg lookups with a default. The hget wrapper pattern (using def*) provides a convenient multi-arity alternative. Use (hash ...) for string keys, (hash-eq ...) for symbol keys.",
    "related": [
      "iterate-hash",
      "hash-table-merge"
    ]
  },
  {
    "id": "exe-build-static-modules",
    "title": "Build statically-linked executable with dependencies",
    "tags": [
      "exe",
      "build",
      "static",
      "link",
      "binary",
      "executable",
      "release",
      "defbuild-script"
    ],
    "imports": [
      ":std/build-script"
    ],
    "code": ";; build.ss — with exe target\n#!/usr/bin/env gxi\n(import :std/build-script)\n(defbuild-script\n  '(\"module-a\"\n    \"module-b\"\n    (exe: \"main\" bin: \"my-app\")))\n\n;; REQUIREMENTS for exe linking:\n;; 1. The main module MUST export its main function:\n;;    (export main)\n;;\n;; 2. All dependencies must have static modules (.scm files in static/ dir).\n;;    Build dependencies with --release:\n;;      cd /path/to/dependency && gerbil build --release\n;;\n;; 3. GERBIL_LOADPATH must include the dependency's .gerbil/lib/ directory\n;;    so the linker can find static modules:\n;;      GERBIL_LOADPATH=/path/to/dep/.gerbil/lib gerbil build --release\n;;\n;; 4. Build YOUR project with --release too:\n;;      gerbil build --release",
    "notes": "Common errors: (1) \"cannot find static module foo__bar.scm\" — the dependency wasn't built with --release, or its .gerbil/lib/ isn't in GERBIL_LOADPATH. (2) \"module does not export symbol: main\" — add (export main) to the main module. (3) Linker warnings about dlopen/getaddrinfo are harmless for static Gambit binaries. The resulting binary is fully self-contained and doesn't need Gerbil installed to run.",
    "related": [
      "cli-getopt-subcommands"
    ]
  },
  {
    "id": "export-t-does-not-reexport-imports",
    "title": "(export #t) does NOT re-export imported symbols",
    "tags": [
      "export",
      "import",
      "re-export",
      "module",
      "gotcha",
      "transitive"
    ],
    "imports": [],
    "code": ";; Module A (a.ss) — imports and re-exports\n(import :some-library/foo)  ;; provides make-foo\n(export #t)\n\n(def (helper x) (make-foo x))  ;; make-foo is usable here\n\n;; Module B (b.ss) — imports Module A\n(import ./a)\n\n;; (make-foo 42)  ;; ERROR: make-foo is NOT available!\n;; (export #t) only exports symbols DEFINED in the module,\n;; not symbols imported from other modules.\n\n;; WORKAROUND 1: Import the library directly in Module B\n(import :some-library/foo)  ;; now make-foo is available\n\n;; WORKAROUND 2: Explicitly re-export in Module A\n;; (export (import: :some-library/foo))  ;; re-exports foo's bindings",
    "notes": "In Gerbil, (export #t) exports all bindings DEFINED in the current module's scope, but does NOT transitively re-export symbols imported from other modules. If module A imports :lib/foo and uses (export #t), module B importing A will NOT get :lib/foo's symbols. Module B must import :lib/foo directly, or module A must use (export (import: :lib/foo)) for explicit re-export. This is a common source of \"Reference to unbound identifier\" errors when refactoring."
  },
  {
    "id": "cons-pair-in-bracket-list-gotcha",
    "title": "Dotted pair syntax inside [] is a function call, not a cons pair",
    "tags": [
      "cons",
      "pair",
      "list",
      "bracket",
      "dotted",
      "gotcha",
      "alist",
      "dimensions"
    ],
    "imports": [],
    "code": ";; WRONG: Dotted pair syntax with a variable inside [] list sugar\n;; This is interpreted as calling \"Key\" as a function with value as arg!\n(def key-name \"MyKey\")\n;; [(\"Key\" . key-name)]  ;; ERROR: Bad syntax; invalid match target\n;; Expands to (@list (\"Key\" . key-name)) where (\"Key\" . key-name)\n;; is treated as (%%app \"Key\" . key-name) — a function application.\n\n;; CORRECT: Use (cons ...) to build pairs with variables\n[(cons \"Key\" key-name)]        ;; => ((\"Key\" . \"MyKey\"))\n\n;; Literal dotted pairs (both sides are constants) work inside quote:\n'((\"Key\" . \"literal-value\"))   ;; OK — quoted datum\n\n;; Common use case: building alists for AWS API dimensions\n(def instance-id \"i-abc123\")\n;; Wrong:  dimensions: [(\"InstanceId\" . instance-id)]\n;; Right:  dimensions: [(cons \"InstanceId\" instance-id)]\n\n;; Multiple pairs:\n(def name \"my-func\")\n(def dims [(cons \"FunctionName\" name)\n           (cons \"Resource\" \"my-resource\")])\n;; => ((\"FunctionName\" . \"my-func\") (\"Resource\" . \"my-resource\"))",
    "notes": "In Gerbil, [x y z] is sugar for (@list x y z). Each element is an expression. The syntax (\"Key\" . var) in expression position is NOT a cons pair — it's a function application where \"Key\" is the operator. This causes \"Bad syntax; invalid match target\" or similar errors. Use (cons \"Key\" var) instead. Literal pairs work fine inside quote: '((\"k\" . \"v\")). This commonly bites when building alists (e.g., AWS API dimension parameters) where keys are string literals but values are variables."
  },
  {
    "id": "gerbil-build-loadpath-for-packages",
    "title": "gerbil build needs GERBIL_LOADPATH to find installed packages",
    "tags": [
      "build",
      "GERBIL_LOADPATH",
      "package",
      "import",
      "cannot find",
      "library module",
      "Makefile"
    ],
    "imports": [],
    "code": ";; If your project imports a third-party package installed via gerbil pkg:\n;; (import :my-library/module)\n;;\n;; Running bare `gerbil build` may fail with:\n;;   Syntax Error: cannot find library module\n;;   form: :my-library/module\n;;\n;; The fix: set GERBIL_LOADPATH to include ~/.gerbil/lib\n;;\n;; Option 1: Shell environment variable\n;; $ GERBIL_LOADPATH=~/.gerbil/lib gerbil build\n;;\n;; Option 2: Makefile (recommended for projects)\n;; ------- Makefile -------\n;; GERBIL_PATH = $(HOME)/.gerbil\n;; export GERBIL_LOADPATH = $(GERBIL_PATH)/lib\n;;\n;; build:\n;; \tgerbil build\n;;\n;; clean:\n;; \tgerbil clean\n;; ------- end -------\n;;\n;; Note: gxi (the REPL) finds packages without GERBIL_LOADPATH,\n;; but the build subprocess spawned by `gerbil build` does not.\n;; This is a common source of confusion when imports work in gxi\n;; but fail during compilation.",
    "notes": "The gerbil build command spawns a subprocess to compile, and that subprocess does not inherit the default package search paths that gxi uses. You must explicitly set GERBIL_LOADPATH=$HOME/.gerbil/lib (or wherever packages are installed). A Makefile with `export GERBIL_LOADPATH` is the standard pattern. This explains why `gxi -e '(import :pkg/mod)'` works but `gerbil build` fails with \"cannot find library module\"."
  },
  {
    "id": "gerbil-aws-query-vs-json-response-keys",
    "title": "gerbil-aws Query API vs JSON API response key differences",
    "tags": [
      "gerbil-aws",
      "query",
      "json",
      "XML",
      "symbol",
      "string",
      "keys",
      "AWS",
      "migration",
      "CloudWatch",
      "RDS",
      "ELBv2"
    ],
    "imports": [],
    "code": ";; gerbil-aws has two API protocols with DIFFERENT response formats:\n;;\n;; 1. Query API (XML): EC2, STS, IAM, CloudWatch, RDS, ELBv2, SNS, SQS, CloudFormation\n;;    - Keys are SYMBOLS: 'Average, 'InstanceId, 'DBInstanceIdentifier\n;;    - Values are STRINGS (from XML text): \"30.5\", \"true\", \"i-abc123\"\n;;    - Lists use {member: [...]} wrapper from XML <member> elements\n;;    - Booleans are strings: \"true\" / \"false\"\n;;\n;; 2. JSON API: Lambda, CloudWatch Logs, DynamoDB, Compute Optimizer, Cost Optimization Hub\n;;    - Keys are STRINGS: \"Average\", \"instanceId\", \"functionName\"\n;;    - Values are TYPED: 30.5 (number), #t (boolean), \"i-abc123\" (string)\n;;    - Lists are plain lists (JSON arrays)\n;;    - Booleans are #t / #f\n;;\n;; When migrating from AWS CLI (JSON output) to native Query API:\n;;   (hget resp \"Datapoints\")          ;; CLI: string key, list value\n;;   ;; becomes:\n;;   ;; get-metric-statistics returns the list directly (no wrapper key)\n;;\n;;   (hget dp \"Average\")               ;; CLI: string key, number value\n;;   ;; becomes:\n;;   (safe-number (hash-ref dp 'Average #f) 0)  ;; Query: symbol key, STRING value\n;;\n;; When migrating from AWS CLI to native JSON API:\n;;   (hget resp \"Functions\")           ;; CLI: string key, list value\n;;   ;; stays the same — JSON API matches CLI output format\n;;\n;; IMPORTANT: Query API numeric values MUST be converted with string->number\n;; or a safe-number wrapper. They come back as strings like \"30.5\" not 30.5.",
    "notes": "This is the most common source of bugs when migrating from AWS CLI calls to native gerbil-aws. Query API services return symbol keys and string values from XML parsing, while JSON API services return string keys and typed values (matching CLI output). Always use hash-ref with symbol keys ('Key) for Query API responses, and convert numeric strings with string->number or a safe wrapper.",
    "related": [
      "http-post-form-encoded",
      "parse-xml-to-sxml"
    ]
  },
  {
    "id": "extract-member-list-xml-normalization",
    "title": "Normalize XML member-list structures from gerbil-aws Query API",
    "tags": [
      "gerbil-aws",
      "XML",
      "member",
      "list",
      "normalize",
      "query",
      "API",
      "dimensions",
      "CloudWatch"
    ],
    "imports": [],
    "code": ";; AWS Query API XML uses <member> elements for lists:\n;;   <Dimensions>\n;;     <member><Name>InstanceId</Name><Value>i-abc</Value></member>\n;;     <member><Name>ImageId</Name><Value>ami-xyz</Value></member>\n;;   </Dimensions>\n;;\n;; After sxml->hash parsing, this becomes different structures depending\n;; on the number of <member> elements:\n;;\n;;   Single member:  {member: {Name: \"InstanceId\", Value: \"i-abc\"}}\n;;   Multiple:       {member: [{Name: \"InstanceId\", ...}, {Name: \"ImageId\", ...}]}\n;;   Empty:          #f or missing key\n;;\n;; Use this helper to normalize to a plain list in all cases:\n\n(def (extract-member-list raw)\n  \"Normalize XML member-list to a plain list.\n   Handles: #f -> [], list -> list, {member: list} -> list,\n            {member: hash} -> [hash], string -> [string]\"\n  (cond\n    ((not raw) [])\n    ((list? raw) raw)\n    ((hash-table? raw)\n     (let ((m (hash-get raw 'member)))\n       (cond\n         ((list? m) m)\n         ((not m) [])\n         (else [m]))))          ;; single member: wrap in list\n    (else [])))\n\n;; Example: extracting CloudWatch dimensions from list-metrics response\n;; (def metric (car (list-metrics cw metric-name: \"CPUUtilization\" ...)))\n;; (def dims-raw (hash-ref metric 'Dimensions #f))\n;; (def dims (extract-member-list dims-raw))\n;; ;; dims is now always a list of hashes with 'Name and 'Value keys\n;; (def dims-alist\n;;   (map (lambda (d) (cons (hash-ref d 'Name \"\") (hash-ref d 'Value \"\")))\n;;        dims))",
    "notes": "The gerbil-aws Query API functions like cw-action/items extract the outer member list, but inner nested member-list structures (e.g., Dimensions within a Metric) remain in raw XML-parsed form. This helper normalizes the three possible shapes (single hash, list of hashes, or #f) into a consistent list. Essential when processing CloudWatch list-metrics dimensions, IAM policy documents, or any Query API response with nested lists.",
    "related": [
      "gerbil-aws-query-vs-json-response-keys"
    ]
  },
  {
    "id": "sxml-skip-pi-nodes",
    "title": "Skip *PI* processing instruction nodes when traversing SXML",
    "tags": [
      "sxml",
      "xml",
      "parsing",
      "processing-instruction",
      "PI",
      "read-xml",
      "traverse",
      "gotcha",
      "*PI*",
      "*TOP*"
    ],
    "imports": [
      ":std/markup/xml"
    ],
    "code": "\n(import :std/markup/xml)\n\n;; XML responses often start with <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n;; read-xml parses this into a *PI* (Processing Instruction) SXML node:\n;;\n;;   (*TOP*\n;;     (@ (*NAMESPACES* ...))\n;;     (*PI* xml \"version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"\")   ;; <-- gotcha!\n;;     (ns:RootElement ...))\n;;\n;; When traversing SXML to find the root element, you MUST skip *PI* nodes\n;; along with @, *NAMESPACES*, and *TOP*. Otherwise *PI* gets mistakenly\n;; treated as the root element.\n\n;; WRONG — misses *PI*, returns wrong node:\n(def (find-root-BAD xml)\n  (let find ((node xml))\n    (cond\n      ((not (pair? node)) #f)\n      ((memq (car node) '(@ *NAMESPACES*)) #f)        ;; missing *PI*!\n      ((not (eq? (car node) '*TOP*)) node)\n      (else (ormap find (cdr node))))))\n\n;; CORRECT — skips *PI* nodes:\n(def (find-root-GOOD xml)\n  (let find ((node xml))\n    (cond\n      ((not (pair? node)) #f)\n      ((memq (car node) '(@ *NAMESPACES* *PI*)) #f)   ;; includes *PI*\n      ((not (eq? (car node) '*TOP*)) node)\n      (else (ormap find (cdr node))))))\n\n;; Example: parsing an S3 response with XML declaration\n(def xml (read-xml\n           \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?><Root><Item>hello</Item></Root>\"\n           namespaces: '()))\n\n(find-root-BAD xml)   ;; => (*PI* xml \"version=\\\"1.0\\\" ...\") — WRONG!\n(find-root-GOOD xml)  ;; => (Root (Item \"hello\")) — correct\n",
    "notes": "The *PI* node appears in SXML when the source XML contains processing instructions like <?xml ...?>. Most real-world XML APIs (AWS S3, etc.) include this declaration. The SXML metadata nodes to always skip when searching for content elements are: *TOP* (document root wrapper), @ (attributes), *NAMESPACES* (namespace declarations), and *PI* (processing instructions). Forgetting *PI* causes silent data loss — the PI node gets processed as if it were the root element, typically producing an empty string or #f instead of the expected parsed data."
  },
  {
    "id": "stale-global-static-files-segfault",
    "title": "Stale global static files cause segfaults in compiled binaries",
    "tags": [
      "segfault",
      "static",
      "linking",
      "build",
      "stale",
      "global",
      "GERBIL_LOADPATH",
      "ABI",
      "mismatch",
      "crash",
      "exe"
    ],
    "imports": [],
    "code": ";; PROBLEM: Compiled binary segfaults but code works fine in gxi REPL.\n;;\n;; ROOT CAUSE: Stale static files (.scm, .c, .o) in ~/.gerbil/lib/static/\n;; shadow locally compiled versions. When GERBIL_LOADPATH includes\n;; ~/.gerbil/lib BEFORE the local project path, the exe linker picks up\n;; the old global .o files instead of the current local ones.\n;;\n;; This causes ABI mismatches: e.g., cost-explorer calls\n;;   aws-billing/aws#first-of-month-string__%  (new split variant)\n;; but the stale global aws module only defines\n;;   aws-billing/aws#first-of-month-string     (old monolithic variant)\n;; Calling an undefined symbol → SIGSEGV.\n;;\n;; HOW STALE FILES GET THERE:\n;; - Running `gerbil build` or `gxpkg build` from within a project\n;;   that has its .gerbil/lib/ in GERBIL_LOADPATH\n;; - A previous `gerbil pkg install` of the package\n;; - Manually copying build artifacts\n;;\n;; DIAGNOSIS:\n;; 1. Check for duplicate static files:\n;;    find ~/.gerbil/lib -name 'YOURPKG__*.scm' -o -name 'YOURPKG__*.o'\n;;\n;; 2. Compare with local project files:\n;;    ls -la ~/.gerbil/lib/static/YOURPKG__module.scm   # stale (old timestamp)\n;;    ls -la ./project/.gerbil/lib/static/YOURPKG__module.scm  # current\n;;\n;; 3. Check build output: if BOTH paths appear during exe compilation,\n;;    the global one may win.\n;;\n;; FIX:\n;; Remove ALL stale global artifacts (.scm, .c, .o, .ssi):\n;;   rm -rf ~/.gerbil/lib/YOURPKG/\n;;   rm -f  ~/.gerbil/lib/static/YOURPKG__*.scm\n;;   rm -f  ~/.gerbil/lib/static/YOURPKG__*.c\n;;   rm -f  ~/.gerbil/lib/static/YOURPKG__*.o\n;;\n;; Then clean rebuild:\n;;   make clean && make build\n;;\n;; IMPORTANT: `gerbil clean` only removes LOCAL .gerbil/ artifacts.\n;; It does NOT clean ~/.gerbil/lib/. You must manually remove stale\n;; global files. Also note: removing just .scm files is NOT enough —\n;; the linker uses the .o files directly if they exist.",
    "notes": "The Gerbil compiler may change how optional-arg functions are compiled across versions (monolithic closure vs split __%/__0 variants). If global static files are from an older compilation, the ABI won't match modules compiled with the current compiler. The segfault typically occurs at the call site in `(declare (not safe))` blocks where the undefined function symbol resolves to null/garbage. The `strings` command won't find Gerbil string literals in compiled binaries (they're stored as Gambit string objects, not C strings), so use `grep` on the `.scm` static files to verify which version the linker uses.",
    "related": [
      "static-exe-with-deps",
      "gerbil-build-loadpath"
    ]
  },
  {
    "id": "debug-compiled-only-segfault",
    "title": "Debug segfaults that only occur in compiled binaries (not REPL)",
    "tags": [
      "debug",
      "segfault",
      "compiled",
      "binary",
      "REPL",
      "gdb",
      "static",
      "linking",
      "crash"
    ],
    "imports": [],
    "code": ";; When code works in gxi but segfaults as a compiled binary:\n;;\n;; STEP 1: Test in REPL to confirm the logic is correct\n;;   echo '(import :mymodule) (my-function args)' | \\\n;;     GERBIL_LOADPATH=... gxi\n;;\n;; STEP 2: Add debug displayln/force-output INSIDE the crashing function\n;;   (def (my-function arg)\n;;     (displayln \"[dbg] entering\") (force-output)\n;;     (let ((x (step-1)))\n;;       (displayln \"[dbg] step-1 ok\") (force-output)\n;;       ...))\n;;\n;; STEP 3: Rebuild and check if debug output appears in binary\n;;   ;; Gerbil string literals are NOT plain C strings in the binary.\n;;   ;; Check the static .scm file instead:\n;;   grep 'dbg' .gerbil/lib/static/YOURPKG__module.scm\n;;\n;; STEP 4: If debug strings are in .scm but NOT in behavior,\n;;   check for stale global copies shadowing local files:\n;;   find ~/.gerbil/lib -name 'YOURPKG__*' -type f\n;;\n;; STEP 5: Compare compiled function signatures between versions\n;;   ;; Old compilation style (monolithic optional-arg function):\n;;   ;;   (define pkg#my-fn (let ((opt-lambda ...)) (lambda _g_ ...)))\n;;   ;;\n;;   ;; New compilation style (split variants):\n;;   ;;   (define pkg#my-fn__% (lambda (arg) ...))    ; implementation\n;;   ;;   (define pkg#my-fn__0 (lambda () ...))        ; zero-arg wrapper\n;;   ;;   (define pkg#my-fn (lambda _g_ (cond ...)))   ; dispatch\n;;   ;;\n;;   ;; If caller uses my-fn__% but linked module only defines my-fn,\n;;   ;; the symbol is undefined → segfault in (declare (not safe)) context.\n;;\n;; STEP 6: GDB can identify the hosting function but not the exact line:\n;;   ;; ___H_pkg____module is Gambit's C hosting function for the module.\n;;   ;; All compiled Scheme code for that module lives inside this one\n;;   ;; C function, so the crash address isn't very informative.\n;;   ;; Use debug displayln to narrow down instead.",
    "notes": "Key insight: in compiled Gerbil binaries with (declare (not safe)), calling an undefined/unresolved symbol doesn't raise a Scheme exception — it causes a raw SIGSEGV because the null function pointer is called without any safety checks. The REPL doesn't have this problem because it resolves symbols dynamically. Also: `gerbil clean` does NOT remove ~/.gerbil/lib/ artifacts — only local .gerbil/ files.",
    "related": [
      "stale-global-static-files-segfault",
      "static-exe-with-deps"
    ]
  },
  {
    "id": "srfi-19-current-time-shadows-gambit",
    "title": "SRFI-19 current-time shadows Gambit's current-time (causes time->seconds crash)",
    "tags": [
      "srfi-19",
      "current-time",
      "time",
      "gambit",
      "shadow",
      "time->seconds",
      "mutex",
      "rate-limit",
      "gotcha"
    ],
    "imports": [
      ":std/srfi/19"
    ],
    "code": ";; PROBLEM: Importing :std/srfi/19 shadows Gambit's built-in (current-time).\n;;\n;; Gambit's (current-time) returns a Gambit time object (##type #2 time).\n;; SRFI-19's (current-time) returns an SRFI-19 time object (different type).\n;; Gambit's (time->seconds) only accepts Gambit time objects.\n;;\n;; If you import :std/srfi/19 and then call:\n;;   (time->seconds (current-time))\n;; You get: \"Instance of #<type #2 time> expected\"\n;; because (current-time) now returns SRFI-19 time, but (time->seconds)\n;; expects Gambit time.\n;;\n;; This commonly bites in rate-limiting code, mutex timing, or anywhere\n;; you mix SRFI-19 date formatting with Gambit timing primitives.\n\n;; WRONG — crashes at runtime:\n;; (import :std/srfi/19)\n;; (def (rate-limit!)\n;;   (let ((now (time->seconds (current-time))))  ;; BOOM\n;;     ...))\n\n;; FIX: Use ##current-time to bypass the SRFI-19 shadow:\n(import :std/srfi/19)\n(def (rate-limit!)\n  (let ((now (exact->inexact (time->seconds (##current-time)))))\n    ;; ##current-time always returns Gambit's native time object\n    ;; time->seconds works correctly on it\n    now))\n\n;; ALTERNATIVE: Use SRFI-19's own time conversion instead:\n;; (import :std/srfi/19)\n;; (def (current-seconds)\n;;   (let ((t (current-time)))  ;; SRFI-19 time\n;;     (+ (time-second t)       ;; SRFI-19 accessor\n;;        (/ (time-nanosecond t) 1e9))))",
    "notes": "The ## prefix accesses Gambit's raw (unshadowed) primitives. ##current-time is safe to use even when SRFI-19 is imported. This issue only manifests at runtime — compilation succeeds because both versions of current-time have the same arity. The error message \"Instance of #<type #2 time> expected\" is the key diagnostic clue. Also note: exact->inexact is needed because time->seconds may return an exact rational.",
    "related": [
      "date-time-formatting-srfi-19"
    ]
  },
  {
    "id": "mutex-unwind-protect-deadlock-prevention",
    "title": "Always wrap mutex-lock!/unlock! with unwind-protect to prevent deadlocks",
    "tags": [
      "mutex",
      "unwind-protect",
      "deadlock",
      "thread",
      "lock",
      "concurrency",
      "exception",
      "safety"
    ],
    "imports": [],
    "code": ";; PROBLEM: If an exception occurs between mutex-lock! and mutex-unlock!,\n;; the mutex stays locked forever, deadlocking all subsequent callers.\n;;\n;; WRONG — deadlocks after first exception:\n;; (def my-lock (make-mutex 'my-lock))\n;; (def (unsafe-operation!)\n;;   (mutex-lock! my-lock)\n;;   (do-something-that-might-throw)  ;; if this throws...\n;;   (mutex-unlock! my-lock))         ;; ...this never runs → deadlock\n\n;; CORRECT — always unlocks, even on exception:\n(def my-lock (make-mutex 'my-lock))\n\n(def (safe-operation!)\n  (mutex-lock! my-lock)\n  (unwind-protect\n    (do-something-that-might-throw)\n    (mutex-unlock! my-lock)))\n\n;; PATTERN: Rate limiter with mutex + timing\n(def _api-lock (make-mutex 'api-lock))\n(def _last-call-time 0.0)\n(defconst API-DELAY 0.1)  ;; 100ms between calls\n\n(def (rate-limit!)\n  (mutex-lock! _api-lock)\n  (unwind-protect\n    (let* ((now (exact->inexact (time->seconds (##current-time))))\n           (elapsed (fl- now _last-call-time)))\n      (when (fl< elapsed API-DELAY)\n        (thread-sleep! (fl- API-DELAY elapsed)))\n      (set! _last-call-time\n        (exact->inexact (time->seconds (##current-time)))))\n    (mutex-unlock! _api-lock)))\n\n;; DIAGNOSTIC: Deadlock symptoms in Gerbil:\n;; - Program hangs after first API error\n;; - GDB backtrace shows ##mutex-lock-out-of-line!\n;; - Error log shows \"Deadlock detected\" with mutex name",
    "notes": "unwind-protect guarantees the cleanup form (mutex-unlock!) runs regardless of whether the body completes normally or throws an exception. This is analogous to try/finally in other languages. Without it, any exception between lock and unlock permanently locks the mutex. This is especially critical in rate-limiting code where API calls may throw network exceptions, timeout errors, or AWS service errors. The deadlock typically manifests on the SECOND call after the first exception.",
    "related": [
      "srfi-19-current-time-shadows-gambit",
      "error-handling"
    ]
  },
  {
    "id": "error-message-returns-false-for-non-error",
    "title": "error-message returns #f for non-Gerbil-Error exceptions — use display-exception",
    "tags": [
      "error-message",
      "exception",
      "display-exception",
      "error",
      "catch",
      "non-error",
      "gambit",
      "gotcha",
      "exception->string"
    ],
    "imports": [
      ":std/error"
    ],
    "code": ";; PROBLEM: (error-message e) only works for Gerbil Error objects.\n;; For Gambit exceptions, AWS errors, or other non-Error exceptions,\n;; it returns #f — making error messages invisible.\n;;\n;; WRONG — loses error information for non-Error exceptions:\n;; (try (some-operation)\n;;   (catch (e)\n;;     (displayln \"Error: \" (error-message e))))\n;; ;; Prints: \"Error: #f\" for Gambit/AWS exceptions\n\n;; CORRECT — use display-exception which handles ALL exception types:\n(def (exception->string e)\n  \"Convert any exception to a readable string.\"\n  (with-output-to-string (lambda () (display-exception e))))\n\n;; Usage in catch blocks:\n(try (some-operation)\n  (catch (e)\n    (displayln \"Error: \" (exception->string e))))\n\n;; WHY: Gerbil has multiple exception types:\n;; - (Error message irritants where) — Gerbil's own error type\n;;   → (error-message e) works, returns the message string\n;;\n;; - Gambit exceptions (error-exception, type-exception, etc.)\n;;   → (error-message e) returns #f\n;;   → (display-exception e port) works for all types\n;;\n;; - AWS service errors (from gerbil-aws)\n;;   → Usually Gambit error-exception objects\n;;   → (error-message e) returns #f\n;;\n;; display-exception is Gambit's universal exception printer.\n;; It knows how to format ALL exception types including stack traces.",
    "notes": "This is a common gotcha when writing generic error handlers. error-message is defined on the Gerbil Error struct and returns the 'message' slot. But catch (e) catches ALL exceptions, not just Gerbil Errors. Gambit runtime exceptions (type errors, arity errors, I/O errors, network errors) are NOT Gerbil Error objects. The exception->string helper using display-exception is the universal solution. Also: (object->string e) sometimes works but may not include the full formatted error message that display-exception provides.",
    "related": [
      "error-handling",
      "custom-error",
      "deferror-class"
    ]
  },
  {
    "id": "gerbil-json-arrays-are-lists-not-vectors",
    "title": "Gerbil JSON arrays are lists, not vectors — never use (vector? x) to check",
    "tags": [
      "json",
      "vector",
      "list",
      "array",
      "vector?",
      "read-json",
      "gerbil-aws",
      "ensure-list",
      "gotcha",
      "silent-failure"
    ],
    "imports": [
      ":std/text/json"
    ],
    "code": ";; PROBLEM: Gerbil's read-json (and gerbil-aws JSON API responses) return\n;; JSON arrays as Scheme LISTS, not vectors. Code that checks (vector? x)\n;; silently drops all data because (vector? '(1 2 3)) => #f.\n;;\n;; This is a SILENT FAILURE — no error, no exception, just empty results.\n\n;; WRONG — silently discards all JSON array data:\n;; (let ((results (hget resp \"ResultsByTime\")))\n;;   (if (vector? results)          ;; ALWAYS #f for JSON arrays!\n;;     (vector->list results)       ;; never reached\n;;     []))                         ;; always returns empty list\n\n;; WRONG — silently skips processing:\n;; (let ((groups (hget resp \"Groups\")))\n;;   (when (vector? groups)         ;; ALWAYS #f!\n;;     (for-each process groups)))  ;; never runs\n\n;; CORRECT — use a defensive ensure-list helper:\n(def (ensure-list v)\n  \"Coerce a vector, list, or other value to a list.\"\n  (cond ((list? v) v)\n        ((vector? v) (vector->list v))  ;; handles the rare vector case\n        (else [])))\n\n;; Usage:\n(let ((results (ensure-list (hget resp \"ResultsByTime\"))))\n  (for-each process results))\n\n;; For extracting the first element of a \"Keys\" array:\n;; WRONG:\n;; (if (vector? keys) (vector-ref keys 0) \"Unknown\")\n;; CORRECT:\n(let ((ks (ensure-list keys)))\n  (if (pair? ks) (car ks) \"Unknown\"))\n\n;; WHY THIS HAPPENS:\n;; - Gerbil's :std/text/json read-json maps JSON arrays to Scheme lists\n;; - gerbil-aws JSON API (Cost Explorer, Lambda, etc.) uses read-json\n;; - Many AWS SDK examples in other languages use arrays/vectors,\n;;   so it's natural to write (vector? ...) but WRONG in Gerbil\n;; - The gerbil-aws Query API (EC2, RDS, etc.) also returns lists\n;;   (from XML member parsing), never vectors",
    "notes": "This is one of the most insidious bugs because it causes SILENT data loss — no exceptions, no errors, just empty results everywhere. The code appears to run successfully but produces no output. Diagnosis: add (displayln (object-type results)) to see that results is a list, not a vector. Prevention: never use (vector? x) to guard JSON array processing — use (list? x) or the ensure-list helper instead. This applies to ALL gerbil-aws responses (both Query API and JSON API) and to any data parsed by Gerbil's read-json.",
    "related": [
      "gerbil-aws-query-vs-json-response-keys",
      "json-parse"
    ]
  },
  {
    "id": "ec2-xml-lowercase-camelcase-keys",
    "title": "EC2 Query API XML uses lowercase camelCase keys, not PascalCase",
    "tags": [
      "ec2",
      "query-api",
      "xml",
      "camelCase",
      "lowercase",
      "regionName",
      "instanceId",
      "symbol",
      "key",
      "gotcha"
    ],
    "imports": [],
    "code": ";; PROBLEM: AWS API documentation shows PascalCase names like\n;; \"RegionName\", \"InstanceId\", \"VolumeId\". But the EC2 Query API\n;; XML response uses lowercase camelCase: <regionName>, <instanceId>.\n;;\n;; After XML parsing in gerbil-aws, these become lowercase symbols:\n;;   'regionName  NOT 'RegionName\n;;   'instanceId  NOT 'InstanceId\n;;   'volumeId    NOT 'VolumeId\n;;   'vpcId       NOT 'VpcId\n;;\n;; WRONG — throws UnboundKeyError:\n;; (hash-ref region-hash 'RegionName)   ;; key not found!\n;; (hash-ref instance 'InstanceId)      ;; key not found!\n;;\n;; CORRECT — use lowercase camelCase:\n;; (hash-ref region-hash 'regionName)   ;; works\n;; (hash-ref instance 'instanceId)      ;; works\n;;\n;; This applies to ALL ec2-action/items responses in gerbil-aws:\n;;   describe-regions     → 'regionName, 'regionEndpoint\n;;   describe-instances   → 'instanceId, 'instanceType, 'imageId\n;;   describe-volumes     → 'volumeId, 'size, 'volumeType\n;;   describe-snapshots   → 'snapshotId, 'volumeId, 'startTime\n;;   describe-addresses   → 'publicIp, 'allocationId\n;;   describe-nat-gateways → 'natGatewayId, 'vpcId, 'subnetId\n;;   describe-images      → 'imageId, 'name, 'creationDate\n;;\n;; But OTHER Query API services may use different casing:\n;;   CloudWatch  → 'MetricName, 'Namespace (PascalCase)\n;;   RDS         → 'DBInstanceIdentifier (PascalCase)\n;;   ELBv2       → 'LoadBalancerArn (PascalCase)\n;;\n;; The casing matches the actual XML element names in each service's\n;; API response, which varies by service. EC2 happens to use lowercase.",
    "notes": "The AWS documentation and CLI both show PascalCase (RegionName, InstanceId), but EC2's actual XML response uses lowercase camelCase. Other Query API services like CloudWatch and RDS use PascalCase in their XML. There's no universal rule — you must check the actual XML element names for each service. When in doubt, add a debug line: (displayln (hash->list my-hash)) to see the actual keys.",
    "related": [
      "gerbil-aws-query-vs-json-response-keys"
    ]
  },
  {
    "id": "write-json-cannot-serialize-cons-pairs",
    "title": "write-json cannot serialize cons pairs from hash->list — convert to hashes first",
    "tags": [
      "write-json",
      "hash->list",
      "cons",
      "pair",
      "alist",
      "serialize",
      "json",
      "Missing method",
      "gotcha"
    ],
    "imports": [
      ":std/text/json"
    ],
    "code": ";; PROBLEM: (hash->list ht) returns alist pairs: ((\"key1\" . val1) (\"key2\" . val2) ...)\n;; write-json does NOT know how to serialize cons pairs (dotted pairs).\n;; It throws: \"Missing method --- irritants: (\"key\" . value) :json\"\n;;\n;; This commonly happens when you sort a hash table and embed the\n;; sorted result in a data structure that later gets written to JSON.\n\n;; WRONG — crashes at JSON serialization time:\n;; (def sorted-services\n;;   (sort (hash->list service-totals)\n;;         (lambda (a b) (> (cdr a) (cdr b)))))\n;; (hash-put! data \"top_services\" sorted-services)\n;; ;; Later: (write-json data port)\n;; ;; ERROR: Missing method (\"EC2 - Other\" . 1073969.83) :json\n\n;; CORRECT — convert cons pairs to hashes before storing:\n(import :std/text/json)\n(def sorted-services\n  (sort (hash->list service-totals)\n        (lambda (a b) (> (cdr a) (cdr b)))))\n\n;; Convert alist pairs to list of hashes for JSON serialization:\n(def json-safe-services\n  (map (lambda (p) (hash (\"service\" (car p)) (\"cost\" (cdr p))))\n       sorted-services))\n\n(hash-put! data \"top_services\" json-safe-services)\n;; Now write-json works: [{\"service\":\"EC2\",\"cost\":1073969.83}, ...]\n\n;; write-json handles these types:\n;;   hash-table  → JSON object {\"key\": value}\n;;   list        → JSON array [...]\n;;   string      → JSON string \"...\"\n;;   number      → JSON number\n;;   #t / #f     → true / false\n;;   void / #!void → null\n;;\n;; It does NOT handle:\n;;   cons pair (\"k\" . v) → ERROR: Missing method :json\n;;   struct             → ERROR (unless has :json method)\n;;   symbol             → ERROR",
    "notes": "This error only surfaces at JSON write time, not when building the data structure. It's easy to miss during development if you only test the markdown output (which uses car/cdr on pairs directly). The fix is to convert alist pairs to hashes at the point where they're stored in the data structure, before they reach write-json. An alternative is to define a recursive sanitizer that walks the data tree and converts all cons pairs to hashes, but it's cleaner to convert at the source.",
    "related": [
      "gerbil-json-arrays-are-lists-not-vectors",
      "json-generate"
    ]
  },
  {
    "id": "gerbil-aws-sts-nested-response",
    "title": "STS GetCallerIdentity returns nested hash — Account is under GetCallerIdentityResult",
    "tags": [
      "sts",
      "get-caller-identity",
      "account-id",
      "nested",
      "gerbil-aws",
      "query-api"
    ],
    "imports": [
      ":gerbil-aws/sts/api",
      ":gerbil-aws/sts/operations"
    ],
    "code": ";; gerbil-aws STS uses the Query API (XML). The GetCallerIdentity\n;; response XML is:\n;;   <GetCallerIdentityResponse>\n;;     <GetCallerIdentityResult>\n;;       <Account>123456789012</Account>\n;;       <Arn>arn:aws:iam::123456789012:user/me</Arn>\n;;       <UserId>AIDAXXXXXXX</UserId>\n;;     </GetCallerIdentityResult>\n;;     <ResponseMetadata>...</ResponseMetadata>\n;;   </GetCallerIdentityResponse>\n;;\n;; After aws-response->hash, the result is a NESTED hash:\n;;   {GetCallerIdentityResult: {Account: \"123456789012\", Arn: \"...\", UserId: \"...\"},\n;;    ResponseMetadata: {RequestId: \"...\"}}\n\n;; WRONG — 'Account is NOT at the top level:\n;; (def identity (get-caller-identity sts))\n;; (hash-ref identity 'Account \"\")  ;; => \"\" (always!)\n\n;; CORRECT — navigate to GetCallerIdentityResult first:\n(def sts (STSClient))\n(def identity (get-caller-identity sts))\n(def result (hash-ref identity 'GetCallerIdentityResult identity))\n(def account-id (hash-ref result 'Account \"\"))\n;; account-id => \"123456789012\"\n\n;; The same pattern applies to other STS operations:\n;; - AssumeRole → 'AssumeRoleResult → 'Credentials, 'AssumedRoleUser\n;; - GetSessionToken → 'GetSessionTokenResult → 'Credentials",
    "notes": "This is because gerbil-aws's aws-response->hash (in aws/xml.ss) converts the entire XML response to a nested hash, including the *Result wrapper element. The Query API always wraps the actual data in an ActionNameResult element. Using (hash-ref identity 'GetCallerIdentityResult identity) as a fallback ensures forward compatibility if the library ever changes to unwrap automatically.",
    "related": [
      "gerbil-aws-query-vs-json-response-keys",
      "ec2-lowercase-camelcase-keys"
    ]
  },
  {
    "id": "gerbil-aws-empty-xml-tagset-string",
    "title": "Empty XML elements like tagSet become \"\" not [] — guard with list? before iterating",
    "tags": [
      "xml",
      "sxml",
      "tagSet",
      "empty-element",
      "type-exception",
      "gerbil-aws",
      "ec2"
    ],
    "imports": [],
    "code": ";; PROBLEM: In gerbil-aws EC2 responses, empty XML elements like <tagSet/>\n;; are parsed by sxml->hash as \"\" (empty string), not [] (empty list).\n;;\n;; This happens because of this clause in sxml->hash:\n;;   ((null? (cdr element)) \"\")  ;; Empty element: (tag) → \"\"\n;;\n;; So when a resource has no tags:\n;;   <tagSet/>  →  \"\" in the hash table\n;;\n;; And (hash-ref resource 'tagSet []) returns \"\" (key exists with value \"\"),\n;; NOT the default [].\n\n;; WRONG — crashes with type-exception: PAIR expected from (car \"\")\n;; (def (get-name tags)\n;;   (let loop ((ts (or tags [])))  ;; (or \"\" []) => \"\" (truthy!)\n;;     (if (null? ts) \"\"            ;; (null? \"\") => #f\n;;       (let ((t (car ts)))        ;; (car \"\") => TYPE EXCEPTION!\n;;         ...))))\n\n;; CORRECT — check (list? tags) before iterating:\n(def (get-name tags)\n  (let ((ts (if (list? tags) tags [])))\n    (let loop ((ts ts))\n      (if (null? ts) \"\"\n        (let ((t (car ts)))\n          (if (and (hash-table? t)\n                   (string=? (hash-ref t 'key \"\") \"Name\"))\n            (hash-ref t 'value \"\")\n            (loop (cdr ts))))))))\n\n;; This affects ANY EC2 field that can be an empty XML element:\n;;   tagSet, blockDeviceMapping, networkInterfaceSet,\n;;   securityGroupSet, natGatewayAddressSet, etc.\n;;\n;; General rule: always use (list? x) not (or x []) when the\n;; value might be \"\" from empty XML elements.",
    "notes": "This is a silent type-exception that only manifests when a resource happens to have no tags (or other empty set elements). Resources with at least one tag work fine because tagSet gets parsed as a list of items. The bug is intermittent — it depends on whether specific resources in specific regions have tags. Use (if (list? val) val []) instead of (or val []) for XML-parsed set fields.",
    "related": [
      "ec2-lowercase-camelcase-keys",
      "gerbil-aws-query-vs-json-response-keys"
    ]
  },
  {
    "id": "aws-pricing-api-endpoint",
    "title": "AWS Pricing API endpoint is api.pricing not pricing — CloudFront 403 on wrong endpoint",
    "tags": [
      "aws",
      "pricing",
      "endpoint",
      "api.pricing",
      "cloudfront",
      "403",
      "gerbil-aws",
      "json-api"
    ],
    "imports": [
      ":gerbil-aws/aws/json-api"
    ],
    "code": ";; PROBLEM: The AWS Pricing API uses a DIFFERENT endpoint pattern\n;; than most AWS services. The standard pattern is:\n;;   service.region.amazonaws.com\n;;\n;; But the Pricing API uses:\n;;   api.pricing.region.amazonaws.com\n;;\n;; Using the standard pattern (pricing.us-east-1.amazonaws.com) hits\n;; a CloudFront distribution that only serves GET requests for the\n;; pricing website. POST requests get:\n;;   403 ERROR: \"This distribution is not configured to allow the\n;;   HTTP request method that was used for this request.\"\n\n;; WRONG — hits CloudFront, gets 403:\n;; (AWSJsonClient service: \"pricing\"\n;;               target-prefix: \"AWSPriceListService\"\n;;               region: \"us-east-1\")\n;; ;; Constructs endpoint: pricing.us-east-1.amazonaws.com\n\n;; CORRECT — explicitly set the api.pricing endpoint:\n(def pricing-client\n  (AWSJsonClient service: \"pricing\"\n                 target-prefix: \"AWSPriceListService\"\n                 endpoint: \"api.pricing.us-east-1.amazonaws.com\"\n                 region: \"us-east-1\"))\n\n;; For a configurable region:\n(def (make-pricing-client (region \"us-east-1\"))\n  (AWSJsonClient service: \"pricing\"\n                 target-prefix: \"AWSPriceListService\"\n                 endpoint: (string-append \"api.pricing.\" region \".amazonaws.com\")\n                 region: region))\n\n;; Other AWS services with non-standard endpoints:\n;;   Cost Explorer: ce.us-east-1.amazonaws.com (standard pattern, works)\n;;   S3: s3.region.amazonaws.com or s3.amazonaws.com (path-style)\n;;   STS: sts.amazonaws.com (global) or sts.region.amazonaws.com (regional)",
    "notes": "The AWS Pricing API is only available in us-east-1 and ap-south-1. Always pass the endpoint explicitly when creating the client. The AWSJsonClient default endpoint construction (service.region.amazonaws.com) does NOT work for the Pricing API. This manifests as a confusing CloudFront 403 error rather than an obvious endpoint error.",
    "related": [
      "gerbil-aws-query-vs-json-response-keys"
    ]
  },
  {
    "id": "aws-pricing-api-content-type-1-1",
    "title": "AWS Pricing API requires content-type application/x-amz-json-1.1, not 1.0",
    "tags": [
      "pricing",
      "aws",
      "content-type",
      "json",
      "1.1",
      "AWSJsonClient",
      "UnknownOperationException",
      "404"
    ],
    "imports": [
      ":gerbil-aws/aws/json-api"
    ],
    "code": ";; PROBLEM: The AWS Pricing API requires content-type \"application/x-amz-json-1.1\"\n;; but AWSJsonClient defaults to \"application/x-amz-json-1.0\".\n;;\n;; Without the correct content-type, ALL Pricing API calls fail with:\n;;   HTTP 404: <UnknownOperationException/>\n;;\n;; This is a SILENT CASCADING FAILURE — pricing lookups return #f,\n;; causing downstream code to skip hundreds of resources.\n\n;; WRONG — uses default content-type 1.0, gets 404 on every call:\n;; (def (make-pricing-client (region \"us-east-1\"))\n;;   (AWSJsonClient service: \"pricing\"\n;;                  target-prefix: \"AWSPriceListService\"\n;;                  endpoint: (string-append \"api.pricing.\" region \".amazonaws.com\")\n;;                  region: region))\n\n;; CORRECT — explicitly set content-type to 1.1:\n(def (make-pricing-client (region \"us-east-1\"))\n  (AWSJsonClient service: \"pricing\"\n                 target-prefix: \"AWSPriceListService\"\n                 endpoint: (string-append \"api.pricing.\" region \".amazonaws.com\")\n                 content-type: \"application/x-amz-json-1.1\"\n                 region: region))\n\n;; AWS services and their JSON protocol versions:\n;;   application/x-amz-json-1.1:\n;;     Pricing, Lambda, CloudWatch Logs, ECS, SSM, Secrets Manager\n;;   application/x-amz-json-1.0:\n;;     DynamoDB, Compute Optimizer, Cost Optimization Hub, SWF\n;;\n;; Check the AWS service's API reference for the correct version.\n;; The version is listed in the \"Common Headers\" section of each API doc.",
    "notes": "The AWSJsonClient in gerbil-aws defaults content-type to \"application/x-amz-json-1.0\" (set in json-api.ss line 45). AWS services that require 1.1 will reject ALL requests with HTTP 404 UnknownOperationException. This is extremely hard to debug because: (1) the error is XML even though it's a JSON API, (2) 404 suggests a wrong URL, not a wrong content-type, (3) the endpoint IS correct (api.pricing.region.amazonaws.com). Combined with the endpoint issue (see aws-pricing-api-endpoint recipe), there are TWO things you must get right for the Pricing API: the api.pricing prefix AND the 1.1 content-type.",
    "related": [
      "aws-pricing-api-endpoint"
    ]
  },
  {
    "id": "gerbil-aws-strip-ns-uri-namespace-bug",
    "title": "gerbil-aws strip-ns breaks on full URI namespace prefixes — finds first colon not last",
    "tags": [
      "strip-ns",
      "namespace",
      "XML",
      "SXML",
      "URI",
      "gerbil-aws",
      "STS",
      "RDS",
      "ELBv2"
    ],
    "imports": [],
    "code": ";; PROBLEM: gerbil-aws's strip-ns function in aws/xml.ss finds the FIRST\n;; colon in a symbol name, but URI namespace prefixes contain multiple colons.\n;;\n;; The function is:\n;;   (def (strip-ns sym)\n;;     (let (s (symbol->string sym))\n;;       (let (pos (string-contains s \":\"))   ;; finds FIRST \":\"\n;;         (if pos\n;;           (string->symbol (substring s (+ pos 1) (string-length s)))\n;;           sym))))\n;;\n;; For EC2, namespaces are mapped to short prefixes like \"ec2:\",\n;; so strip-ns works: 'ec2:instanceId → 'instanceId\n;;\n;; But for services WITHOUT namespace mappings (STS, RDS, ELBv2, CloudWatch),\n;; the XML parser produces full URI prefixes:\n;;   '//sts.amazonaws.com/doc/2011-06-15/:Account\n;;   '//rds.amazonaws.com/doc/2014-10-31/:DBInstances\n;;\n;; strip-ns finds the first \":\" in \"//sts.amazonaws.com/doc/2011-06-15/:Account\"\n;; which is in \"http:\" — producing '//sts.amazonaws.com/doc/2011-06-15/:Account\n;; (unchanged!) instead of 'Account.\n;;\n;; WORKAROUND: Add namespace mappings to your client, like EC2 does:\n;; (AWSClient ...\n;;   namespaces: '((\"https://sts.amazonaws.com/doc/2011-06-15/\" . \"sts\")))\n;;\n;; Or fix strip-ns to find the LAST colon:\n(def (strip-ns sym)\n  (let* ((s (symbol->string sym))\n         (len (string-length s)))\n    (let loop ((i (- len 1)))\n      (cond\n        ((< i 0) sym)\n        ((char=? (string-ref s i) #\\:)\n         (string->symbol (substring s (+ i 1) len)))\n        (else (loop (- i 1)))))))\n\n;; Test:\n;; (strip-ns '//sts.amazonaws.com/doc/2011-06-15/:Account) => 'Account\n;; (strip-ns 'ec2:instanceId) => 'instanceId\n;; (strip-ns 'noNamespace) => 'noNamespace\n\n;; AFFECTED SERVICES (no namespace mappings by default):\n;;   STS  — get-caller-identity returns empty account-id\n;;   RDS  — describe-db-instances returns 0 items\n;;   ELBv2 — describe-load-balancers returns 0 items\n;;   CloudWatch — some responses may be affected\n;;\n;; EC2 WORKS because it has explicit namespace mappings in ec2/xml.ss:\n;;   '((\"http://ec2.amazonaws.com/doc/2016-11-15/\" . \"ec2\"))",
    "notes": "This is a bug in gerbil-aws/aws/xml.ss. The proper fix is to change strip-ns to find the LAST colon instead of the first. The workaround is to add namespace mappings to each client (like EC2 does), but this requires knowing the exact namespace URI for each AWS service version. The bug causes SILENT DATA LOSS — API calls succeed (HTTP 200) but the response parsing can't match expected keys, so functions return empty lists or empty strings. Symptoms: get-account-id returns \"\", describe-db-instances returns 0 items, describe-load-balancers returns 0 items.",
    "related": [
      "aws-pricing-api-endpoint",
      "gerbil-aws-query-vs-json-response-keys",
      "ec2-lowercase-camelcase-keys"
    ]
  },
  {
    "id": "force-gc-gambit",
    "title": "Force garbage collection with ##gc in Gambit/Gerbil",
    "tags": [
      "gc",
      "garbage collection",
      "memory",
      "gambit",
      "heap",
      "oom"
    ],
    "imports": [],
    "code": ";; Force a full garbage collection using Gambit's ##gc primitive.\n;; Useful between memory-intensive sections to prevent heap from\n;; growing unboundedly when processing large datasets.\n\n;; Basic usage:\n(##gc)\n\n;; Pattern: Insert between heavy processing sections\n(def (process-large-dataset)\n  ;; Section 1: fetch and process data\n  (let ((data1 (fetch-large-data-1)))\n    (process data1)\n    (store-results data1))\n\n  ;; Force GC to reclaim temporary data from section 1\n  ;; before starting section 2\n  (##gc)\n\n  ;; Section 2: fetch more data\n  (let ((data2 (fetch-large-data-2)))\n    (process data2)\n    (store-results data2))\n\n  (##gc))\n\n;; Real-world example: AWS report data collection\n;; Without ##gc, parsed JSON from API responses accumulates\n;; until Gambit decides to collect, which may be too late\n;; on memory-constrained systems.\n;;\n;; (displayln \"  Fetching snapshots...\")\n;; (fetch-snapshots)\n;; (##gc)  ;; reclaim parsed API responses\n;; (displayln \"  Analyzing rightsizing...\")\n;; (analyze-rightsizing)  ;; another memory-heavy operation\n;; (##gc)\n",
    "notes": "##gc is a Gambit primitive (double-hash prefix). It triggers a full GC cycle synchronously. Returns void. Safe to call at any time. Particularly important in multi-threaded applications where many short-lived objects are created rapidly (e.g., parsing large JSON API responses) and the GC can't keep up with allocation pressure. Also useful in long-running batch programs that process data in phases. Note: calling ##gc too frequently adds overhead; use it between major processing phases, not in tight loops.",
    "related": [
      "srfi-19-current-time-shadows-gambit"
    ]
  },
  {
    "id": "thread-safe-list-accumulation",
    "title": "Thread-safe list accumulation — avoid O(n²) append anti-pattern",
    "tags": [
      "append",
      "cons",
      "thread",
      "parallel",
      "mutex",
      "performance",
      "memory",
      "accumulate"
    ],
    "imports": [],
    "code": ";; PROBLEM: When accumulating results from parallel threads, using\n;; (append accumulated new-items) copies the ENTIRE accumulated list\n;; on every call, creating O(n²) memory and time behavior.\n;;\n;; With large result sets across many threads, this wastes gigabytes\n;; of memory on redundant list copies before GC can reclaim them.\n\n;; WRONG — O(n²) memory, copies all-results on every append:\n;; (def result-mx (make-mutex 'result-mx))\n;; (def all-results [])\n;; ;; ... in each thread:\n;; (mutex-lock! result-mx)\n;; (set! all-results (append all-results new-results))  ;; BAD\n;; (mutex-unlock! result-mx)\n;; ;; append copies its FIRST argument, so (append big-list small-list)\n;; ;; copies big-list entirely. This grows quadratically.\n\n;; CORRECT — O(n) total, only copies the small new-results list:\n(def result-mx (make-mutex 'result-mx))\n(def all-results [])\n;; ... in each thread:\n(mutex-lock! result-mx)\n(set! all-results (append new-results all-results))  ;; GOOD\n(mutex-unlock! result-mx)\n;; append copies its first arg (small new-results) and links to second\n;; arg (large all-results) without copying it. O(k) per call where\n;; k = length of new-results.\n\n;; ALTERNATIVE — cons individual items (best for single results):\n(mutex-lock! result-mx)\n(set! all-results (cons single-result all-results))\n(mutex-unlock! result-mx)\n\n;; NOTE: Both correct approaches prepend, so results are in reverse\n;; order. Use (reverse all-results) at the end if order matters.\n;; But for many use cases (sorting results anyway), order doesn't matter.\n",
    "notes": "Scheme's append copies all cons cells of every argument except the last. So (append big-list small-list) copies big-list entirely. In a parallel accumulation loop, the accumulated list grows on each iteration, making the copy cost grow linearly and total cost quadratic. Swapping argument order — (append small-list big-list) — means only the small per-thread result is copied, keeping total cost linear. This matters when accumulating thousands of results across many threads: the O(n²) version can waste gigabytes of memory on intermediate copies that become garbage.",
    "related": [
      "mutex-unwind-protect"
    ]
  },
  {
    "id": "gerbil-function-signature-keyword-args-arity",
    "title": "gerbil_function_signature reports arity:1 for functions with keyword args",
    "tags": [
      "function-signature",
      "arity",
      "keyword",
      "args",
      "misleading",
      "gerbil-mcp"
    ],
    "imports": [],
    "code": ";; GOTCHA: gerbil_function_signature (and gerbil_doc) reports arity:1\n;; for functions that accept keyword arguments. This is technically correct\n;; (the compiled lambda takes 1 positional arg — the client/object) but\n;; misleading because the function actually accepts many keyword params.\n;;\n;; Example from gerbil-aws:\n;;   gerbil_function_signature for describe-alarms reports:\n;;     arity:1  (gerbil-aws/cloudwatch/operations#describe-alarms)\n;;\n;;   But the ACTUAL signature (from reading source) is:\n;;     (describe-alarms client\n;;       alarm-names: (alarm-names #f)\n;;       state-value: (state-value #f)\n;;       next-token: (next-token #f)\n;;       max-records: (max-records #f))\n;;\n;;   Similarly, describe-instances reports arity:1 but actually accepts:\n;;     (describe-instances client\n;;       instance-ids: (instance-ids [])\n;;       filters: (filters [])\n;;       max-results: (max-results #f)\n;;       next-token: (next-token #f))\n;;\n;; WORKAROUND: When gerbil_function_signature shows arity:1, ALWAYS\n;; read the actual source code (via gerbil_find_definition with\n;; source_preview: true, or by reading the .ss file directly) to\n;; discover keyword arguments.\n;;\n;; This is especially important for gerbil-aws library functions where\n;; most API operations accept keyword args for optional parameters like\n;; filters:, max-results:, next-token:, etc.",
    "notes": "Gambit compiles keyword arguments into a rest-args list internally, so the arity reflects only positional parameters. The gerbil_function_signature tool cannot currently extract keyword parameter names from compiled modules. Always verify by reading source when arity seems too low for an API wrapper function.",
    "related": [
      "optional-keyword-arguments"
    ]
  },
  {
    "id": "ec2-monitoring-state-filter",
    "title": "Filter EC2 instances by monitoring state instead of running state",
    "tags": [
      "EC2",
      "describe-instances",
      "filter",
      "monitoring",
      "detailed-monitoring",
      "gerbil-aws"
    ],
    "imports": [
      ":gerbil-aws/ec2/instances",
      ":gerbil-aws/ec2/api"
    ],
    "code": ";; To count instances with detailed monitoring enabled, use the\n;; \"monitoring-state\" filter instead of fetching ALL running instances.\n;;\n;; BAD — fetches every running instance (5-20KB each, thousands possible):\n;; (describe-instances ec2 filters: '((\"instance-state-name\" \"running\")))\n;; ;; Then manually check each instance's monitoring.state field\n;;\n;; GOOD — fetches only instances with detailed monitoring (typically few):\n(import :gerbil-aws/ec2/instances :gerbil-aws/ec2/api)\n(let* ((ec2 (EC2Client region: \"us-east-1\"))\n       (reservations (describe-instances ec2\n                       filters: '((\"monitoring-state\" \"enabled\")))))\n  ;; Count instances directly — no need to check monitoring.state\n  (let ((count 0))\n    (for-each\n     (lambda (res)\n       (let ((instances (hash-ref res 'instancesSet [])))\n         (set! count (+ count (if (list? instances) (length instances) 0)))))\n     reservations)\n    count))\n;; This avoids loading full instance metadata for potentially thousands\n;; of running instances when you only need the few with detailed monitoring.",
    "notes": "The \"monitoring-state\" filter is a standard EC2 DescribeInstances filter that returns only instances matching the given monitoring state (\"enabled\" or \"disabled\"). Using this instead of \"instance-state-name\" + manual filtering reduces API response size from potentially hundreds of MBs (all running instances with full metadata) to KBs (just the few with detailed monitoring). Remember that instancesSet may be \"\" (empty string) instead of [] for empty XML elements — always guard with (list? ...) check.",
    "related": [
      "ec2-lowercase-camelcase-keys",
      "ec2-empty-tagset-string"
    ]
  },
  {
    "id": "ec2-paginated-query-with-action-hash",
    "title": "Paginate EC2 API calls using ec2-action/hash to avoid OOM",
    "tags": [
      "ec2",
      "pagination",
      "nextToken",
      "ec2-action/hash",
      "memory",
      "describe-instances",
      "MaxResults"
    ],
    "imports": [
      ":gerbil-aws/ec2/api"
    ],
    "code": ";; PROBLEM: gerbil-aws high-level functions like describe-instances use\n;; ec2-action/items, which returns only the extracted items list and\n;; DISCARDS the NextToken from the response. This means ALL results\n;; are fetched in a single API call with no pagination.\n;;\n;; For large accounts (thousands of instances), this loads hundreds of\n;; MB of instance metadata into memory at once, causing OOM.\n;;\n;; SOLUTION: Use ec2-action/hash directly to get the full response\n;; hash including nextToken, and paginate manually.\n\n(import :gerbil-aws/ec2/api)\n\n;; Example: count instances with detailed monitoring, paginated\n(def (count-detailed-monitoring ec2)\n  (let loop ((next-token #f) (count 0))\n    (let* ((result (ec2-action/hash ec2 \"DescribeInstances\"\n                     (append\n                       [[\"MaxResults\" :: \"50\"]\n                        [\"Filter.1.Name\" :: \"monitoring-state\"]\n                        [\"Filter.1.Value.1\" :: \"enabled\"]]\n                       (if next-token [[\"NextToken\" :: next-token]] []))))\n           ;; reservationSet is a list of reservation hashes (EC2 uses lowercase)\n           (reservations (let ((rs (hash-get result 'reservationSet)))\n                           (if (list? rs) rs [])))\n           ;; Count instances across all reservations in this page\n           (page-count (let pc ((res reservations) (n 0))\n                         (if (null? res) n\n                           (let ((is (hash-get (car res) 'instancesSet)))\n                             (pc (cdr res) (+ n (if (list? is) (length is) 0)))))))\n           (new-count (+ count page-count))\n           ;; EC2 uses lowercase 'nextToken (not 'NextToken)\n           (nt (hash-get result 'nextToken)))\n      (if (and (string? nt) (> (string-length nt) 0))\n        (loop nt new-count)\n        new-count))))\n\n;; KEY POINTS:\n;; - ec2-action/hash returns the FULL response as a hash, including nextToken\n;; - EC2 uses lowercase camelCase keys: 'nextToken, 'reservationSet, 'instancesSet\n;; - MaxResults limits items per page (5-1000 for DescribeInstances)\n;; - Filter params use dot notation: Filter.N.Name, Filter.N.Value.M\n;; - Always check (list? ...) for set fields — empty XML elements become \"\"\n;; - Only accumulate what you need (counts, IDs) — let each page be GC'd",
    "notes": "The high-level describe-instances function uses ec2-action/items which extracts items from a specific XML tag but discards the rest of the response (including nextToken). This makes pagination impossible through the high-level API. You MUST drop down to ec2-action/hash for paginated queries. The same pattern applies to all EC2 Describe* operations. Remember EC2 uses lowercase camelCase keys (nextToken not NextToken), unlike CloudWatch which uses PascalCase.",
    "related": [
      "ec2-lowercase-camelcase-keys",
      "ec2-empty-tagset-string",
      "ec2-monitoring-state-filter"
    ]
  },
  {
    "id": "cloudwatch-paginated-describe-alarms",
    "title": "Paginate CloudWatch DescribeAlarms using cw-action/hash",
    "tags": [
      "cloudwatch",
      "pagination",
      "NextToken",
      "cw-action/hash",
      "describe-alarms",
      "MaxRecords",
      "memory"
    ],
    "imports": [
      ":gerbil-aws/cloudwatch/api"
    ],
    "code": ";; PROBLEM: The describe-alarms function in :gerbil-aws/cloudwatch/operations\n;; uses cw-action/hash internally but only returns MetricAlarms and\n;; CompositeAlarms — it DISCARDS the NextToken. No pagination possible.\n;;\n;; SOLUTION: Use cw-action/hash directly to paginate.\n\n(import :gerbil-aws/cloudwatch/api)\n\n;; Helper to unwrap CloudWatch member-list structures\n(def (cw-member-list raw)\n  (cond\n    ((not raw) [])\n    ((list? raw) raw)\n    ((hash-table? raw)\n     (let ((m (hash-get raw 'member)))\n       (cond ((list? m) m) ((not m) []) (else [m]))))\n    (else [])))\n\n;; Example: count alarms by type across all pages\n(def (count-alarms-by-type cw)\n  (let loop ((next-token #f) (std 0) (hires 0) (comp 0))\n    (let* ((full-hash (cw-action/hash cw \"DescribeAlarms\"\n                        (append\n                          [[\"MaxRecords\" :: \"100\"]]\n                          (if next-token [[\"NextToken\" :: next-token]] []))))\n           ;; CloudWatch wraps response in DescribeAlarmsResult\n           (result (or (hash-get full-hash 'DescribeAlarmsResult) full-hash))\n           (result (if (hash-table? result) result (hash)))\n           (metric-alarms (cw-member-list (hash-get result 'MetricAlarms)))\n           (composite-alarms (cw-member-list (hash-get result 'CompositeAlarms)))\n           ;; Count standard vs high-resolution metric alarms\n           (page-std 0) (page-hires 0))\n      (for-each\n       (lambda (a)\n         (if (and (hash-table? a)\n                  (< (string->number (hash-ref a 'Period \"60\")) 60))\n           (set! page-hires (+ page-hires 1))\n           (set! page-std (+ page-std 1))))\n       metric-alarms)\n      (let ((new-std (+ std page-std))\n            (new-hires (+ hires page-hires))\n            (new-comp (+ comp (length composite-alarms)))\n            ;; CloudWatch uses PascalCase 'NextToken (not lowercase)\n            (nt (hash-get result 'NextToken)))\n        (if (and (string? nt) (> (string-length nt) 0))\n          (loop nt new-std new-hires new-comp)\n          (values new-std new-hires new-comp))))))\n\n;; KEY POINTS:\n;; - cw-action/hash returns full response; navigate to 'DescribeAlarmsResult\n;; - CloudWatch uses PascalCase: 'NextToken, 'MetricAlarms, 'Period\n;; - MetricAlarms/CompositeAlarms use &lt;member&gt; tags — use cw-member-list helper\n;; - MaxRecords limits alarms per page (1-100, default 50)",
    "notes": "CloudWatch Query API uses PascalCase keys (NextToken, MetricAlarms) unlike EC2 which uses lowercase camelCase (nextToken, reservationSet). The DescribeAlarmsResult wrapper must be navigated to before accessing alarms. The member-list extraction is needed because CloudWatch XML uses member elements instead of item elements, and sxml->hash only auto-unwraps item elements.",
    "related": [
      "normalize-xml-member-list",
      "ec2-paginated-query-with-action-hash",
      "ec2-lowercase-camelcase-keys"
    ]
  },
  {
    "id": "aws-sxml-lightweight-counting",
    "title": "Use raw SXML (cw-action/ec2-action) instead of hash conversion for memory-efficient counting",
    "tags": [
      "sxml",
      "memory",
      "optimization",
      "cw-action",
      "ec2-action",
      "cloudwatch",
      "ec2",
      "hash-table",
      "count",
      "strip-ns"
    ],
    "imports": [
      ":gerbil-aws/cloudwatch/api",
      ":gerbil-aws/ec2/api",
      ":gerbil-aws/aws/xml"
    ],
    "code": ";; PROBLEM: cw-action/hash and ec2-action/hash parse the ENTIRE XML response\n;; into deeply nested hash tables via sxml->hash. For DescribeAlarms with\n;; 100 alarms (each with 25+ fields), this creates thousands of hash table\n;; entries per page — but you may only need a count or one field.\n;;\n;; SOLUTION: Use cw-action / ec2-action (raw SXML) and navigate the tree\n;; directly with strip-ns + sxml-items + sxml-text from :gerbil-aws/aws/xml.\n;; No hash tables are allocated per-object.\n\n(import :gerbil-aws/cloudwatch/api\n        :gerbil-aws/ec2/api\n        (only-in :gerbil-aws/aws/xml strip-ns sxml-items sxml-text))\n\n;; Helper: navigate past *TOP* to the response element\n(def (sxml-unwrap-top sxml)\n  (if (and (pair? sxml) (eq? (car sxml) '*TOP*))\n    (let loop ((children (cdr sxml)))\n      (cond\n        ((null? children) sxml)\n        ((and (pair? (car children))\n              (symbol? (caar children))\n              (not (memq (caar children) '(@ *NAMESPACES* *PI*))))\n         (car children))\n        (else (loop (cdr children)))))\n    sxml))\n\n;; Helper: find first direct child by tag (handles namespace prefixes)\n(def (sxml-child node tag)\n  (and (pair? node)\n       (let loop ((children (cdr node)))\n         (cond\n           ((null? children) #f)\n           ((and (pair? (car children))\n                 (symbol? (caar children))\n                 (eq? (strip-ns (caar children)) tag))\n            (car children))\n           (else (loop (cdr children)))))))\n\n;; Helper: get text of a named child\n(def (sxml-child-text node tag)\n  (let ((child (sxml-child node tag)))\n    (and child (sxml-text child))))\n\n;; Example: count CloudWatch alarms by type from raw SXML\n;; (cw-action returns SXML, NOT hash tables)\n(def (count-alarms-page cw next-token)\n  (let* ((sxml (cw-action cw \"DescribeAlarms\"\n                 (append [[\"MaxRecords\" :: \"100\"]]\n                         (if next-token [[\"NextToken\" :: next-token]] []))))\n         (resp (sxml-unwrap-top sxml))\n         (result (or (sxml-child resp 'DescribeAlarmsResult) resp))\n         ;; sxml-items finds <member> children (CW uses member, EC2 uses item)\n         (ma (sxml-child result 'MetricAlarms))\n         (members (if ma (sxml-items ma 'member) []))\n         (ca (sxml-child result 'CompositeAlarms))\n         (composites (if ca (sxml-items ca 'member) [])))\n    ;; Only extract Period — no hash tables built for each alarm\n    (let ((std 0) (hires 0))\n      (for-each (lambda (m)\n                  (let ((p (sxml-child-text m 'Period)))\n                    (if (and p (< (string->number p) 60))\n                      (set! hires (+ hires 1))\n                      (set! std (+ std 1)))))\n                members)\n      (values std hires (length composites)\n              (sxml-child-text result 'NextToken)))))\n\n;; Example: count EC2 instances from raw SXML\n;; (ec2-action returns SXML; EC2 uses 'item not 'member)\n(def (count-instances-page ec2 next-token)\n  (let* ((sxml (ec2-action ec2 \"DescribeInstances\"\n                 (append [[\"MaxResults\" :: \"50\"]\n                          [\"Filter.1.Name\" :: \"monitoring-state\"]\n                          [\"Filter.1.Value.1\" :: \"enabled\"]]\n                         (if next-token [[\"NextToken\" :: next-token]] []))))\n         (resp (sxml-unwrap-top sxml))\n         (res-set (sxml-child resp 'reservationSet))\n         ;; sxml-items default tag is 'item (EC2 convention)\n         (reservations (if res-set (sxml-items res-set) [])))\n    (let ((count (let loop ((res reservations) (n 0))\n                   (if (null? res) n\n                     (let ((is (sxml-child (car res) 'instancesSet)))\n                       (loop (cdr res)\n                             (+ n (if is (length (sxml-items is)) 0))))))))\n      (values count (sxml-child-text resp 'nextToken)))))",
    "notes": "Key insight: cw-action/hash and ec2-action/hash call sxml->hash which recursively creates make-hash-table + hash-put! for EVERY XML element. For responses with 100+ objects (alarms, instances), this is the dominant memory cost. Using the raw SXML APIs (cw-action, ec2-action) and navigating with strip-ns/sxml-items/sxml-text avoids all hash allocation.\n\nImportant details:\n- CloudWatch XML uses <member> elements: (sxml-items container 'member)\n- EC2 XML uses <item> elements: (sxml-items container) — default tag is 'item\n- CloudWatch uses PascalCase tags: 'DescribeAlarmsResult, 'NextToken, 'Period\n- EC2 uses lowercase camelCase: 'reservationSet, 'instancesSet, 'nextToken\n- strip-ns handles both full URI namespaces (CloudWatch) and short prefixes (ec2:)\n- sxml-text only works for (tag \"text\") leaf elements — exactly 2 elements\n- sxml-items uses strip-ns internally, so namespace handling is automatic\n- Semaphore concurrency should be reduced when using this pattern (less memory headroom needed but still good practice)",
    "related": [
      "paginate-ec2-action-hash",
      "sxml-skip-pi-nodes",
      "parse-xml-to-sxml",
      "ec2-lowercase-camelcase-keys"
    ]
  },
  {
    "id": "serialize-regions-gc-bound-memory",
    "title": "Serialize multi-region AWS calls with GC to bound peak memory",
    "tags": [
      "memory",
      "GC",
      "sequential",
      "region",
      "OOM",
      "serialize",
      "paginate",
      "page-size",
      "aws"
    ],
    "imports": [],
    "code": ";; PROBLEM: Processing all AWS regions concurrently with semaphore/threads\n;; causes OOM when each region produces large SXML trees (e.g., DescribeAlarms\n;; with 100 records/page, DescribeInstances with 50 full instance records).\n;; Even with raw SXML (no hash conversion), 2+ concurrent regions parsing\n;; large XML responses can exhaust memory before GC runs.\n;;\n;; SOLUTION: Three combined techniques:\n;; 1. Process regions sequentially (for-each, no threads/semaphore)\n;; 2. Use small page sizes (MaxRecords 25, MaxResults 10)\n;; 3. Force GC between phases and after each region\n\n;; BEFORE (OOM-prone):\n;; (let ((sem (make-semaphore 2)))\n;;   (for-each\n;;    (lambda (region)\n;;      (semaphore-wait! sem)\n;;      (spawn (lambda ()\n;;        (try\n;;          (do-alarms region)       ;; large SXML\n;;          (do-dashboards region)   ;; more SXML\n;;          (do-instances region)    ;; huge SXML (full instance details)\n;;          (finally (semaphore-post! sem))))))\n;;    regions))\n\n;; AFTER (memory-bounded):\n(def (process-all-regions regions)\n  (let ((total-count 0))\n    (for-each\n     (lambda (region)\n       (try\n        ;; Phase 1: alarms (small pages)\n        (let loop ((next-token #f))\n          (let* ((sxml (api-call region \"DescribeAlarms\"\n                         [[\"MaxRecords\" :: \"25\"]]))  ;; was 100\n                 (count (count-items sxml))\n                 (nt (extract-next-token sxml)))\n            (set! total-count (+ total-count count))\n            (when nt (loop nt))))\n        (##gc)  ;; free alarm SXML before next phase\n\n        ;; Phase 2: instances (very small pages — response includes\n        ;; ALL instance attributes: security groups, network interfaces,\n        ;; block devices, tags, etc.)\n        (let loop ((next-token #f))\n          (let* ((sxml (api-call region \"DescribeInstances\"\n                         [[\"MaxResults\" :: \"10\"]]))  ;; was 50\n                 (count (count-items sxml))\n                 (nt (extract-next-token sxml)))\n            (set! total-count (+ total-count count))\n            (when nt (loop nt))))\n\n        (catch (e) (handle-error region e))\n        (finally (##gc))))  ;; free everything before next region\n     regions)\n    total-count))\n\n;; WHY SMALL PAGES MATTER:\n;; - DescribeInstances returns FULL instance details for each instance\n;;   (security groups, network interfaces, block devices, tags, etc.)\n;;   A single instance can be 50+ SXML elements.\n;; - MaxResults=50 → ~2500 SXML elements per page\n;; - MaxResults=10 → ~500 SXML elements per page (5x less peak memory)\n;; - More API calls, but each page is GC-friendly\n;;\n;; TRADEOFF: Sequential is slower than concurrent, but won't OOM.\n;; For counting/aggregation tasks, correctness > speed.",
    "notes": "This pattern applies when you only need aggregated results (counts, sums) from AWS API responses, not the full data. The key insight is that DescribeInstances responses are disproportionately large because they include ALL instance attributes even when you only need a count. Reducing MaxResults from 50 to 10 cuts peak SXML memory ~5x per page. Combined with sequential processing and GC between phases, this bounds memory to roughly one small page worth of SXML at a time. If you need the actual data (not just counts), consider processing each page immediately and discarding the SXML before fetching the next page.",
    "related": [
      "force-gc-gambit",
      "sxml-counting-raw",
      "paginate-ec2-action-hash"
    ]
  },
  {
    "id": "memory-snapshot-profiling",
    "title": "Memory snapshot profiling with RSS + GC heap stats",
    "tags": [
      "memory",
      "profiling",
      "debug",
      "heap",
      "RSS",
      "VmRSS",
      "gc",
      "leak",
      "snapshot"
    ],
    "imports": [
      ":std/debug/heap",
      ":std/format"
    ],
    "code": ";; Complete memory profiling utility that combines:\n;; 1. OS-level RSS from /proc/self/status (actual process memory)\n;; 2. GC heap stats from :std/debug/heap memory-usage\n;;\n;; Returns an alist: ((gc-heap-size . N) (gc-alloc . N) (gc-live . N)\n;;                    (gc-movable . N) (gc-still . N))\n\n(import :std/debug/heap :std/format)\n\n;; Get VmRSS from /proc/self/status (Linux only)\n(def (get-rss-kb)\n  (try\n    (call-with-input-file \"/proc/self/status\"\n      (lambda (port)\n        (let loop ((line (read-line port)))\n          (if (eof-object? line) 0\n            (if (and (>= (string-length line) 6)\n                     (string=? \"VmRSS:\" (substring line 0 6)))\n              ;; Parse the number from \"VmRSS:   12345 kB\"\n              (let find-num ((i 6))\n                (cond\n                  ((>= i (string-length line)) 0)\n                  ((char-numeric? (string-ref line i))\n                   (let end-num ((j (+ i 1)))\n                     (if (or (>= j (string-length line))\n                             (not (char-numeric? (string-ref line j))))\n                       (string->number (substring line i j))\n                       (end-num (+ j 1)))))\n                  (else (find-num (+ i 1)))))\n              (loop (read-line port)))))))\n    (catch (e) 0)))\n\n;; Print + return memory snapshot\n(def (mem-snapshot label)\n  (let* ((rss-kb (get-rss-kb))\n         (rss-mb (/ rss-kb 1024.0))\n         (heap (memory-usage))\n         (gc-heap-mb (/ (cdr (assoc 'gc-heap-size heap)) (* 1024.0 1024.0)))\n         (gc-live-mb (/ (cdr (assoc 'gc-live heap)) (* 1024.0 1024.0))))\n    (fprintf (current-error-port)\n             \"[MEM ~a] RSS=~aMB | GC-heap=~aMB live=~aMB~n\"\n             label\n             (number->string (inexact->exact (round rss-mb)))\n             (number->string (inexact->exact (round gc-heap-mb)))\n             (number->string (inexact->exact (round gc-live-mb))))\n    (force-output (current-error-port))\n    (list (cons 'rss-kb rss-kb) (cons 'rss-mb rss-mb)\n          (cons 'gc-heap-mb gc-heap-mb) (cons 'gc-live-mb gc-live-mb))))\n\n;; Print delta from previous snapshot\n(def (mem-delta label prev)\n  (let* ((snap (mem-snapshot label))\n         (d-rss (- (cdr (assoc 'rss-mb snap)) (cdr (assoc 'rss-mb prev))))\n         (d-live (- (cdr (assoc 'gc-live-mb snap)) (cdr (assoc 'gc-live-mb prev)))))\n    (fprintf (current-error-port)\n             \"[MEM-DELTA ~a] RSS=~a~aMB live=~a~aMB~n\"\n             label\n             (if (>= d-rss 0) \"+\" \"-\") (number->string (inexact->exact (round (abs d-rss))))\n             (if (>= d-live 0) \"+\" \"-\") (number->string (inexact->exact (round (abs d-live)))))\n    (force-output (current-error-port))\n    snap))\n\n;; Usage: wrap suspect sections\n;; (let ((s (mem-snapshot \"before-heavy-work\")))\n;;   (heavy-work)\n;;   (mem-delta \"after-heavy-work\" s)\n;;   (##gc)\n;;   (mem-delta \"after-gc\" s))",
    "notes": "memory-usage from :std/debug/heap returns an alist with keys: gc-heap-size, gc-alloc, gc-live, gc-movable, gc-still (all in bytes). The gc-live value shows how much memory is actually retained after GC. RSS from /proc/self/status shows the OS-level resident set — this includes memory that Gambit has allocated from the OS but may not have returned yet (the GC heap can grow but rarely shrinks). Output goes to stderr via current-error-port so it doesn't pollute stdout. The :std/debug/heap import triggers some Gambit warnings about undefined variables (macro-slot, macro-will-action, macro-will-testator) — these are harmless and can be ignored.",
    "related": [
      "force-gc-gambit",
      "serialize-multi-region-gc"
    ]
  },
  {
    "id": "run-standalone-script-with-project-imports",
    "title": "Run standalone gxi script that imports project modules",
    "tags": [
      "gxi",
      "script",
      "standalone",
      "import",
      "GERBIL_LOADPATH",
      "package",
      "relative",
      "module context"
    ],
    "imports": [],
    "code": ";; PROBLEM: You have a standalone test/utility script that needs to\n;; import modules from your project. Relative imports fail:\n;;\n;;   ;; test-script.ss\n;;   (import ./aws ./resources)  ;; FAILS!\n;;   ;; Error: \"cannot resolve relative module path; not in module context\"\n;;\n;; Relative imports (./module) only work inside a module being compiled\n;; as part of a build. When running a .ss file directly with `gxi`,\n;; the file is NOT in a module context.\n;;\n;; SOLUTION: Use package-qualified imports and set GERBIL_LOADPATH.\n;;\n;; Given a project with gerbil.pkg:\n;;   (package: my-project)\n;;\n;; And modules: aws.ss, resources.ss, etc.\n\n;; test-script.ss — correct way:\n;; (import :my-project/aws\n;;         :my-project/resources\n;;         :my-project/pricing)\n;;\n;; Run with GERBIL_LOADPATH pointing to the project's compiled libs:\n;;   GERBIL_LOADPATH=.gerbil/lib gxi test-script.ss\n;;\n;; Or with absolute path:\n;;   GERBIL_LOADPATH=/path/to/project/.gerbil/lib gxi test-script.ss\n;;\n;; If the project also depends on external packages:\n;;   GERBIL_LOADPATH=/path/to/project/.gerbil/lib:~/.gerbil/lib gxi test-script.ss\n\n;; IMPORTANT: The project must be built first (`gerbil build` or `make`)\n;; so that .gerbil/lib/ contains the compiled module files.\n\n;; Full example — standalone memory test script:\n;; #!/usr/bin/env gxi\n;; (import :std/format\n;;         :std/debug/heap\n;;         :my-project/aws\n;;         :my-project/resources)\n;;\n;; (def (main . args)\n;;   (let ((snap (mem-snapshot \"START\")))\n;;     (get-resources)\n;;     (mem-delta \"END\" snap)))\n;;\n;; (apply main (cdr (command-line)))",
    "notes": "Key points: (1) ./module syntax ONLY works inside compiled modules, not standalone gxi scripts. (2) Use :package/module paths matching your gerbil.pkg package: declaration. (3) GERBIL_LOADPATH must include the project's .gerbil/lib/ directory. (4) The project must be built first so compiled modules exist. (5) Multiple LOADPATH entries are colon-separated. (6) For CLI scripts, use (command-line) to get args and (apply main (cdr (command-line))) to invoke.",
    "related": [
      "gerbil-build-loadpath"
    ]
  },
  {
    "id": "resolve-import-naming-conflicts",
    "title": "Resolve naming conflicts when importing modules with only-in/except-in",
    "tags": [
      "import",
      "only-in",
      "except-in",
      "conflict",
      "naming",
      "duplicate",
      "shadow",
      "string-split",
      "string-prefix"
    ],
    "imports": [],
    "code": ";; PROBLEM: Your module defines a function that has the same name as\n;; something exported by a standard library module you want to import.\n;;\n;; Example: Your aws.ss defines its own string-split and string-prefix?\n;; but you also want to import :std/misc/string for other utilities.\n;;\n;; WRONG — duplicate definition error:\n;; (import :std/misc/string)  ;; exports string-split, string-prefix?, etc.\n;; (def (string-split s sep) ...)  ;; CONFLICT! already imported\n;;\n;; SOLUTION 1: Use only-in to import specific non-conflicting symbols\n;; (import (only-in :std/misc/string\n;;           string-trim-prefix\n;;           string-trim-suffix\n;;           string-trim-eol))\n;;\n;; SOLUTION 2: Use except-in to exclude conflicting symbols\n;; (import (except-in :std/misc/string\n;;           string-split\n;;           string-prefix?))\n;;\n;; SOLUTION 3: Use prefix-in to namespace all imports\n;; (import (prefix-in str: :std/misc/string))\n;; ;; Now use str:string-split, str:string-prefix?, etc.\n;; ;; Your own string-split is unaffected\n;;\n;; SOLUTION 4: Skip the import entirely if you only need the\n;; conflicting symbols and already have local implementations.\n;; This is the simplest approach when the overlap is large.\n;;\n;; SOLUTION 5: Use rename-in to rename specific conflicting imports\n;; (import (rename-in :std/misc/string\n;;           (string-split std-string-split)\n;;           (string-prefix? std-string-prefix?)))\n;; ;; Now both versions available under different names\n\n;; CHECKING what a module exports before importing:\n;; Use gerbil_module_exports MCP tool, or in the REPL:\n;;   (import :std/misc/string)\n;;   ;; then check which names appeared",
    "notes": "Common conflict sources: (1) :std/misc/string exports string-split, string-prefix?, string-suffix? which many projects define locally. (2) :std/srfi/1 exports map, for-each, filter etc. which shadow Gerbil's built-ins. (3) :std/iter exports for which shadows Gerbil's for (though they're usually compatible). Always use gerbil_module_exports to check what a module exports BEFORE importing it. The only-in approach is safest — you explicitly list what you need and won't get surprise conflicts if the upstream module adds new exports.",
    "related": [
      "export-t-no-reexport"
    ]
  },
  {
    "id": "def-self-shadow-infinite-recursion",
    "title": "Local def shadows imported/intended function — causes infinite recursion",
    "tags": [
      "shadow",
      "def",
      "infinite recursion",
      "SIGSEGV",
      "stack overflow",
      "self-call",
      "gotcha"
    ],
    "imports": [
      ":std/error"
    ],
    "code": ";; PROBLEM: Defining a function with the same name as one you intend to call\n;; creates accidental infinite recursion. The local def shadows any import.\n;;\n;; WRONG — infinite recursion, manifests as SIGSEGV (stack overflow):\n;; (def (exception->string e)\n;;   (or (exception->string e)   ;; calls ITSELF, not some library function\n;;       (call-with-output-string (lambda (p) (display-exception e p)))))\n;;\n;; The author likely intended to call a library's exception->string first,\n;; then fall back. But no such function exists in Gerbil's stdlib, and\n;; even if it did, the local def would shadow it.\n;;\n;; This causes SIGSEGV because:\n;; 1. An exception occurs somewhere (e.g., API error)\n;; 2. A catch block calls exception->string\n;; 3. The function calls itself infinitely\n;; 4. Stack overflow hits the guard page → SIGSEGV\n;; 5. GDB may report the crash in a DIFFERENT module's code\n;;    (wherever the stack pointer lands)\n\n;; CORRECT — use type-dispatch, never self-reference unless intended:\n(def (exception->string e)\n  (cond\n    ((Error? e) (Error-message e))              ;; Gerbil Error struct\n    ((error-exception? e)                        ;; Gambit error-exception\n     (error-exception-message e))\n    (else                                        ;; everything else\n     (call-with-output-string\n       (lambda (p) (display-exception e p))))))\n\n;; GENERAL RULE: In Gerbil, a top-level (def (foo ...) ...) in a module\n;; creates a binding for 'foo' that shadows ANY imported 'foo'.\n;; If you call 'foo' inside the body of that def, you call YOURSELF.\n;; There is no way to \"fall through\" to the imported version.\n;;\n;; If you need the imported version, rename on import:\n;; (import (rename-in :some-lib (foo lib-foo)))\n;; (def (foo e)\n;;   (or (lib-foo e)  ;; calls the imported version\n;;       (fallback e)))",
    "notes": "This is a subtle bug because: (1) it compiles without warning, (2) it only crashes when the code path is actually hit (e.g., when an exception is caught), (3) the SIGSEGV crash location in GDB may point to a completely different module due to how stack overflow works in compiled Gambit code. The key diagnostic clue is a SIGSEGV during exception handling. Always check that your catch-block helper functions don't accidentally recurse.",
    "related": [
      "error-message-returns-false",
      "error-handling"
    ]
  }
]
